# --- Standard library ---
import os
import math
import time
import gzip
import threading
from datetime import datetime
from typing import Sequence, Optional, Union

# --- Third-party ---
import numpy as np
import numpy_financial as npf
import pandas as pd
import xarray as xr
import dill
from joblib import Parallel, delayed
import geopandas as gpd
import rasterio
from rasterio.features import rasterize

# --- Local packages ---
from tools.tools import (
    get_path, get_year, save2nc, filter_all_from_dims, nc_to_tif, get_data_RES_path
)
from tools.helper_data import (
    summarize_to_type, summarize_to_category, build_profit_and_cost_nc,
    make_prices_nc, summarize_netcdf_to_excel, create_profit_for_cost, create_summary
)
from tools import LogToFile, log_memory_usage
import tools.config as config


def tprint(*args, **kwargs):
    """
    æ‰“å°æ—¶è‡ªåŠ¨åŠ ä¸Šæ—¶é—´æˆ³ (YYYY-MM-DD HH:MM:SS)
    """
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{now}]", *args, **kwargs)
    return

def get_main_data_variable_name(ds: xr.Dataset) -> str:
    """è‡ªåŠ¨ä» xarray.Dataset ä¸­è·å–å”¯ä¸€çš„æ•°æ®å˜é‡åã€‚"""
    data_vars_list = list(ds.data_vars)
    if len(data_vars_list) == 1:
        return data_vars_list[0]
    elif len(data_vars_list) == 0:
        raise ValueError("é”™è¯¯ï¼šæ•°æ®é›†ä¸­ä¸åŒ…å«ä»»ä½•æ•°æ®å˜é‡ã€‚")
    else:
        raise ValueError(f"é”™è¯¯ï¼šæ•°æ®é›†ä¸­åŒ…å«å¤šä¸ªæ•°æ®å˜é‡: {data_vars_list}ã€‚")

def sum_dims_if_exist(
    nc_path: str,
    vars: Optional[Sequence[str]] = None,   # æŒ‡å®šåªå¤„ç†å“ªäº›å˜é‡ï¼›None=å¤„ç†å…¨éƒ¨
    dims = ['lm',"source","Type","GHG_source","Cost type","From water-supply","To water-supply"],
    engine: Optional[str] = "h5netcdf",           # ä¾‹å¦‚ "h5netcdf" æˆ– "netcdf4"
    chunks="auto",                           # å¤§æ–‡ä»¶å»ºè®®ä¿ç•™æ‡’åŠ è½½
    keep_attrs: bool = True,
    finalize: str = "compute",                  # "lazy" | "persist" | "compute"
):
    """
    æ‰“å¼€ NetCDF æ–‡ä»¶ï¼Œå¯¹ç»™å®šçš„ç»´åº¦ï¼ˆå¦‚æœè¯¥å˜é‡é‡Œå­˜åœ¨ï¼‰æ‰§è¡Œ sum å½’çº¦ã€‚
    è¿”å› xarray.Datasetï¼ˆé»˜è®¤æ‡’è®¡ç®—ï¼‰ã€‚

    å‚æ•°
    ----
    nc_path : str
        NetCDF æ–‡ä»¶è·¯å¾„
    dims : str | list[str]
        æƒ³è¦æ±‚å’Œçš„ç»´åº¦åé›†åˆï¼›ä»…å½“ç»´åº¦å­˜åœ¨äºå˜é‡ä¸­æ—¶æ‰ä¼šè¢«æ±‚å’Œ
    vars : list[str] | None
        ä»…å¤„ç†è¿™äº›å˜é‡ï¼›None è¡¨ç¤ºå¤„ç†æ‰€æœ‰ data_vars
    engine : str | None
        xarray åç«¯å¼•æ“ï¼ˆå¦‚ "h5netcdf"ï¼‰
    chunks : "auto" | dict | None
        dask åˆ†å—è®¾ç½®
    keep_attrs : bool
        å½’çº¦æ—¶æ˜¯å¦ä¿ç•™ attrs
    finalize : "lazy" | "persist" | "compute"
        è¿”å›å‰æ˜¯å¦è§¦å‘è®¡ç®—ï¼š
        - "lazy"ï¼šä¸è®¡ç®—ï¼ˆé»˜è®¤ï¼‰
        - "persist"ï¼šæŠŠç»“æœæŒä¹…åœ¨å†…å­˜ï¼ˆé€‚åˆåå¤ç”¨ï¼‰
        - "compute"ï¼šç›´æ¥è®¡ç®—æˆ numpy-backed

    è¿”å›
    ----
    xr.Dataset
    """
    if isinstance(dims, str):
        dims = [dims]

    ds = xr.open_dataset(nc_path, engine=engine, chunks=chunks)

    def _reduce(da: xr.DataArray) -> xr.DataArray:
        present = [d for d in dims if d in da.dims]
        return da.sum(dim=present, keep_attrs=keep_attrs, skipna=True) if present else da

    if vars is None:
        out = ds.map(_reduce)  # å¯¹æ‰€æœ‰å˜é‡åº”ç”¨
    else:
        missing = [v for v in vars if v not in ds.data_vars]
        if missing:
            raise KeyError(f"å˜é‡ä¸å­˜åœ¨: {missing}")
        out = ds.copy()
        for v in vars:
            out[v] = _reduce(ds[v])

    if finalize == "compute":
        res = out.compute()
        ds.close()
        return res
    if finalize == "persist":
        res = out.persist()
        ds.close()
        return res
    return out

def amortize_costs(data_path_name, amortize_file, years, njobs=0, rate=0.07, horizon=91):
    """
    ã€æœ€ç»ˆä¿®å¤ç‰ˆ - é€å¹´è¾“å‡ºã€‘è®¡ç®—æˆæœ¬å‡æ‘Šï¼Œå¹¶ä¸ºæ¯ä¸€å¹´ç”Ÿæˆä¸€ä¸ªç´¯è®¡æˆæœ¬æ–‡ä»¶ã€‚
    1. ä½¿ç”¨ Dask æ„å»ºå®Œæ•´çš„è®¡ç®—å›¾ï¼Œè®¡ç®—å‡ºæ‰€æœ‰å¹´ä»½çš„ç´¯è®¡æ‘Šé”€æˆæœ¬ã€‚
    2. åœ¨ä¿å­˜é˜¶æ®µï¼Œé€šè¿‡å¾ªç¯å’Œåˆ‡ç‰‡ï¼Œä¸ºæ¯ä¸€å¹´å•ç‹¬è§¦å‘è®¡ç®—å¹¶ä¿å­˜ä¸€ä¸ªæ–‡ä»¶ã€‚
    """
    tprint(f"å¼€å§‹è®¡ç®— '{data_path_name}' çš„æ‘Šé”€æˆæœ¬... (é€å¹´è¾“å‡ºæ¨¡å¼)")
    # --- 1. æ•°æ®åŠ è½½ä¸é¢„å¤„ç† (ä¸ä¹‹å‰ç‰ˆæœ¬å®Œå…¨ç›¸åŒ) ---
    file_paths = [os.path.join(data_path_name, f'{year}', f'{amortize_file}_{year}.nc') for year in years]
    existing_files = [p for p in file_paths if os.path.exists(p)]
    if not existing_files: raise FileNotFoundError(
        f"åœ¨è·¯å¾„ {data_path_name} ä¸‹æ‰¾ä¸åˆ°ä»»ä½•ä¸ '{amortize_file}' ç›¸å…³çš„æ–‡ä»¶ã€‚")
    valid_years = sorted([int(path.split('_')[-1].split('.')[0]) for path in existing_files])

    all_costs_ds = xr.open_mfdataset(
        existing_files,
        engine="h5netcdf",  # æ¨èåç«¯
        combine="nested",
        concat_dim="year",
        parallel=False,  # å…³é”®ï¼šé¿å…å¥æŸ„å¹¶å‘é—®é¢˜
        chunks={ "cell":'auto', "year": -1}  # year æ•´å—ã€cell åˆ†å—
    ).assign_coords(year=valid_years)

    cost_variable_name = get_main_data_variable_name(all_costs_ds)
    pv_values_all_years = all_costs_ds[cost_variable_name]

    annual_payments = xr.apply_ufunc(
        lambda x: -1 * npf.pmt(rate, horizon, pv=x.astype(np.float64), fv=0, when='begin'),
        pv_values_all_years,
        dask="parallelized",
        output_dtypes=[np.float32],
    ).astype('float32')

    all_years = annual_payments.year.values  # e.g., np.arange(2010, 2051)
    base_shape = annual_payments.sel(year=all_years[0]).drop_vars('year').shape
    n_years = len(all_years)

    # åˆå§‹åŒ– numpy arrayï¼Œç”¨äºç´¯åŠ æ‰€æœ‰å½±å“
    amortized_matrix = np.zeros((n_years,) + base_shape, dtype=np.float32)
    for source_year in all_years:
        tprint(f"  - å¤„ç†{data_path_name}èµ·å§‹å¹´ä»½ {source_year} ...")
        payment = annual_payments.sel(year=source_year).drop_vars('year').values
        payment = np.nan_to_num(payment, nan=0.0)
        for offset in range(horizon):
            affect_year = source_year + offset
            if affect_year in all_years:
                affect_idx = affect_year - all_years[0]
                amortized_matrix[affect_idx] += payment
    # æ„å»º xarray.DataArrayï¼Œæ·»åŠ åæ ‡ä¿¡æ¯
    coords = {k: v for k, v in annual_payments.coords.items() if k != 'year'}
    coords['year'] = all_years
    dims = ('year',) + tuple(d for d in annual_payments.dims if d != 'year')
    amortized_by_affect_year = xr.DataArray(
        data=amortized_matrix,
        dims=dims,
        coords=coords,
        name='data',
    )
    tprint("start compute...")
    amortized_by_affect_year.compute()
    tprint("compute done.")

    # å…³é—­å¥æŸ„
    all_costs_ds.close()

    # === ä¿å­˜å‡½æ•° ===
    # ä¿å­˜å„å¹´ä»½è¾“å‡º
    if njobs and njobs > 0:
        def _save_one_year(y: int):
            try:
                out_dir = os.path.join(data_path_name, f"{y}")
                os.makedirs(out_dir, exist_ok=True)
                out_path = os.path.join(out_dir, f"{amortize_file}_amortised_{y}.nc")
                tprint(f"  - [thread] ä¿å­˜å¹´ä»½ {y} -> {out_path}")

                da_y = amortized_by_affect_year.sel(year=y)
                ds_y = xr.Dataset({'data': da_y})
                save2nc(ds_y, out_path)
                return f"âœ… å¹´ä»½ {y} å·²ä¿å­˜"
            except Exception as e:
                return f"âŒ å¹´ä»½ {y} å¤±è´¥: {e}"

        results = Parallel(n_jobs=njobs, backend="threading")(
            delayed(_save_one_year)(y) for y in all_years
        )
        for msg in results:
            tprint(msg)

    else:
        for y in all_years:
            out_dir = os.path.join(data_path_name, f"{y}")
            os.makedirs(out_dir, exist_ok=True)
            out_path = os.path.join(out_dir, f"{amortize_file}_amortised_{y}.nc")
            tprint(f"  - ä¿å­˜å¹´ä»½ {y} -> {out_path}")
            da_y = amortized_by_affect_year.sel(year=y)
            ds_y = xr.Dataset({'data': da_y})
            save2nc(ds_y, out_path)
    return

# --- è¾…åŠ©å‡½æ•°ï¼šä¸“é—¨ç”¨äºè®¡ç®—å•ä¸ªæ–‡ä»¶å¯¹çš„å·®å¼‚ï¼Œä»¥ä¾¿å¹¶è¡ŒåŒ– ---
def calculate_and_save_single_diff(diff_file, year, data_path_name):
    """
    è®¡ç®—å¹¶ä¿å­˜å•ä¸ªæ–‡ä»¶å¯¹çš„å·®å¼‚ã€‚
    è¿™ä¸ªå‡½æ•°å°†è¢«å¹¶è¡Œè°ƒç”¨ã€‚
    """
    # 1. æ„é€ ä¸Šä¸€å¹´åº¦å’Œå½“å‰å¹´åº¦çš„æ–‡ä»¶è·¯å¾„
    src_file_0 = os.path.join(data_path_name, str(year),  f"{diff_file}_{year}.nc")
    src_file_1 = os.path.join(data_path_name, f'{year - 1}',  f"{diff_file}_{year-1}.nc")
    tprint(f"Calculating diff for {src_file_0} between years {year-1} and {year}...")

    # 4. æ„é€ ç›®æ ‡è·¯å¾„å¹¶ä¿å­˜
    variable_name = diff_file.replace('.nc', '')
    dst_filename = f"{variable_name}_diff_{year}.nc"
    dst_file = os.path.join(data_path_name, str(year), dst_filename)
    # 2. æ‰“å¼€è¿™å¯¹æ–‡ä»¶
    with xr.open_dataset(src_file_0) as ds_0, xr.open_dataset(src_file_1) as ds_1:
        # 3. è®¡ç®—å·®å¼‚
        ds_res = ds_0 - ds_1

    save2nc(ds_res, dst_file)

    return f"  - Success: Calculated and saved diff for {dst_filename}"



def copy_single_file(
        origin_path_name: str,
        target_path_name: str,
        var_prefix: str,  # ä¾‹å¦‚ "xr_cost_ag"
        year: int,
        dims_to_sum=('lm', 'source', 'Type', 'GHG_source', 'Cost type', 'From water-supply', 'To water-supply'),
        engine: str = "h5netcdf",
        chunks="auto",
        allow_missing_2010: bool = True,
) -> str:
    """
    ã€é™é»˜ç‰ˆã€‘å¤åˆ¶å¹¶å¤„ç†å•ä¸ª NetCDF æ–‡ä»¶ï¼Œç§»é™¤äº†æ‰€æœ‰æ—¥å¿—è®°å½•ï¼Œé€‚ç”¨äºå¹¶è¡Œç¯å¢ƒã€‚
    """
    # 1. æ„å»ºæ–‡ä»¶è·¯å¾„
    year_path = os.path.join(origin_path_name, f"out_{year}")
    target_year_path = os.path.join(target_path_name, str(year))
    os.makedirs(target_year_path, exist_ok=True)

    src_file = os.path.join(year_path, f"{var_prefix}_{year}.nc")
    dst_file = os.path.join(target_year_path, f"{var_prefix}_{year}.nc")

    tprint(f"Copying: {os.path.basename(src_file)} to {dst_file}")

    # 2. æ£€æŸ¥æºæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(src_file):
        if allow_missing_2010 and year == 2010:
            tprint( f"Skipped: {os.path.basename(src_file)} (missing but allowed for year 2010)")
            return

    def _reduce_one(da: xr.DataArray) -> xr.DataArray:
        """å¯¹ DataArray ä¸­å­˜åœ¨çš„ç»´åº¦è¿›è¡Œæ±‚å’Œ"""
        if not np.issubdtype(da.dtype, np.number):
            return da

        present_dims = [d for d in dims_to_sum if d in da.dims]

        if present_dims:
            return da.sum(dim=present_dims, keep_attrs=True, skipna=True)
        return da

    with xr.open_dataset(src_file, engine=engine, chunks=chunks) as ds:
        ds = filter_all_from_dims(ds)
        ds_filled = ds.fillna(0)
        out = ds_filled.map(_reduce_one).load()
        save2nc(out, dst_file)
    return f"âœ… Copied: {os.path.basename(src_file)} to {dst_file}"



# ==============================================================================
# STAGE 1: è®¡ç®—åˆ©æ¶¦ (Profit = Revenue - Cost)
# ==============================================================================
def calculate_profit_for_run(year, out_path, run_name, cost_basename, revenue_basename):
    """
    ä¸ºå•ä¸ªæƒ…æ™¯(Run)å’Œå•ä¸ªç±»åˆ«è®¡ç®—åˆ©æ¶¦ã€‚
    """
    tprint(f"{out_path}/{run_name}/{year}: è®¡ç®—åˆ©æ¶¦...")
    # æ„å»ºè¾“å…¥æ–‡ä»¶è·¯å¾„
    cost_file = os.path.join(out_path, run_name, str(year), f'{cost_basename}_{year}.nc')
    revenue_file = os.path.join(out_path, run_name, str(year), f'{revenue_basename}_{year}.nc')

    # ä½¿ç”¨ with è¯­å¥ç¡®ä¿æ–‡ä»¶æ­£ç¡®å…³é—­
    with xr.open_dataset(cost_file,chunks='auto') as ds_cost, \
            xr.open_dataset(revenue_file,chunks='auto') as ds_revenue:
        # 1. åº”ç”¨æ‚¨è‡ªå®šä¹‰çš„è¿‡æ»¤å™¨
        ds_revenue_processed = filter_all_from_dims(ds_revenue)
        ds_cost_processed = filter_all_from_dims(ds_cost)

        # 2. å¡«å…… NaN å€¼
        ds_revenue_filled = ds_revenue_processed.fillna(0)
        ds_cost_filled = ds_cost_processed.fillna(0)

        # --- ã€å…³é”®ä¿®æ­£ã€‘ æ£€æŸ¥ 'source' ç»´åº¦æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœå­˜åœ¨åˆ™è¿›è¡Œèšåˆ ---

        # å¤„ç† Revenue æ•°æ®é›†
        # ds.dims æ˜¯ä¸€ä¸ªåŒ…å«æ‰€æœ‰ç»´åº¦åç§°çš„ç±»å…ƒç»„å¯¹è±¡
        if 'source' in ds_revenue_filled.dims:
            total_revenue = ds_revenue_filled.sum(dim='source')
        else:
            total_revenue = ds_revenue_filled

        # å¤„ç† Cost æ•°æ®é›†
        if 'source' in ds_cost_filled.dims:
            total_cost = ds_cost_filled.sum(dim='source')
        else:
            total_cost = ds_cost_filled

        profit = total_revenue - total_cost
        profit_out_path = os.path.join(out_path, run_name, str(year))
        os.makedirs(profit_out_path, exist_ok=True)

        # ä¸ºäº†åŒºåˆ†ï¼Œæˆ‘ä»¬ç»™æ–‡ä»¶ååŠ ä¸Š profit å‰ç¼€
        profit_filename = f'xr_profit_{cost_basename.replace("xr_cost_", "")}_{year}.nc'
        save2nc(profit, os.path.join(profit_out_path, profit_filename))

        return f"âœ… Profit: Calculated for {os.path.basename(out_path)}/{profit_filename}"




# ==============================================================================


# å‡è®¾ tprint å’Œ save2nc å·²å®šä¹‰

def calculate_policy_cost(year, output_path, run_all_names, cost_category, policy_type, cost_names):
    """
    åŸºäºåˆ©æ¶¦å·®è®¡ç®—æ”¿ç­–æˆæœ¬ (Carbon æˆ– Bio)ã€‚ã€ä¼˜åŒ–ç‰ˆã€‘
    """
    tprint(f"Calculating policy cost for {policy_type}/{cost_category} in year {year}...")

    # 1. ç”Ÿæˆè®¡ç®—ä»»åŠ¡é…ç½®
    cost_configs = []
    if policy_type == 'carbon':
        # Carbon Cost: Profit_Run0 - Profit_Run1
        for i, run_B_name in enumerate(run_all_names[1]):
            cost_configs.append({
                'run_A_name': run_all_names[0][0],
                'run_B_name': run_B_name,
                'output_subdir': cost_names[i]
            })
    elif policy_type == 'bio':
        # Bio Cost: Profit_Run1 - Profit_Run2
        # å‡è®¾æ¯ä¸ª Run1 å¯¹åº” 5 ä¸ª Run2 åœºæ™¯
        num_j = int(len(run_all_names[2])/len(run_all_names[1]))
        for i, run_A_name in enumerate(run_all_names[1]):
            for j in range(num_j):
                index = i * num_j + j
                if index >= len(cost_names) or index >= len(run_all_names[2]):
                    tprint(f"âš ï¸ WARNING: Index {index} is out of bounds. Skipping.")
                    continue
                cost_configs.append({
                    'run_A_name': run_A_name,
                    'run_B_name': run_all_names[2][index],
                    'output_subdir': cost_names[index]
                })
    elif policy_type == 'counter':
        # åŒæ—¶è®¡ç®— Carbon å’Œ Bio æˆæœ¬
        # Carbon Cost éƒ¨åˆ†
        for i, run_B_name in enumerate(run_all_names[2]):
            cost_configs.append({
                'run_A_name': run_all_names[0][0],
                'run_B_name': run_B_name,
                'output_subdir': cost_names[i]
            })
    else:
        raise ValueError(f"Unknown policy_type: {policy_type}. Expected 'carbon' or 'bio'.")

    # 2. å¾ªç¯æ‰§è¡Œè®¡ç®—ä»»åŠ¡
    profit_file_basename = f'xr_profit_{cost_category}_{year}.nc'
    for config in cost_configs:
        run_A_name, run_B_name, output_subdir = config['run_A_name'], config['run_B_name'], config['output_subdir']

        # æ„å»ºè·¯å¾„å¹¶æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        profit_file_A = os.path.join(output_path, run_A_name, str(year), profit_file_basename)
        profit_file_B = os.path.join(output_path, run_B_name, str(year), profit_file_basename)

        # è®¡ç®—ã€ä¿å­˜
        tprint(f"  -> Processing: {output_subdir}...")
        output_dir = os.path.join(output_path, output_subdir, str(year))
        os.makedirs(output_dir, exist_ok=True)
        output_filename = f'xr_cost_{cost_category}_{output_subdir}_{year}.nc'

        with xr.open_dataset(profit_file_A,chunks='auto') as ds_A, xr.open_dataset(profit_file_B,chunks='auto') as ds_B:
            ds_A = filter_all_from_dims(ds_A)
            ds_B = filter_all_from_dims(ds_B)

            policy_cost = ds_A - ds_B
            save2nc(policy_cost, os.path.join(output_dir, output_filename))

    tprint(f"âœ… All {policy_type} policy cost calculations complete for year {year}.")
    return


def calculate_transition_cost_diff(year, output_path, run_all_names, tran_cost_file, policy_type, cost_names):
    """
    è®¡ç®—è½¬å‹æˆæœ¬æ–‡ä»¶çš„å·®å€¼ (Run1-Run0 æˆ– Run2-Run1)ã€‚
    ã€ä¼˜åŒ–ç‰ˆã€‘: ä½¿ç”¨ .persist() é¿å…åœ¨å¾ªç¯ä¸­é‡å¤è¯»å–æ–‡ä»¶ï¼Œæé«˜æ€§èƒ½å¹¶å¢å¼ºå¹¶è¡Œç¨³å®šæ€§ã€‚
    """
    # tprint(f"Calculating transition cost diff for {tran_cost_file} {policy_type} in year {year}...")

    tran_file_basename = f"{tran_cost_file}_{year}.nc"

    if policy_type == "carbon":
        # Carbon: Run1 - Run0 (å•ä¸€å¾ªç¯)
        run0_path = os.path.join(output_path, run_all_names[0][0], str(year), tran_file_basename)
        if not os.path.exists(run0_path):
            raise FileNotFoundError(f"Base file for carbon cost not found: {run0_path}")

        # --- ä¼˜åŒ–ç‚¹ ---
        # 1. åœ¨å¾ªç¯å¤–æ‰“å¼€ run0 æ–‡ä»¶ä¸€æ¬¡
        # 2. ä½¿ç”¨ .persist() å°†å…¶æ•°æ®åŠ è½½å¹¶â€œé’‰â€åœ¨å†…å­˜ä¸­
        with xr.open_dataset(run0_path, chunks='auto') as ds_A_template:
            ds_A = filter_all_from_dims(ds_A_template)
            ds_A = ds_A.persist()

            for i, run1_name in enumerate(run_all_names[1]):
                output_subdir = cost_names[i]
                run1_path = os.path.join(output_path, run1_name, str(year), tran_file_basename)

                # tprint(f"  -> Processing (carbon): {output_subdir}...")

                # ç°åœ¨ï¼Œds_A ç›´æ¥ä»å†…å­˜ä¸­è¯»å–ï¼Œds_B ä»ç£ç›˜è¯»å–
                with xr.open_dataset(run1_path, chunks='auto') as ds_B:
                    ds_B = filter_all_from_dims(ds_B)
                    tran_cost_diff = ds_B - ds_A  # Run1 - Run0 (ds_Aæ¥è‡ªå†…å­˜)

                # ä¿å­˜ç»“æœ
                output_dir = os.path.join(output_path, output_subdir, str(year))
                os.makedirs(output_dir, exist_ok=True)
                output_filename = f"{tran_cost_file}_diff_{output_subdir}_{year}.nc"
                save2nc(tran_cost_diff, os.path.join(output_dir, output_filename))
                tprint(f"  - Saved: {output_filename}")

    elif policy_type == "bio":
        # Bio: Run2 - Run1 (åµŒå¥—å¾ªç¯)
        num_j = int(len(run_all_names[2])/len(run_all_names[1]))
        for i, run1_name in enumerate(run_all_names[1]):
            run1_path = os.path.join(output_path, run1_name, str(year), tran_file_basename)

            # --- ä¼˜åŒ–ç‚¹ ---
            # 1. åœ¨å†…å±‚å¾ªç¯å¼€å§‹å‰ï¼Œæ‰“å¼€ run1 æ–‡ä»¶ä¸€æ¬¡
            # 2. ä½¿ç”¨ .persist() å°†å…¶æ•°æ®åŠ è½½å¹¶â€œé’‰â€åœ¨å†…å­˜ä¸­
            with xr.open_dataset(run1_path, chunks='auto') as ds_A_template:
                ds_A = filter_all_from_dims(ds_A_template)
                ds_A = ds_A.persist()

                for j in range(num_j):
                    index = i * num_j + j
                    output_subdir = cost_names[index]
                    run2_name = run_all_names[2][index]
                    run2_path = os.path.join(output_path, run2_name, str(year), tran_file_basename)

                    # tprint(f"  -> Processing (bio): {output_subdir}...")

                    # ç°åœ¨ï¼Œds_A ç›´æ¥ä»å†…å­˜ä¸­è¯»å–ï¼Œds_B (å³run2) ä»ç£ç›˜è¯»å–
                    with xr.open_dataset(run2_path, chunks='auto') as ds_B:
                        ds_B = filter_all_from_dims(ds_B)
                        tran_cost_diff = ds_B - ds_A  # Run2 - Run1 (ds_Aæ¥è‡ªå†…å­˜)

                    # ä¿å­˜ç»“æœ
                    output_dir = os.path.join(output_path, output_subdir, str(year))
                    os.makedirs(output_dir, exist_ok=True)
                    output_filename = f"{tran_cost_file}_diff_{output_subdir}_{year}.nc"
                    save2nc(tran_cost_diff, os.path.join(output_dir, output_filename))
                    tprint(f"  - Saved: {output_filename}")
    elif policy_type == "counter":
        run0_path = os.path.join(output_path, run_all_names[0][0], str(year), tran_file_basename)

        with xr.open_dataset(run0_path, chunks='auto') as ds_A_template:
            ds_A = filter_all_from_dims(ds_A_template)
            ds_A = ds_A.persist()

            for i, run1_name in enumerate(run_all_names[2]):
                output_subdir = cost_names[i]
                run1_path = os.path.join(output_path, run1_name, str(year), tran_file_basename)

                with xr.open_dataset(run1_path, chunks='auto') as ds_B:
                    ds_B = filter_all_from_dims(ds_B)
                    tran_cost_diff = ds_B - ds_A
                output_dir = os.path.join(output_path, output_subdir, str(year))
                os.makedirs(output_dir, exist_ok=True)
                output_filename = f"{tran_cost_file}_diff_{output_subdir}_{year}.nc"
                save2nc(tran_cost_diff, os.path.join(output_dir, output_filename))
                tprint(f"  - Saved: {output_filename}")
    else:
        raise ValueError(f"Invalid policy_type '{policy_type}'. Use 'carbon' or 'bio'.")

    tprint(f"âœ… All  {tran_cost_file} {policy_type} cost diff calculations complete for year {year}.")
    return

def calculate_env_diff(year, output_path, run_all_names, env_file, policy_type, output_names):
    """
    è®¡ç®—è½¬å‹æˆæœ¬æ–‡ä»¶çš„å·®å€¼ (Run1-Run0 æˆ– Run2-Run1)ã€‚
    ã€ä¼˜åŒ–ç‰ˆã€‘: ä½¿ç”¨ .persist() é¿å…åœ¨å¾ªç¯ä¸­é‡å¤è¯»å–æ–‡ä»¶ï¼Œæé«˜æ€§èƒ½å¹¶å¢å¼ºå¹¶è¡Œç¨³å®šæ€§ã€‚
    """
    # tprint(f"Calculating transition cost diff for {tran_cost_file} {policy_type} in year {year}...")

    env_file_basename = f"{env_file}_{year}.nc"

    if policy_type == "carbon":
        # Carbon: Run1 - Run0 (å•ä¸€å¾ªç¯)
        run0_path = os.path.join(output_path, run_all_names[0][0], str(year), env_file_basename)
        if not os.path.exists(run0_path):
            raise FileNotFoundError(f"Base file for carbon cost not found: {run0_path}")

        # --- ä¼˜åŒ–ç‚¹ ---
        # 1. åœ¨å¾ªç¯å¤–æ‰“å¼€ run0 æ–‡ä»¶ä¸€æ¬¡
        # 2. ä½¿ç”¨ .persist() å°†å…¶æ•°æ®åŠ è½½å¹¶â€œé’‰â€åœ¨å†…å­˜ä¸­
        with xr.open_dataset(run0_path, chunks='auto') as ds_A_template:
            ds_A = filter_all_from_dims(ds_A_template)
            ds_A = ds_A.persist()

            for i, run1_name in enumerate(run_all_names[1]):
                output_subdir = output_names[i]
                run1_path = os.path.join(output_path, run1_name, str(year), env_file_basename)

                # tprint(f"  -> Processing (carbon): {output_subdir}...")

                # ç°åœ¨ï¼Œds_A ç›´æ¥ä»å†…å­˜ä¸­è¯»å–ï¼Œds_B ä»ç£ç›˜è¯»å–
                with xr.open_dataset(run1_path, chunks='auto') as ds_B:
                    ds_B = filter_all_from_dims(ds_B)
                    env_diff = ds_B - ds_A  # Run1 - Run0 (ds_Aæ¥è‡ªå†…å­˜)
                    if 'biodiversity_GBF2_priority' not in env_file:
                        env_diff = -env_diff

                # ä¿å­˜ç»“æœ
                output_dir = os.path.join(output_path, output_subdir, str(year))
                os.makedirs(output_dir, exist_ok=True)
                output_filename = f"{env_file}_{output_subdir}_{year}.nc"
                save2nc(env_diff, os.path.join(output_dir, output_filename))
                tprint(f"  - Saved: {output_filename}")

    elif policy_type == "bio":
        # Bio: Run2 - Run1 (åµŒå¥—å¾ªç¯)
        num_j = int(len(run_all_names[2])/len(run_all_names[1]))
        for i, run1_name in enumerate(run_all_names[1]):
            run1_path = os.path.join(output_path, run1_name, str(year), env_file_basename)

            # --- ä¼˜åŒ–ç‚¹ ---
            # 1. åœ¨å†…å±‚å¾ªç¯å¼€å§‹å‰ï¼Œæ‰“å¼€ run1 æ–‡ä»¶ä¸€æ¬¡
            # 2. ä½¿ç”¨ .persist() å°†å…¶æ•°æ®åŠ è½½å¹¶â€œé’‰â€åœ¨å†…å­˜ä¸­
            with xr.open_dataset(run1_path, chunks='auto') as ds_A_template:
                ds_A = filter_all_from_dims(ds_A_template)
                ds_A = ds_A.persist()

                for j in range(num_j):
                    index = i * num_j + j
                    output_subdir = output_names[index]
                    run2_name = run_all_names[2][index]
                    run2_path = os.path.join(output_path, run2_name, str(year), env_file_basename)

                    # tprint(f"  -> Processing (bio): {output_subdir}...")

                    # ç°åœ¨ï¼Œds_A ç›´æ¥ä»å†…å­˜ä¸­è¯»å–ï¼Œds_B (å³run2) ä»ç£ç›˜è¯»å–
                    with xr.open_dataset(run2_path, chunks='auto') as ds_B:
                        ds_B = filter_all_from_dims(ds_B)
                        env_diff = ds_B - ds_A  # Run1 - Run0 (ds_Aæ¥è‡ªå†…å­˜)
                        if 'biodiversity_GBF2_priority' not in env_file:
                            env_diff = -env_diff

                    # ä¿å­˜ç»“æœ
                    output_dir = os.path.join(output_path, output_subdir, str(year))
                    os.makedirs(output_dir, exist_ok=True)
                    output_filename = f"{env_file}_{output_subdir}_{year}.nc"
                    save2nc(env_diff, os.path.join(output_dir, output_filename))
                    tprint(f"  - Saved: {output_filename}")
    elif policy_type == "counter":
        run0_path = os.path.join(output_path, run_all_names[0][0], str(year), env_file_basename)

        with xr.open_dataset(run0_path, chunks='auto') as ds_A_template:
            ds_A = filter_all_from_dims(ds_A_template)
            ds_A = ds_A.persist()

            for i, run1_name in enumerate(run_all_names[2]):
                output_subdir = output_names[i]
                run1_path = os.path.join(output_path, run1_name, str(year), env_file_basename)

                with xr.open_dataset(run1_path, chunks='auto') as ds_B:
                    ds_B = filter_all_from_dims(ds_B)
                    env_diff = ds_B - ds_A  # Run1 - Run0 (ds_Aæ¥è‡ªå†…å­˜)
                    if 'biodiversity_GBF2_priority' not in env_file:
                        env_diff = -env_diff
                output_dir = os.path.join(output_path, output_subdir, str(year))
                os.makedirs(output_dir, exist_ok=True)
                output_filename = f"{env_file}_{output_subdir}_{year}.nc"
                save2nc(env_diff, os.path.join(output_dir, output_filename))
                tprint(f"  - Saved: {output_filename}")
    else:
        raise ValueError(f"Invalid policy_type '{policy_type}'. Use 'carbon' or 'bio'.")

    tprint(f"âœ… All  {env_file_basename} {policy_type} cost diff calculations complete for year {year}.")
    return

def aggregate_and_save_cost(year, output_path, cost_names):
    """
    ã€æœ€ç»ˆç‰ˆã€‘èšåˆå•ä¸ªå¹´ä»½çš„æˆæœ¬æ–‡ä»¶ï¼Œä½¿ç”¨ä¸€ä¸ªç²¾ç¡®çš„æ–‡ä»¶åˆ—è¡¨ã€‚
    """

    base_names = [
        'xr_cost_ag',
        'xr_cost_agricultural_management',
        'xr_cost_non_ag',
        'xr_cost_transition_ag2ag_diff',
    ]
    # æ³¨æ„ï¼šä½ çš„è¾“å…¥åå¸¦æœ‰ _diffï¼Œè¿™é‡Œå…¼å®¹å¹¶æ®æ­¤åˆ¤æ–­ am_type
    add_variants = [
        'xr_transition_cost_ag2non_ag_amortised_diff',
        'xr_transition_cost_ag2non_ag_diff',
    ]
    for i in range(len(cost_names)):
        file_dir = os.path.join(output_path, f'{cost_names[i]}', str(year))

        for add_name in add_variants:
            data_type_names_all = base_names + [add_name]

            # 1) å…ˆç”Ÿæˆå…¨è·¯å¾„å¹¶é€ä¸€æ ¡éªŒå­˜åœ¨æ€§ï¼›ç¼ºå“ªä¸ªç«‹å³æŠ¥é”™
            full_paths = [
                os.path.join(file_dir, f'{basename}_{cost_names[i]}_{year}.nc')
                for basename in data_type_names_all
            ]

            # 2) åˆå§‹åŒ–ç´¯åŠ å™¨
            total_sum_ds = None

            # 3) é€ä¸ªæ–‡ä»¶è¯»å– -> é¢„æ£€æŸ¥ -> æ±‚å’Œ -> ç´¯åŠ 

            # 5) ä¿å­˜ï¼šæ ¹æ®æ˜¯å¦åŒ…å« 'amortised' åˆ¤å®š am_type
            am_type = 'amortised' if 'amortised' in add_name else 'original'
            final_path = os.path.join(file_dir, f'xr_total_cost_{cost_names[i]}_{am_type}_{year}.nc')

            for file_path in full_paths:
                tprint(f"Aggregated total cost file: {file_path}")
                with xr.open_dataset(file_path,chunks='auto') as ds:
                    ds = filter_all_from_dims(ds)
                    # å°†é™¤ 'cell' å¤–çš„ç»´åº¦å…¨éƒ¨æ±‚å’Œ
                    sum_dims = [d for d in ds.dims if d != 'cell']
                    summed_single_ds = ds.sum(dim=sum_dims) if sum_dims else ds

                    if total_sum_ds is None:
                        total_sum_ds = summed_single_ds
                    else:
                        total_sum_ds = total_sum_ds + summed_single_ds
                    save2nc(total_sum_ds, final_path)

            tprint(f"Saved aggregated total cost to {final_path}")
    return


def aggregate_and_save_summary(year, output_path, data_type_names, input_files_names, type):
    # 1. ã€å…³é”®ä¿®æ”¹ã€‘æ ¹æ®ä¼ å…¥çš„åˆ—è¡¨æ„å»ºå®Œæ•´çš„æ–‡ä»¶è·¯å¾„
    for i in range(len(input_files_names)):
        tprint(f"Aggregating summary for {input_files_names[i]} in year {year}...")
        input_files_name = input_files_names[i]
        file_dir = os.path.join(output_path, f'{input_files_name}', str(year))

        final_dir = os.path.join(output_path, input_files_name, str(year))
        os.makedirs(final_dir, exist_ok=True)

        # 2. åˆå§‹åŒ–ç´¯åŠ å™¨
        total_sum_ds = None

        # 3. å¾ªç¯å¤„ç†æ¯ä¸€ä¸ªæ–‡ä»¶
        for basename in data_type_names:
            file_path = os.path.join(file_dir, f'{basename}_{input_files_name}_{year}.nc')
            with xr.open_dataset(file_path,chunks='auto') as ds:
                filtered_ds = filter_all_from_dims(ds)
                summed_single_ds = filtered_ds.sum(dim=[d for d in filtered_ds.dims if d != 'cell'])
                if total_sum_ds is None:
                    total_sum_ds = summed_single_ds
                else:
                    total_sum_ds += summed_single_ds

        # 5. ä¿å­˜
        final_path = os.path.join(final_dir, f'xr_total_{type}_{input_files_name}_{year}.nc')
        save2nc(total_sum_ds, final_path)
    return

def calculate_price(input_file, year, base_dir,type,chunks='auto'):
    tprint(f"Processing price {input_file} for year {year}...")

    output_path = os.path.join(base_dir, input_file, str(year), f"xr_{type}_price_{input_file}_{year}.nc")
    cost_path = os.path.join(base_dir, input_file, str(year), f"xr_total_cost_{input_file}_amortised_{year}.nc")
    env_path = os.path.join(base_dir, input_file, str(year), f"xr_total_{type}_{input_file}_{year}.nc")

    with xr.open_dataarray(cost_path, chunks=chunks) as cost_da, xr.open_dataarray(env_path, chunks=chunks) as env_da:
        mask_da = (cost_da >= 1) & (env_da >= 1)
        price_da = cost_da / env_da
        price_da = price_da.where(mask_da, np.nan)
        save2nc(price_da, output_path)

def xarrays_to_tifs(env_cat, file_part, base_dir, tif_dir, data):
    """å¤„ç†ä¸€ä¸ªç±»åˆ«+æ–‡ä»¶éƒ¨åˆ†ï¼Œå¹¶è¾“å‡ºtif"""
    print(f"Processing {env_cat} - {file_part}")

    # æ„é€ è¾“å…¥è·¯å¾„
    if file_part == 'total_cost':
        input_path = f"{base_dir}/{env_cat}/2050/xr_{file_part}_{env_cat}_amortised_2050.nc"
    else:
        input_path = f"{base_dir}/{env_cat}/2050/xr_{file_part}_{env_cat}_2050.nc"

    # è¯»å–å’Œå¤„ç†
    da = xr.open_dataarray(input_path)
    da = da.sum(dim=[d for d in da.dims if d != 'cell'])
    da = da.where(da >= 1)

    # è¾“å‡ºè·¯å¾„
    out_tif = f"{tif_dir}/{env_cat}/xr_{file_part}_{env_cat}_cell_2050.tif"
    os.makedirs(os.path.dirname(out_tif), exist_ok=True)
    nc_to_tif(data, da, out_tif)

    out_tif = f"{tif_dir}/{env_cat}/xr_{file_part}_{env_cat}_area_2050.tif"
    da = da / data.REAL_AREA
    nc_to_tif(data, da, out_tif)

    return out_tif

def subtract_tifs(a_path, b_path, out_path):
    with rasterio.open(a_path) as A, rasterio.open(b_path) as B:
        # 1) åŸºæœ¬ä¸€è‡´æ€§æ£€æŸ¥
        if (A.width, A.height) != (B.width, B.height) or A.transform != B.transform or A.crs != B.crs:
            raise ValueError("è¾“å…¥å½±åƒçš„å¤§å°/transform/CRS ä¸ä¸€è‡´ï¼Œè¯·å…ˆé‡é‡‡æ ·/é‡æŠ•å½±å¯¹é½ã€‚")

        # 2) è¯»ä¸º masked arrayï¼ˆä¼šè‡ªåŠ¨å°† nodata å±è”½ï¼‰ï¼Œå†è½¬ä¸ºå« NaN çš„æ•°ç»„
        arr_a = A.read(1, masked=True).filled(np.nan).astype(np.float32)
        arr_b = B.read(1, masked=True).filled(np.nan).astype(np.float32)

        arr_a[arr_a < 0] = np.nan
        arr_b[arr_b < 0] = np.nan

        # 3) ç›¸å‡
        out = arr_a - arr_b

        # 4) å°† <0 çš„ç»“æœç½®ä¸º NaNï¼ˆå…¶ä»–ä½ç½®åŸæœ¬çš„ NaN å°†è‡ªåŠ¨ä¿ç•™ï¼‰
        out[out <= 0] = np.nan

        # 5) å†™å‡ºï¼ˆFloat32 + LZW å‹ç¼©ï¼›nodata è®¾ä¸º NaNï¼‰
        nodata_value = -9999
        profile = A.profile.copy()
        profile.update(dtype="float32", compress="lzw", nodata=nodata_value)
        out = np.where(np.isnan(out), nodata_value, out)

        with rasterio.open(out_path, "w", **profile) as dst:
            dst.write(out, 1)

def create_shp(env_cat, shp_name, file_parts, tif_dir):
    for file_part in file_parts:
        tif_env_dir = os.path.join(tif_dir, env_cat)
        input_tif_name = f'xr_{file_part}_{env_cat}_2050.tif'
        out_shp = os.path.join(tif_env_dir, f'{shp_name}', f'{shp_name}_{file_part}_{env_cat}_2050.shp')
        os.makedirs(os.path.dirname(out_shp), exist_ok=True)
        shp_path = f"../Map/{shp_name}.shp"
        zonal_stats_rasterized(tif_env_dir, input_tif_name, shp_path, out_shp)

def zonal_stats_rasterized(input_tif_dir, input_tif_name, shp_path, out_shp,
                           extra_nodata_vals=(-9999.0,), drop_allnan=True):
    # 1) è¯» shp ä¸ tif
    gdf = gpd.read_file(shp_path)
    input_tif = os.path.join(input_tif_dir, input_tif_name)

    with rasterio.open(input_tif) as src:
        img_m = src.read(1, masked=True)  # MaskedArrayï¼ˆè‹¥ nodata æœªè®¾ç½®ï¼Œmask å¯èƒ½æ— æ•ˆï¼‰
        transform = src.transform
        shape = (src.height, src.width)
        if gdf.crs is not None and src.crs is not None and gdf.crs != src.crs:
            gdf = gdf.to_crs(src.crs)

    n_shapes = len(gdf)

    # 2) å°†æ©è†œä¸å“¨å…µå€¼ç»Ÿä¸€è½¬ä¸º NaN
    arr = img_m.filled(np.nan).astype('float64', copy=False)
    for nd in (extra_nodata_vals or ()):
        arr[np.isclose(arr, nd)] = np.nan

    # 3) æ …æ ¼åŒ–çŸ¢é‡ï¼šåƒå…ƒå€¼=1..n_shapesï¼›0 ä¸ºèƒŒæ™¯
    shapes = ((geom, i + 1) for i, geom in enumerate(gdf.geometry))
    id_arr = rasterize(shapes, out_shape=shape, transform=transform, fill=0, dtype="int32")

    # 4) åªç»Ÿè®¡æœ‰æ•ˆåƒå…ƒï¼ˆåŒºåŸŸå†… ä¸” é NaNï¼‰
    valid_mask = (id_arr > 0) & np.isfinite(arr)
    if not np.any(valid_mask):
        if drop_allnan:
            print("âš ï¸ æ‰€æœ‰å¤šè¾¹å½¢å‡æ— æœ‰æ•ˆåƒå…ƒï¼Œæœªè¾“å‡ºã€‚")
            return
        # ä¸åˆ é™¤åˆ™å†™å‡ºå…¨ NaN çš„ç»“æœ
        gdf["sum"] = np.nan
        gdf["mean"] = np.nan
        gdf.to_file(out_shp)
        print(f"âœ… Saved {out_shp} (all NaN)")
        return

    vals = arr[valid_mask]
    ids = id_arr[valid_mask]

    # 5) åˆ†ç»„èšåˆ
    sum_per_id = np.bincount(ids, weights=vals, minlength=n_shapes + 1)
    cnt_per_id = np.bincount(ids, minlength=n_shapes + 1)

    sum_stat = sum_per_id[1:]
    cnt_stat = cnt_per_id[1:]

    mean_stat = np.full_like(sum_stat, np.nan, dtype="float64")
    np.divide(sum_stat, cnt_stat, out=mean_stat, where=cnt_stat > 0)

    if 'total_carbon' in input_tif_name:
        sum_stat = sum_stat / 1e6
        mean_stat = mean_stat / 1e6

    # 6) èµ‹å€¼åˆ° gdf
    gdf["sum"] = sum_stat
    gdf["mean"] = mean_stat
    gdf["count"] = cnt_stat  # æ–¹ä¾¿ç­›é€‰

    # 7) ï¼ˆæ–°å¢ï¼‰åˆ é™¤å…¨ NaNï¼ˆå³ count==0ï¼‰çš„è¦ç´ 
    if drop_allnan:
        before = len(gdf)
        gdf = gdf[gdf["count"] > 0].copy()
        removed = before - len(gdf)
        print(f"ğŸ§¹ ç§»é™¤äº† {removed} ä¸ªå…¨ NaN çš„å¤šè¾¹å½¢ã€‚")

        if gdf.empty:
            print("âš ï¸ è¿‡æ»¤åæ— è¦ç´ ï¼Œæœªè¾“å‡ºã€‚")
            return

    # å¯é€‰ï¼šä¸æƒ³ä¿ç•™ count å­—æ®µå°±æ³¨é‡Šæ‰ä¸‹ä¸€è¡Œ
    # gdf = gdf.drop(columns=["count"])

    # 8) è¾“å‡º
    gdf.to_file(out_shp)
    print(f"âœ… Saved {out_shp}ï¼ˆå…± {len(gdf)} ä¸ªè¦ç´ ï¼‰")

def main(task_dir, njobs):
    # ============================================================================
    output_path = f'{task_dir}/carbon_price/0_base_data'
    os.makedirs(output_path, exist_ok=True)
    tprint(f"ä»»åŠ¡ç›®å½•: {task_dir}")

    area_files = ['xr_area_agricultural_landuse', 'xr_area_agricultural_management','xr_area_non_agricultural_landuse']
    cost_files = ['xr_cost_ag', 'xr_cost_agricultural_management', 'xr_cost_non_ag', 'xr_cost_transition_ag2ag',
                  'xr_transition_cost_ag2non_ag']
    revenue_files = ['xr_revenue_ag', 'xr_revenue_agricultural_management', 'xr_revenue_non_ag']
    carbon_files = ['xr_GHG_ag', 'xr_GHG_ag_management', 'xr_GHG_non_ag', 'xr_transition_GHG']
    bio_files = ['xr_biodiversity_GBF2_priority_ag', 'xr_biodiversity_GBF2_priority_ag_management',
                 'xr_biodiversity_GBF2_priority_non_ag']
    amortize_files = ['xr_transition_cost_ag2non_ag']
    economic_files = config.economic_files
    env_files = carbon_files + bio_files

    # carbon_files_diff = ['xr_GHG_ag_diff', 'xr_GHG_ag_management', 'xr_GHG_non_ag', 'xr_transition_GHG']
    # bio_files_diff = ['xr_biodiversity_GBF2_priority_ag_diff', 'xr_biodiversity_GBF2_priority_ag_management',
    #                   'xr_biodiversity_GBF2_priority_non_ag']
    # env_files_diff = carbon_files_diff + bio_files_diff


    input_files_0 = config.input_files_0
    input_files_1 = config.input_files_1
    input_files_2 = config.input_files_2
    input_files = input_files_0 + input_files_1 + input_files_2
    run_all_names = [input_files_0, input_files_1, input_files_2]

    carbon_names = config.carbon_names
    carbon_bio_names = config.carbon_bio_names
    counter_carbon_bio_names = config.counter_carbon_bio_names
    output_all_names = carbon_names + carbon_bio_names + counter_carbon_bio_names


    years = get_year(get_path(task_name, input_files[0]))

    # ============================================================================
    # ç¬¬ä¸€æ‰¹ï¼šæ•°æ®é¢„å¤„ç†é˜¶æ®µ (æ‘Šé”€æˆæœ¬è®¡ç®— + æ–‡ä»¶å¤åˆ¶/å·®å¼‚è®¡ç®—)
    # ============================================================================
    start_time = time.time()

    tprint("=" * 80)

    # --- ç¬¬ä¸€æ‰¹ä»»åŠ¡ (æ‹†åˆ†ä¸ºä¸¤ä¸ªç‹¬ç«‹çš„ç»„) ---
    # ----------------------------------------------------------------------------
    # ===========================================================================
    # --- é˜¶æ®µ 1: æ–‡ä»¶å¤„ç† ---
    # tprint("\n--- æ–‡ä»¶copy ---")
    #
    # for i in range(len(run_all_names)):
    #     run_names = run_all_names[i]
    #     for j in range(len(run_names)):
    #         origin_path_name = get_path(task_name, run_names[j])
    #         target_path_name = os.path.join(output_path, run_names[j])
    #         tprint(f"  -> æ­£åœ¨copy: {origin_path_name}")
    #         copy_files = cost_files + revenue_files + carbon_files + bio_files + area_files
    #         # ç›´æ¥è°ƒç”¨å‡½æ•°ï¼Œè€Œä¸æ˜¯ç”¨ delayed åŒ…è£…
    #
    #         # --- 1. å¹¶è¡ŒåŒ–æ–‡ä»¶å¤åˆ¶ (é€»è¾‘ä¸å˜) ---
    #         if copy_files:
    #             for f in copy_files:
    #                 if njobs == 0:
    #                     for year in years:
    #                         copy_single_file(origin_path_name, target_path_name, f, year,dims_to_sum=('source'))
    #                 else:
    #                     Parallel(n_jobs=njobs)(
    #                         delayed(copy_single_file)(origin_path_name, target_path_name, f, year,dims_to_sum=('source'))
    #                         for year in years
    #                     )
    #
    # tprint(f"âœ… æ–‡ä»¶copyä»»åŠ¡å®Œæˆ!")
    #
    # ## --- 1. å¹¶è¡ŒåŒ–æ–‡ä»¶diff in two years for GHG/BIO ag benefit ---
    # for i in range(len(run_all_names)):
    #     run_names = run_all_names[i]
    #     for j in range(len(run_names)):
    #         data_path_name = os.path.join(output_path, run_names[j])
    #         diff_files = ['xr_biodiversity_GBF2_priority_ag', 'xr_GHG_ag']
    #
    #         if diff_files:
    #             for diff_file in diff_files:
    #                 if njobs == 0:
    #                     for year in years[1:]:
    #                         calculate_and_save_single_diff(diff_file, year, data_path_name)
    #                 else:
    #                     Parallel(n_jobs=njobs)(
    #                         delayed(calculate_and_save_single_diff)(diff_file, year, data_path_name)
    #                         for year in years[1:]
    #                     )

    # if njobs == 0:
    #     for i in range(len(input_files)):
    #         data_path_name = os.path.join(output_path, input_files[i])
    #         amortize_costs(data_path_name, amortize_files[0], years, njobs=njobs)
    # else:
    #     Parallel(n_jobs=7, backend="loky")(
    #         delayed(amortize_costs)(
    #             os.path.join(output_path, run_name),  # data_path_name
    #             amortize_files[0],  # ä½ çš„ç¬¬äºŒä¸ªå‚æ•°
    #             years,
    #             njobs=math.ceil(njobs/7)  # ä¼ ç»™å†…éƒ¨çš„å¹¶è¡Œå‚æ•°ï¼ˆè‹¥æœ‰ï¼‰
    #         )
    #         for run_name in input_files
    #     )
    # tprint("æ‘Šé”€æˆæœ¬è®¡ç®— å®Œæˆ!")
    #
    ##--- é˜¶æ®µ 2: carbon & bioè®¡ç®— ---
    if njobs == 0:
        for env_file in env_files:
            for year in years[1:]:
                calculate_env_diff(year, output_path, run_all_names, env_file, 'carbon', carbon_names)
                calculate_env_diff(year, output_path, run_all_names, env_file, 'bio', carbon_bio_names)
                calculate_env_diff(year, output_path, run_all_names, env_file, 'counter', counter_carbon_bio_names)
    else:
        for env_file in env_files:
            Parallel(n_jobs=njobs)(
                delayed(calculate_env_diff)(year, output_path, run_all_names, env_file, 'carbon', carbon_names)
                for year in years[1:]
            )
            Parallel(n_jobs=njobs)(
                delayed(calculate_env_diff)(year, output_path, run_all_names, env_file, 'bio', carbon_bio_names)
                for year in years[1:]
            )
            Parallel(n_jobs=njobs)(
                delayed(calculate_env_diff)(year, output_path, run_all_names, env_file, 'counter', counter_carbon_bio_names)
                for year in years[1:]
            )

    tprint("\n--- é˜¶æ®µ 2: æ±‡æ€»carbon & bioè®¡ç®— ---")
    if njobs == 0:
        for year in years[1:]:
            # ç›´æ¥è°ƒç”¨
            aggregate_and_save_summary(year, output_path, carbon_files, output_all_names,'carbon')
            aggregate_and_save_summary(year, output_path, bio_files, output_all_names,'bio')
    else:
        Parallel(n_jobs=njobs)(
            delayed(aggregate_and_save_summary)(year, output_path, carbon_files, output_all_names,'carbon')
            for year in years[1:]
        )
        Parallel(n_jobs=njobs)(
            delayed(aggregate_and_save_summary)(year, output_path, bio_files, output_all_names,'bio')
            for year in years[1:]
        )

    tprint(f"âœ… ç¬¬2æ‰¹ä»»åŠ¡æ±‡æ€»carbon & bioå®Œæˆ! ")

    # --- é˜¶æ®µ 3: åˆ©æ¶¦è®¡ç®— ---
    # tprint("\n--- é˜¶æ®µ 3: åˆ©æ¶¦è®¡ç®— ---")
    # profit_categories = zip(cost_files, revenue_files)
    # for cost_base, rev_base in profit_categories:
    #     if njobs == 0:
    #         for run_names in run_all_names:
    #             for run_name in run_names:
    #                 for year in years:
    #                     # ç›´æ¥è°ƒç”¨
    #                     calculate_profit_for_run(year, output_path, run_name, cost_base, rev_base)
    #     else:
    #         for run_names in run_all_names:
    #             for run_name in run_names:
    #                 Parallel(n_jobs=njobs)(
    #                     delayed(calculate_profit_for_run)(year, output_path, run_name, cost_base, rev_base)
    #                     for year in years
    #                 )
    # tprint(f"âœ… ç¬¬3æ‰¹ä»»åŠ¡å®Œæˆ!")
    #
    # ##--- é˜¶æ®µ 4: æ”¿ç­–æˆæœ¬è®¡ç®— ---
    # tprint("\n--- é˜¶æ®µ 4: æ”¿ç­–æˆæœ¬è®¡ç®— ---")
    # category_costs = ['ag', 'agricultural_management', 'non_ag']
    # for category in category_costs:
    #     if njobs == 0:
    #         for year in years[1:]:
    #             # ç›´æ¥è°ƒç”¨
    #             calculate_policy_cost(year, output_path, run_all_names, category, 'carbon',carbon_names)
    #             calculate_policy_cost(year, output_path, run_all_names, category, 'bio', carbon_bio_names)
    #             calculate_policy_cost(year, output_path, run_all_names, category, 'counter', counter_carbon_bio_names)
    #     else:
    #         Parallel(n_jobs=njobs)(
    #             delayed(calculate_policy_cost)(year, output_path, run_all_names, category, 'carbon', carbon_names)
    #             for year in years[1:]
    #         )
    #         Parallel(n_jobs=njobs)(
    #             delayed(calculate_policy_cost)(year, output_path, run_all_names, category, 'bio', carbon_bio_names)
    #             for year in years[1:]
    #         )
    #         Parallel(n_jobs=njobs)(
    #             delayed(calculate_policy_cost)(year, output_path, run_all_names, category, 'counter', counter_carbon_bio_names)
    #             for year in years[1:]
    #         )
    # tprint(f"âœ… ç¬¬4æ‰¹ä»»åŠ¡å®Œæˆ! ")
    #
    # --- é˜¶æ®µ 5: è½¬å‹æˆæœ¬å·®å€¼è®¡ç®— (ä»…ç‹¬ç«‹éƒ¨åˆ†) ---
    # tprint("\n--- é˜¶æ®µ 5: è½¬å‹æˆæœ¬å·®å€¼è®¡ç®— ---")
    # independent_tran_files = ['xr_cost_transition_ag2ag', 'xr_transition_cost_ag2non_ag',
    #                           'xr_transition_cost_ag2non_ag_amortised']
    # for tran_file in independent_tran_files:
    #     tprint(f"Processing transition cost file: {tran_file}...")
    #     if njobs == 0:
    #         for year in years[1:]:
    #             # ç›´æ¥è°ƒç”¨
    #             calculate_transition_cost_diff(year, output_path, run_all_names, tran_file, 'carbon', carbon_names)
    #             calculate_transition_cost_diff(year, output_path, run_all_names, tran_file, 'bio', carbon_bio_names)
    #             calculate_transition_cost_diff(year, output_path, run_all_names, tran_file, 'counter', counter_carbon_bio_names)
    #     else:
    #         Parallel(n_jobs=math.ceil(njobs/2))(
    #             delayed(calculate_transition_cost_diff)(year, output_path, run_all_names, tran_file, 'carbon', carbon_names)
    #             for year in years[1:]
    #         )
    #         Parallel(n_jobs=math.ceil(njobs/2))(
    #             delayed(calculate_transition_cost_diff)(year, output_path, run_all_names, tran_file, 'bio', carbon_bio_names)
    #             for year in years[1:]
    #         )
    #         Parallel(n_jobs=math.ceil(njobs/2))(
    #             delayed(calculate_transition_cost_diff)(year, output_path, run_all_names, tran_file, 'counter', counter_carbon_bio_names)
    #             for year in years[1:]
    #         )
    # tprint(f"âœ… ç¬¬5æ‰¹ è½¬å‹æˆæœ¬å·®å€¼è®¡ç®— ä»»åŠ¡å®Œæˆ! ")

    # # --- é˜¶æ®µ 6: æˆæœ¬èšåˆ ---
    # tprint("\n--- é˜¶æ®µ 6: æˆæœ¬èšåˆ ---")
    #
    # if njobs == 0:
    #     for year in years[1:]:
    #         # ç›´æ¥è°ƒç”¨
    #         aggregate_and_save_cost(year, output_path,carbon_names)
    #         aggregate_and_save_cost(year, output_path,carbon_bio_names)
    #         aggregate_and_save_cost(year, output_path,counter_carbon_bio_names)
    # else:
    #     Parallel(n_jobs=njobs)(
    #         delayed(aggregate_and_save_cost)(year, output_path, carbon_names)
    #         for year in years[1:]
    #     )
    #     Parallel(n_jobs=njobs)(
    #         delayed(aggregate_and_save_cost)(year, output_path, carbon_bio_names)
    #         for year in years[1:]
    #     )
    #     Parallel(n_jobs=njobs)(
    #         delayed(aggregate_and_save_cost)(year, output_path, counter_carbon_bio_names)
    #         for year in years[1:]
    #     )
    #
    # tprint(f"âœ… ç¬¬6æ‰¹ (æœ€ç»ˆèšåˆ) ä»»åŠ¡å®Œæˆ! ")

    # --- é˜¶æ®µ 7: ä»·æ ¼è®¡ç®— ---
    tprint("\n--- é˜¶æ®µ 7: ä»·æ ¼è®¡ç®— ---")

    if njobs == 0:
        for input_file in output_all_names:
            for year in years[1:]:
                calculate_price(input_file, year, output_path,'carbon')
                calculate_price(input_file, year, output_path,'bio')
    else:
        for input_file in output_all_names:
            Parallel(n_jobs=njobs)(
                delayed(calculate_price)(input_file, year, output_path,'carbon')
                for year in years[1:]
            )
            Parallel(n_jobs=njobs)(
                delayed(calculate_price)(input_file, year, output_path,'bio')
                for year in years[1:]
            )

    tprint(f"âœ… ç¬¬7æ‰¹ ä»·æ ¼è®¡ç®— ä»»åŠ¡å®Œæˆ! ")
   ## ==========================================================================


# ============================================================================
    excel_path = f"../../../output/{config.TASK_NAME}/carbon_price/1_excel"
    os.makedirs(excel_path, exist_ok=True)

    for input_file in input_files:
        print(f"carbon: {input_file}")
        df = summarize_netcdf_to_excel(input_file, years[1:], carbon_files, njobs, 'carbon')
    for input_file in input_files:
        print(f"biodiversity: {input_file}")
        df = summarize_netcdf_to_excel(input_file, years[1:], bio_files, njobs, 'biodiversity')
    for input_file in input_files:
        print(f"economic: {input_file}")
        df = summarize_netcdf_to_excel(input_file, years[1:], economic_files, np.ceil(njobs/2), 'economic')
#
#     # ---------------------------------------make excel 1_cost---------------------------------------
    profit_0_list = []
    for input_file in input_files_0:
        profit_0_list.append(create_profit_for_cost(excel_path, input_file))
    profit_1_list = []
    for input_file in input_files_1:
        profit_1_list.append(create_profit_for_cost(excel_path, input_file))
    profit_2_list = []
    for input_file in input_files_2:
        profit_2_list.append(create_profit_for_cost(excel_path, input_file))

    bio_nums = int(len(input_files_2) / len(input_files_1))
    for i in range(len(input_files_1)):
        df = profit_0_list[0] - profit_1_list[i]
        df.columns = df.columns.str.replace('profit', '')
        df['Total'] = df.sum(axis=1)
        df.to_excel(os.path.join(excel_path, f'1_Cost_{carbon_names[i]}.xlsx'))
    for i in range(len(input_files_1)):
        for j in range(bio_nums):
            idx = i * bio_nums + j
            df = profit_1_list[i] - profit_2_list[idx]
            df.columns = df.columns.str.replace('profit', '')
            df['Total'] = df.sum(axis=1)
            df.to_excel(os.path.join(excel_path, f'1_Cost_{carbon_bio_names[idx]}.xlsx'))
    for i in range(bio_nums):
        df = profit_2_list[i] - profit_0_list[0]
        df.columns = df.columns.str.replace('profit', '')
        df['Total'] = df.sum(axis=1)
        df.to_excel(os.path.join(excel_path, f'1_Cost_{counter_carbon_bio_names[i]}.xlsx'))

    # -----------------------------------make excel 1_processed carbon/bio---------------------------------------
    for input_file in input_files:
        df = pd.read_excel(os.path.join(excel_path, f'0_Origin_carbon_{input_file}.xlsx'), index_col=0)
        df.columns = df.columns.str.replace(' GHG', '')
        new_rows_list = []

        # ä»ç¬¬äºŒè¡Œå¼€å§‹å¾ªç¯ (ç´¢å¼• i ä» 1 åˆ° df çš„æœ«å°¾)
        for i in range(1, len(df)):
            # å–å‡ºå½“å‰è¡Œå¹¶å–è´Ÿ
            new_row = df.iloc[i].copy()
            new_row = new_row * -1

            # å…³é”®æ­¥éª¤ï¼šæ–°è¡Œçš„ç¬¬ä¸€åˆ— = (åŸå€¼å–è´Ÿ) + (åŸdfä¸­ä¸Šä¸€è¡Œç¬¬ä¸€åˆ—çš„å€¼)
            new_row.iloc[0] = -df.iloc[i, 0] + df.iloc[i - 1, 0]

            # å°†è®¡ç®—å‡ºçš„æ–°è¡Œï¼ˆè¿™æ˜¯ä¸€ä¸ª Seriesï¼‰æ·»åŠ åˆ°åˆ—è¡¨ä¸­
            new_rows_list.append(new_row)

        # ä½¿ç”¨æ”¶é›†åˆ°çš„è¡Œåˆ—è¡¨ä¸€æ¬¡æ€§åˆ›å»ºæ–°çš„ DataFrame
        # è¿™æ ·åšæ¯”åœ¨å¾ªç¯ä¸­åå¤ concat æ›´é«˜æ•ˆ
        new_df = pd.DataFrame(new_rows_list)

        # å°†æ–° DataFrame çš„ç´¢å¼•è®¾ç½®ä¸ºä¸åŸæ•°æ®å¯¹åº”ï¼ˆä» 1 å¼€å§‹ï¼‰
        new_df.index = df.index[1:]
        new_df['Total'] = new_df.sum(axis=1)
        new_df.to_excel(os.path.join(excel_path, f'1_Processed_carbon_{input_file}.xlsx'))

    for input_file in input_files:
        df = pd.read_excel(os.path.join(excel_path, f'0_Origin_biodiversity_{input_file}.xlsx'), index_col=0)
        df.columns = df.columns.str.replace(' biodiversity', '')
        new_rows_list = []

        # ä»ç¬¬äºŒè¡Œå¼€å§‹å¾ªç¯ (ç´¢å¼• i ä» 1 åˆ° df çš„æœ«å°¾)
        for i in range(1, len(df)):
            # å–å‡ºå½“å‰è¡Œå¹¶å–è´Ÿ
            new_row = df.iloc[i].copy()

            new_row.iloc[0] = df.iloc[i, 0] - df.iloc[i - 1, 0]

            # å°†è®¡ç®—å‡ºçš„æ–°è¡Œï¼ˆè¿™æ˜¯ä¸€ä¸ª Seriesï¼‰æ·»åŠ åˆ°åˆ—è¡¨ä¸­
            new_rows_list.append(new_row)

        # ä½¿ç”¨æ”¶é›†åˆ°çš„è¡Œåˆ—è¡¨ä¸€æ¬¡æ€§åˆ›å»ºæ–°çš„ DataFrame
        # è¿™æ ·åšæ¯”åœ¨å¾ªç¯ä¸­åå¤ concat æ›´é«˜æ•ˆ
        new_df = pd.DataFrame(new_rows_list)

        # å°†æ–° DataFrame çš„ç´¢å¼•è®¾ç½®ä¸ºä¸åŸæ•°æ®å¯¹åº”ï¼ˆä» 1 å¼€å§‹ï¼‰
        new_df.index = df.index[1:]
        new_df['Total'] = new_df.sum(axis=1)
        new_df.to_excel(os.path.join(excel_path, f'1_Processed_bio_{input_file}.xlsx'))
#
#
#     # -----------------------------------make excel 2_cost & carbon/bio & average price---------------------------------------
    colnames = ["Change in GHG benefits (Mt CO2e)", "Carbon cost (M AUD$)", "Average Carbon price (AUD$/t CO2e)"]
    if njobs == 0:
        for carbon_name in carbon_names:
            create_summary(carbon_name, years[1:], output_path,'carbon', colnames)
        for carbon_bio_name in carbon_bio_names:
            create_summary(carbon_bio_name, years[1:], output_path,'carbon', colnames)
        for counter_carbon_bio_name in counter_carbon_bio_names:
            create_summary(counter_carbon_bio_name, years[1:], output_path,'carbon', colnames)
    else:
        Parallel(n_jobs=njobs)(
            delayed(create_summary)(carbon_name, years[1:], output_path,'carbon', colnames)
            for carbon_name in carbon_names
        )
        Parallel(n_jobs=njobs)(
            delayed(create_summary)(carbon_bio_name, years[1:], output_path,'carbon', colnames)
            for carbon_bio_name in carbon_bio_names
        )
        Parallel(n_jobs=njobs)(
            delayed(create_summary)(counter_carbon_bio_name, years[1:], output_path,'carbon', colnames)
            for counter_carbon_bio_name in counter_carbon_bio_names
        )

    colnames = ["Change in biodiversity benefits (Mt CO2e)", "Biodiversity cost (M AUD$)",
                "Average Biodiversity price (AUD$/t CO2e)"]
    if njobs == 0:
        for bio_name in carbon_bio_names:
            create_summary(bio_name, years[1:], output_path,'bio', colnames)
        for counter_carbon_bio_name in counter_carbon_bio_names:
            create_summary(counter_carbon_bio_name, years[1:], output_path,'bio', colnames)
    else:
        Parallel(n_jobs=njobs)(
            delayed(create_summary)(bio_name, years[1:], output_path,'bio', colnames)
            for bio_name in carbon_bio_names
        )
        Parallel(n_jobs=njobs)(
            delayed(create_summary)(counter_carbon_bio_name, years[1:], output_path,'bio', colnames)
            for counter_carbon_bio_name in counter_carbon_bio_names
        )

    summarize_to_category(output_all_names, years[1:], carbon_files, 'xr_total_carbon', n_jobs=41)
    summarize_to_category(output_all_names, years[1:], bio_files, 'xr_total_bio', n_jobs=41)

    summarize_to_category(input_files, years[1:], carbon_files, 'xr_total_carbon_original', n_jobs=41,scenario_name=False)
    summarize_to_category(input_files, years[1:], bio_files, 'xr_total_bio_original', n_jobs=41,scenario_name=False)

    profit_da = summarize_to_category(input_files, years[1:], economic_files, 'xr_cost_for_profit', n_jobs=41,scenario_name=False)
    build_profit_and_cost_nc(profit_da, input_files_0, input_files_1, input_files_2, carbon_names, carbon_bio_names,
                             counter_carbon_bio_names)
    make_prices_nc(output_all_names)
    files = ['xr_cost_agricultural_management', 'xr_cost_non_ag', 'xr_transition_cost_ag2non_ag_amortised_diff',
             'xr_GHG_ag_management', 'xr_GHG_non_ag', 'xr_biodiversity_GBF2_priority_ag_management',
             'xr_biodiversity_GBF2_priority_non_ag']
    dim_names = ['am', 'lu', 'To land-use', 'am', 'lu', 'am', 'lu']

    for file, dim_name in zip(files, dim_names):
        summarize_to_type(
            scenarios=output_all_names,
            years=years[1:],
            file=file,
            keep_dim=dim_name,
            output_file=f'{file}',
            var_name='data',
            scale=1e6,
            n_jobs=njobs,
            dtype='float32',
        )

    files = ['xr_area_agricultural_management','xr_area_non_agricultural_landuse',
             'xr_biodiversity_GBF2_priority_ag_management','xr_biodiversity_GBF2_priority_non_ag',
             'xr_GHG_ag_management','xr_GHG_non_ag',
             'xr_cost_agricultural_management', 'xr_cost_non_ag', 'xr_transition_cost_ag2non_ag_amortised']
    dim_names = ['am','lu','am','lu','am','lu','am', 'lu', 'To land-use']

    for file, dim_name in zip(files, dim_names):
        summarize_to_type(
            scenarios=input_files,
            years=years[1:],
            file=file,
            keep_dim=dim_name,
            output_file=f'{file}',
            var_name='data',
            scale=1e6,
            n_jobs=njobs,
            dtype='float32',
            scenario_name=False
        )

    tif_dir = f"../../../output/{config.TASK_NAME}/carbon_price/4_tif"
    data_path = get_data_RES_path(f"../../../output/{config.TASK_NAME}/{input_files_0[0]}/output")

    with gzip.open(data_path, 'rb') as f:
        data = dill.load(f)

    file_parts = ['total_cost', 'cost_ag', 'cost_agricultural_management', 'cost_non_ag', 'cost_transition_ag2ag_diff',
                  'transition_cost_ag2non_ag_amortised_diff', 'total_carbon', 'total_bio', 'bio_price', 'carbon_price']

    tasks = [(env_cat, file_part) for env_cat in output_all_names for file_part in file_parts]

    results = Parallel(n_jobs=njobs)(  # è¿™é‡Œä½ å¯ä»¥æ”¹ n_jobsï¼Œæ¯”å¦‚ 8 æˆ– -1 ç”¨æ‰€æœ‰CPU
        delayed(xarrays_to_tifs)(env_cat, file_part, output_path, tif_dir, data)
        for env_cat, file_part in tasks
    )

    tif_path_1 = os.path.join(tif_dir, 'carbon_high', "xr_carbon_price_carbon_high_2050.tif")
    tif_path_2 = os.path.join(tif_dir, 'Counterfactual_carbon_high_bio_50',
                              f"xr_carbon_price_Counterfactual_carbon_high_bio_50_2050.tif")
    tif_output = os.path.join(tif_dir, 'carbon_high_bio_50', f"xr_carbon_price_carbon_high_bio_50_2050.tif")
    subtract_tifs(tif_path_2, tif_path_1, tif_output)

    # --- é˜¶æ®µ 8: shpè®¡ç®— ---
    tprint("\n--- é˜¶æ®µ 8: shpè®¡ç®— ---")
    shp_names = ['H_1kkm2', 'H_2kkm2', 'H_5kkm2', 'H_100km2']

    for shp_name in shp_names:
        if njobs == 0:
            for env_cat in output_all_names:
                create_shp(env_cat, shp_name, file_parts, tif_dir)
        else:
            Parallel(n_jobs=njobs)(
                delayed(create_shp)(env_cat, shp_name, file_parts, tif_dir)
                for env_cat in output_all_names
            )

    # --- æ€»ç»“ ---
    end_time = time.time()
    total_time = end_time - start_time
    tprint("\n" + "=" * 80)
    tprint("æ‰€æœ‰ä»»åŠ¡å·²æŒ‰é¡ºåºæ‰§è¡Œå®Œæ¯•")
    tprint(f"æ€»æ‰§è¡Œæ—¶é—´: {total_time / 60 / 60:.2f} å°æ—¶ )")
    tprint("=" * 80)
    return

def run(task_dir, njobs):
    save_dir = os.path.join(task_dir, 'carbon_price')
    log_path = os.path.join(save_dir,'log_0_preprocess')
    @LogToFile(log_path)
    def _run():
        # Start recording memory usage
        stop_event = threading.Event()
        memory_thread = threading.Thread(target=log_memory_usage, args=(save_dir, 'a', 1, stop_event))
        memory_thread.start()

        try:
            print('\n')
            main(task_dir, njobs)
        except Exception as e:
            print(f"An error occurred during the simulation: {e}")
            raise e
        finally:
            # Ensure the memory logging thread is stopped
            stop_event.set()
            memory_thread.join()

    return _run()

if __name__ == "__main__":
    task_name = config.TASK_NAME
    njobs = math.ceil(41/1)
    task_dir = f'../../../output/{task_name}'

    run(task_dir, njobs)