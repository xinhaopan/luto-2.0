# --- Standard library ---
import os
import math
import time
import gzip
import threading
from datetime import datetime
from typing import Sequence, Optional, Union, Dict, Tuple, Iterable
import cf_xarray as cfxr

# --- Third-party ---
import numpy as np
import numpy_financial as npf
import pandas as pd
import xarray as xr
import dill
from joblib import Parallel, delayed
import geopandas as gpd
import rasterio
from rasterio.features import rasterize
import io
import zipfile
from threading import Lock
import sys
sys.path.insert(0, "../../../")


# --- Local packages ---
from tools.tools import (
    get_path, get_year, save2nc, filter_all_from_dims, nc_to_tif, get_data_RES
)
from tools.helper_data import (
    summarize_to_type, summarize_to_category, build_profit_and_cost_nc,create_processed_xarray,build_sol_profit_and_cost_nc,
    make_prices_nc, summarize_netcdf_to_excel, create_profit_for_cost, create_summary, make_sol_prices_nc
)
from tools import LogToFile, log_memory_usage
import tools.config as config


def tprint(*args, **kwargs):
    """
    æ‰“å°æ—¶è‡ªåŠ¨åŠ ä¸Šæ—¶é—´æˆ³ (YYYY-MM-DD HH:MM:SS)
    """
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{now}]", *args, **kwargs)
    return

def get_main_data_variable_name(ds: xr.Dataset) -> str:
    """è‡ªåŠ¨ä» xarray.Dataset ä¸­è·å–å”¯ä¸€çš„æ•°æ®å˜é‡åã€‚"""
    data_vars_list = list(ds.data_vars)
    if len(data_vars_list) == 1:
        return data_vars_list[0]
    elif len(data_vars_list) == 0:
        raise ValueError("é”™è¯¯ï¼šæ•°æ®é›†ä¸­ä¸åŒ…å«ä»»ä½•æ•°æ®å˜é‡ã€‚")
    else:
        raise ValueError(f"é”™è¯¯ï¼šæ•°æ®é›†ä¸­åŒ…å«å¤šä¸ªæ•°æ®å˜é‡: {data_vars_list}ã€‚")


def sum_dims_if_exist(
        nc_path: str,
        vars: Optional[Sequence[str]] = None,
        dims=['lm', "source", "Type", "GHG_source", "Cost type", "From water-supply", "To water-supply"],
        engine: Optional[str] = "h5netcdf",
        chunks="auto",
        keep_attrs: bool = True,
        finalize: str = "compute",
        save_inplace: bool = True,
):
    """
    æ‰“å¼€ NetCDF æ–‡ä»¶ï¼Œå¯¹ç»™å®šçš„ç»´åº¦ï¼ˆå¦‚æœè¯¥å˜é‡é‡Œå­˜åœ¨ï¼‰æ‰§è¡Œ sum å½’çº¦ã€‚

    å‚æ•°
    ----
    save_inplace : bool, default=False
        å¦‚æœä¸º Trueï¼Œå¤„ç†åä¿å­˜åˆ°åŸæ–‡ä»¶ï¼›å¦åˆ™è¿”å› Dataset
    """
    import shutil
    import tempfile

    if isinstance(dims, str):
        dims = [dims]

    ds = xr.open_dataset(nc_path, engine=engine, chunks=chunks)

    def _reduce(da: xr.DataArray) -> xr.DataArray:
        present = [d for d in dims if d in da.dims]
        return da.sum(dim=present, keep_attrs=keep_attrs, skipna=True) if present else da

    if vars is None:
        out = ds.map(_reduce)
    else:
        missing = [v for v in vars if v not in ds.data_vars]
        if missing:
            raise KeyError(f"å˜é‡ä¸å­˜åœ¨: {missing}")
        out = ds.copy()
        for v in vars:
            out[v] = _reduce(ds[v])

    if finalize == "compute":
        out = out.compute()
    elif finalize == "persist":
        out = out.persist()

    ds.close()

    # ===== æ–°å¢ï¼šä¿å­˜åˆ°åŸæ–‡ä»¶ =====
    if save_inplace:
        temp_path = nc_path + ".tmp"
        out.to_netcdf(temp_path, engine=engine)
        shutil.move(temp_path, nc_path)
        return nc_path

    return out

def amortize_costs(data_path_name, amortize_file, years, njobs=0, rate=0.07, horizon=60):
    """
    ã€æœ€ç»ˆä¿®å¤ç‰ˆ - é€å¹´è¾“å‡ºã€‘è®¡ç®—æˆæœ¬å‡æ‘Šï¼Œå¹¶ä¸ºæ¯ä¸€å¹´ç”Ÿæˆä¸€ä¸ªç´¯è®¡æˆæœ¬æ–‡ä»¶ã€‚
    1. ä½¿ç”¨ Dask æ„å»ºå®Œæ•´çš„è®¡ç®—å›¾ï¼Œè®¡ç®—å‡ºæ‰€æœ‰å¹´ä»½çš„ç´¯è®¡æ‘Šé”€æˆæœ¬ã€‚
    2. åœ¨ä¿å­˜é˜¶æ®µï¼Œé€šè¿‡å¾ªç¯å’Œåˆ‡ç‰‡ï¼Œä¸ºæ¯ä¸€å¹´å•ç‹¬è§¦å‘è®¡ç®—å¹¶ä¿å­˜ä¸€ä¸ªæ–‡ä»¶ã€‚
    """
    tprint(f"å¼€å§‹è®¡ç®— '{data_path_name}' çš„æ‘Šé”€æˆæœ¬... (é€å¹´è¾“å‡ºæ¨¡å¼)")
    # --- 1. æ•°æ®åŠ è½½ä¸é¢„å¤„ç† (ä¸ä¹‹å‰ç‰ˆæœ¬å®Œå…¨ç›¸åŒ) ---
    file_paths = [os.path.join(data_path_name, f'{year}', f'{amortize_file}_{year}.nc') for year in years]
    existing_files = [p for p in file_paths if os.path.exists(p)]
    if not existing_files: raise FileNotFoundError(
        f"åœ¨è·¯å¾„ {data_path_name} ä¸‹æ‰¾ä¸åˆ°ä»»ä½•ä¸ '{amortize_file}' ç›¸å…³çš„æ–‡ä»¶ã€‚")
    valid_years = sorted([int(path.split('_')[-1].split('.')[0]) for path in existing_files])

    all_costs_ds = xr.open_mfdataset(
        existing_files,
        engine="h5netcdf",  # æ¨èåç«¯
        combine="nested",
        concat_dim="year",
        parallel=False,  # å…³é”®ï¼šé¿å…å¥æŸ„å¹¶å‘é—®é¢˜
        chunks={ "cell":'auto', "year": -1}  # year æ•´å—ã€cell åˆ†å—
    ).assign_coords(year=valid_years)

    cost_variable_name = get_main_data_variable_name(all_costs_ds)
    pv_values_all_years = all_costs_ds[cost_variable_name]

    annual_payments = xr.apply_ufunc(
        lambda x: -1 * npf.pmt(rate, horizon, pv=x.astype(np.float64), fv=0, when='begin'),
        pv_values_all_years,
        dask="parallelized",
        output_dtypes=[np.float32],
    ).astype('float32')

    all_years = annual_payments.year.values  # e.g., np.arange(2010, 2051)
    base_shape = annual_payments.sel(year=all_years[0]).drop_vars('year').shape
    n_years = len(all_years)

    # åˆå§‹åŒ– numpy arrayï¼Œç”¨äºç´¯åŠ æ‰€æœ‰å½±å“
    amortized_matrix = np.zeros((n_years,) + base_shape, dtype=np.float32)
    for source_year in all_years:
        tprint(f"  - å¤„ç†{data_path_name}èµ·å§‹å¹´ä»½ {source_year} ...")
        payment = annual_payments.sel(year=source_year).drop_vars('year').values
        payment = np.nan_to_num(payment, nan=0.0)
        for offset in range(horizon):
            affect_year = source_year + offset
            if affect_year in all_years:
                affect_idx = affect_year - all_years[0]
                amortized_matrix[affect_idx] += payment
    # æ„å»º xarray.DataArrayï¼Œæ·»åŠ åæ ‡ä¿¡æ¯
    coords = {k: v for k, v in annual_payments.coords.items() if k != 'year'}
    coords['year'] = all_years
    dims = ('year',) + tuple(d for d in annual_payments.dims if d != 'year')
    amortized_by_affect_year = xr.DataArray(
        data=amortized_matrix,
        dims=dims,
        coords=coords,
        name='data',
    )
    tprint("start compute...")
    amortized_by_affect_year.compute()
    tprint("compute done.")

    # å…³é—­å¥æŸ„
    all_costs_ds.close()

    # === ä¿å­˜å‡½æ•° ===
    # ä¿å­˜å„å¹´ä»½è¾“å‡º
    if njobs and njobs > 0:
        def _save_one_year(y: int):
            try:
                out_dir = os.path.join(data_path_name, f"{y}")
                os.makedirs(out_dir, exist_ok=True)
                out_path = os.path.join(out_dir, f"{amortize_file}_amortised_{y}.nc")
                tprint(f"  - [thread] ä¿å­˜å¹´ä»½ {y} -> {out_path}")

                da_y = amortized_by_affect_year.sel(year=y)
                ds_y = xr.Dataset({'data': da_y})
                save2nc(ds_y, out_path)
                return f"âœ… å¹´ä»½ {y} å·²ä¿å­˜"
            except Exception as e:
                return f"âŒ å¹´ä»½ {y} å¤±è´¥: {e}"

        results = Parallel(n_jobs=njobs, backend="threading")(
            delayed(_save_one_year)(y) for y in all_years
        )
        for msg in results:
            tprint(msg)

    else:
        for y in all_years:
            out_dir = os.path.join(data_path_name, f"{y}")
            os.makedirs(out_dir, exist_ok=True)
            out_path = os.path.join(out_dir, f"{amortize_file}_amortised_{y}.nc")
            tprint(f"  - ä¿å­˜å¹´ä»½ {y} -> {out_path}")
            da_y = amortized_by_affect_year.sel(year=y)
            ds_y = xr.Dataset({'data': da_y})
            save2nc(ds_y, out_path)
    return

# --- è¾…åŠ©å‡½æ•°ï¼šä¸“é—¨ç”¨äºè®¡ç®—å•ä¸ªæ–‡ä»¶å¯¹çš„å·®å¼‚ï¼Œä»¥ä¾¿å¹¶è¡ŒåŒ– ---
def calculate_and_save_single_diff(diff_file, year, data_path_name):
    """
    è®¡ç®—å¹¶ä¿å­˜å•ä¸ªæ–‡ä»¶å¯¹çš„å·®å¼‚ã€‚
    è¿™ä¸ªå‡½æ•°å°†è¢«å¹¶è¡Œè°ƒç”¨ã€‚
    """
    # 1. æ„é€ ä¸Šä¸€å¹´åº¦å’Œå½“å‰å¹´åº¦çš„æ–‡ä»¶è·¯å¾„
    src_file_0 = os.path.join(data_path_name, str(year),  f"{diff_file}_{year}.nc")
    src_file_1 = os.path.join(data_path_name, f'{year - 1}',  f"{diff_file}_{year-1}.nc")
    tprint(f"Calculating diff for {src_file_0} between years {year-1} and {year}...")

    # 4. æ„é€ ç›®æ ‡è·¯å¾„å¹¶ä¿å­˜
    variable_name = diff_file.replace('.nc', '')
    dst_filename = f"{variable_name}_diff_{year}.nc"
    dst_file = os.path.join(data_path_name, str(year), dst_filename)
    # 2. æ‰“å¼€è¿™å¯¹æ–‡ä»¶
    with xr.open_dataset(src_file_0) as ds_0, xr.open_dataset(src_file_1) as ds_1:
        # 3. è®¡ç®—å·®å¼‚
        ds_0, ds_1 = xr.align(
            ds_0,
            ds_1,
            join='outer',  # ä¿ç•™æ‰€æœ‰åæ ‡ï¼ˆå¹¶é›†ï¼‰
            fill_value=0  # ç¼ºå¤±ä½ç½®å¡«å…… 0
        )
        ds_res = ds_0 - ds_1

    save2nc(ds_res, dst_file)

    return f"  - Success: Calculated and saved diff for {dst_filename}"



def copy_single_file(
        origin_path_name: str,
        target_path_name: str,
        var_prefix: str,  # ä¾‹å¦‚ "xr_cost_ag"
        year: int,
        dims_to_sum=('lm', 'source', 'Type', 'GHG_source', 'Cost type', 'From water-supply', 'To water-supply'),
        engine: str = "h5netcdf",
        chunks="auto",
        allow_missing_2010: bool = True,
) -> str:
    """
    ã€é™é»˜ç‰ˆã€‘å¤åˆ¶å¹¶å¤„ç†å•ä¸ª NetCDF æ–‡ä»¶ï¼Œç§»é™¤äº†æ‰€æœ‰æ—¥å¿—è®°å½•ï¼Œé€‚ç”¨äºå¹¶è¡Œç¯å¢ƒã€‚
    """
    # 1. æ„å»ºæ–‡ä»¶è·¯å¾„
    year_path = os.path.join(origin_path_name, f"out_{year}")
    target_year_path = os.path.join(target_path_name, str(year))
    os.makedirs(target_year_path, exist_ok=True)

    src_file = os.path.join(year_path, f"{var_prefix}_{year}.nc")
    dst_file = os.path.join(target_year_path, f"{var_prefix}_{year}.nc")

    tprint(f"Copying: {os.path.basename(src_file)} to {dst_file}")

    # 2. æ£€æŸ¥æºæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(src_file):
        if allow_missing_2010 and year == 2010:
            tprint( f"Skipped: {os.path.basename(src_file)} (missing but allowed for year 2010)")
            return

    def _reduce_one(da: xr.DataArray) -> xr.DataArray:
        """å¯¹ DataArray ä¸­å­˜åœ¨çš„ç»´åº¦è¿›è¡Œæ±‚å’Œ"""
        if not np.issubdtype(da.dtype, np.number):
            return da

        present_dims = [d for d in dims_to_sum if d in da.dims]

        if present_dims:
            return da.sum(dim=present_dims, keep_attrs=True, skipna=True)
        return da

    with xr.open_dataset(src_file, engine=engine, chunks=chunks) as ds:
        ds = filter_all_from_dims(ds)
        ds_filled = ds.fillna(0)
        out = ds_filled.map(_reduce_one).load()
        save2nc(out, dst_file)
    return f"âœ… Copied: {os.path.basename(src_file)} to {dst_file}"


def extract_files_from_zip(
        zip_path: str,
        copy_files: list,
        years: list,
        allow_missing_2010: bool = True
) -> Dict[Tuple[str, int], bytes]:
    """
    ä» zip æ–‡ä»¶æˆ–ç›®å½•ä¸­æå–æ‰€æœ‰éœ€è¦çš„æ–‡ä»¶åˆ°å†…å­˜

    å‚æ•°:
        zip_path: zipæ–‡ä»¶è·¯å¾„ æˆ– å·²è§£å‹çš„ç›®å½•è·¯å¾„
        copy_files: éœ€è¦å¤åˆ¶çš„æ–‡ä»¶å‰ç¼€åˆ—è¡¨
        years: å¹´ä»½åˆ—è¡¨
        allow_missing_2010: æ˜¯å¦å…è®¸2010å¹´æ–‡ä»¶ç¼ºå¤±

    è¿”å›: {(var_prefix, year): file_bytes} å­—å…¸
    """
    files_dict = {}

    # åˆ¤æ–­æ˜¯zipæ–‡ä»¶è¿˜æ˜¯ç›®å½•
    if os.path.isfile(zip_path) and zipfile.is_zipfile(zip_path):
        # æƒ…å†µ1: æ˜¯zipæ–‡ä»¶ï¼ŒæŒ‰åŸé€»è¾‘å¤„ç†
        tprint(f"Extracting all files from {os.path.basename(zip_path)}...")
        with zipfile.ZipFile(zip_path, 'r') as zf:
            all_names = set(zf.namelist())

            for var_prefix in copy_files:
                for year in years:
                    src_file_in_zip = f"out_{year}/{var_prefix}_{year}.nc"

                    if src_file_in_zip in all_names:
                        files_dict[(var_prefix, year)] = zf.read(src_file_in_zip)
                        tprint(f"  Extracted: {src_file_in_zip}")
                    elif allow_missing_2010 and year == 2010:
                        tprint(f"  Skipped: {src_file_in_zip} (missing but allowed)")
                        files_dict[(var_prefix, year)] = None  # æ ‡è®°ä¸ºè·³è¿‡
                    else:
                        tprint(f"  Warning: {src_file_in_zip} not found")
                        files_dict[(var_prefix, year)] = None

    elif os.path.isdir(zip_path):
        # æƒ…å†µ2: æ˜¯å·²è§£å‹çš„ç›®å½•ï¼Œç›´æ¥è¯»å–æ–‡ä»¶
        tprint(f"Reading files from directory {os.path.basename(zip_path)}...")

        for var_prefix in copy_files:
            for year in years:
                src_file_path = os.path.join(zip_path, f"out_{year}", f"{var_prefix}_{year}.nc")

                if os.path.exists(src_file_path):
                    with open(src_file_path, 'rb') as f:
                        files_dict[(var_prefix, year)] = f.read()
                    tprint(f"  Read: out_{year}/{var_prefix}_{year}.nc")
                elif allow_missing_2010 and year == 2010:
                    tprint(f"  Skipped: out_{year}/{var_prefix}_{year}.nc (missing but allowed)")
                    files_dict[(var_prefix, year)] = None  # æ ‡è®°ä¸ºè·³è¿‡
                else:
                    tprint(f"  Warning: out_{year}/{var_prefix}_{year}.nc not found")
                    files_dict[(var_prefix, year)] = None

    else:
        raise ValueError(f"Invalid path: {zip_path} is neither a valid zip file nor a directory")

    tprint(f"Extraction complete: {sum(1 for v in files_dict.values() if v is not None)} files loaded")
    return files_dict


def reduce_layered_da(
    da: xr.DataArray,
    dims_to_sum: Sequence[str],
    layer_dim: str = "layer",
    keep_attrs: bool = True,
    skipna: bool = True,
    layer_level_order: Optional[Iterable[str]] = None,
) -> xr.DataArray:
    """
    è¾“å…¥ï¼šda dims é€šå¸¸ä¸º ('cell','layer')ï¼Œä¸” layer æ˜¯ MultiIndexï¼ˆæˆ–å¯ç”± layer-level coords ä¸¥æ ¼é‡å»ºï¼‰
    è¾“å‡ºï¼šä»ä¸º ('cell','layer')ï¼Œå¹¶ä¿æŒ layer ä¸º MultiIndexï¼ˆå¤šçº§ç´¢å¼•åæ ‡å¯æ¢å¤ã€å¯ selï¼‰

    ä¸ä½¿ç”¨ tryï¼›æ— æ³• unstack å°±ç›´æ¥æŠ¥é”™ã€‚
    """

    def _ensure_layer_multiindex_strict(
            da: xr.DataArray,
            layer_dim: str = "layer",
            level_order: Optional[Iterable[str]] = None,
    ) -> xr.DataArray:
        """
        ä¸¥æ ¼ç¡®ä¿ da çš„ layer æ˜¯ MultiIndexã€‚
        è§„åˆ™ï¼š
        - å¦‚æœ layer å·²ç»æ˜¯ MultiIndexï¼šç›´æ¥è¿”å›
        - å¦åˆ™è¦æ±‚å­˜åœ¨ coords(dims=(layer,)) çš„ level å˜é‡ï¼ˆå¦‚ am/lm/lu/source...ï¼‰
          ç”¨ set_index(layer=[...]) æ„é€  MultiIndex
        - å¦‚æœæ²¡æœ‰ level å˜é‡ï¼šç›´æ¥æŠ¥é”™ï¼ˆå› ä¸ºæ— æ³•è¿˜åŸï¼‰
        """
        if layer_dim not in da.dims:
            return da

        idx = da.indexes.get(layer_dim, None)
        if isinstance(idx, pd.MultiIndex):
            return da

        layer_level_vars = [
            c for c in da.coords
            if c != layer_dim and da.coords[c].dims == (layer_dim,)
        ]
        if not layer_level_vars:
            raise ValueError(
                f"'{layer_dim}' is not a MultiIndex and no layer-level coords exist to rebuild it. "
                f"Available coords with dims=('layer',): {layer_level_vars}"
            )

        if level_order is not None:
            level_order = list(level_order)
            layer_level_vars = (
                    [c for c in level_order if c in layer_level_vars]
                    + [c for c in layer_level_vars if c not in level_order]
            )

        return da.set_index({layer_dim: layer_level_vars})

    if not np.issubdtype(da.dtype, np.number):
        return da

    if layer_dim not in da.dims:
        present = [d for d in dims_to_sum if d in da.dims]
        return da.sum(dim=present, keep_attrs=keep_attrs, skipna=skipna) if present else da

    # 1) ä¸¥æ ¼ç¡®ä¿ layer æ˜¯ MultiIndex
    da = _ensure_layer_multiindex_strict(
        da, layer_dim=layer_dim, level_order=layer_level_order
    )

    # 2) unstackï¼šlayer -> å¤šç»´ dims
    da_u = da.unstack(layer_dim)

    # 3) æ±‚å’Œ
    present = [d for d in dims_to_sum if d in da_u.dims]
    if present:
        da_u = da_u.sum(dim=present, keep_attrs=keep_attrs, skipna=skipna)

    # 4) stack å› layerï¼šæŠŠé™¤ cell ä»¥å¤–çš„ dims å…¨éƒ¨ stack
    stack_levels = [d for d in da_u.dims if d != "cell"]
    if layer_level_order is not None:
        layer_level_order = list(layer_level_order)
        stack_levels = (
            [d for d in layer_level_order if d in stack_levels]
            + [d for d in stack_levels if d not in layer_level_order]
        )

    if stack_levels:
        return da_u.stack({layer_dim: stack_levels})

    return da_u


def process_single_file_from_memory(
    file_bytes: bytes,
    var_prefix: str,
    year: int,
    target_path_name: str,
    dims_to_sum=("lm", "source", "Type", "GHG_source", "Cost type",
                "From water-supply", "To water-supply"),
    engine: str = "h5netcdf",
    chunks="auto",
    layer_level_order=None,
) -> str:
    """
    å¤„ç†å·²ç»åœ¨å†…å­˜ä¸­çš„æ–‡ä»¶ï¼ˆæ— éœ€é”ï¼Œå¯å¹¶è¡Œï¼‰
    - ä¸¥æ ¼ï¼šä¸ä½¿ç”¨ try
    - å¼ºåˆ¶ decode_compress_to_multi_index
    """
    if file_bytes is None:
        return f"â­ï¸ Skipped: {var_prefix}_{year}.nc"

    target_year_path = os.path.join(target_path_name, str(year))
    os.makedirs(target_year_path, exist_ok=True)
    dst_file = os.path.join(target_year_path, f"{var_prefix}_{year}.nc")

    tprint(f"Processing: {var_prefix}_{year}.nc")

    with io.BytesIO(file_bytes) as bio:
        with xr.open_dataset(bio, engine=engine, chunks=chunks) as ds:
            # âœ… å…³é”®ï¼šå…ˆ decodeï¼ˆä¸¥æ ¼ï¼Œä¸ç”¨ tryï¼›decode å¤±è´¥å°±ç›´æ¥æŠ¥é”™ï¼‰
            ds = cfxr.decode_compress_to_multi_index(ds, "layer")

            # âœ… å† fillna
            ds = ds.fillna(0)

            out_vars = {}
            for v in ds.data_vars:
                da = ds[v]

                da = filter_all_from_dims(
                    da,
                    layer_dim="layer",
                    strict_layer_multiindex=True,
                    layer_level_order=layer_level_order,
                )

                da = reduce_layered_da(
                    da,
                    dims_to_sum=dims_to_sum,
                    layer_dim="layer",
                    keep_attrs=True,
                    skipna=True,
                    layer_level_order=layer_level_order,
                )

                out_vars[v] = da

            out = xr.Dataset(out_vars, attrs=ds.attrs).load()
            if 'layer' in out.dims:
                idx = out.indexes.get('layer')
                if isinstance(idx, pd.MultiIndex):
                    # ä¾‹å¦‚ï¼šlayer(lu, lm) â†’ å˜æˆ lu Ã— lm ä¸¤ä¸ªç‹¬ç«‹ç»´åº¦
                    out = out.unstack('layer')

    save2nc(out["data"] if "data" in out.data_vars else out[list(out.data_vars)[0]], dst_file)
    sum_dims_if_exist(dst_file)
    return f"âœ… Processed: {var_prefix}_{year}.nc"

# ==============================================================================
# STAGE 1: è®¡ç®—åˆ©æ¶¦ (Profit = Revenue - Cost)
# ==============================================================================
def calculate_profit_for_run(year, out_path, run_name, cost_basename, revenue_basename):
    """
    ä¸ºå•ä¸ªæƒ…æ™¯(Run)å’Œå•ä¸ªç±»åˆ«è®¡ç®—åˆ©æ¶¦ã€‚
    """
    tprint(f"{out_path}/{run_name}/{year}: è®¡ç®—åˆ©æ¶¦...")
    # æ„å»ºè¾“å…¥æ–‡ä»¶è·¯å¾„
    cost_file = os.path.join(out_path, run_name, str(year), f'{cost_basename}_{year}.nc')
    revenue_file = os.path.join(out_path, run_name, str(year), f'{revenue_basename}_{year}.nc')

    # ä½¿ç”¨ with è¯­å¥ç¡®ä¿æ–‡ä»¶æ­£ç¡®å…³é—­
    with xr.open_dataset(cost_file,chunks='auto') as ds_cost, \
            xr.open_dataset(revenue_file,chunks='auto') as ds_revenue:
        # 1. åº”ç”¨æ‚¨è‡ªå®šä¹‰çš„è¿‡æ»¤å™¨
        ds_revenue_processed = filter_all_from_dims(ds_revenue)
        ds_cost_processed = filter_all_from_dims(ds_cost)

        # 2. å¡«å…… NaN å€¼
        ds_revenue_filled = ds_revenue_processed.fillna(0)
        ds_cost_filled = ds_cost_processed.fillna(0)

        # --- ã€å…³é”®ä¿®æ­£ã€‘ æ£€æŸ¥ 'source' ç»´åº¦æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœå­˜åœ¨åˆ™è¿›è¡Œèšåˆ ---

        # å¤„ç† Revenue æ•°æ®é›†
        # ds.dims æ˜¯ä¸€ä¸ªåŒ…å«æ‰€æœ‰ç»´åº¦åç§°çš„ç±»å…ƒç»„å¯¹è±¡
        if 'source' in ds_revenue_filled.dims:
            total_revenue = ds_revenue_filled.sum(dim='source')
        else:
            total_revenue = ds_revenue_filled

        # å¤„ç† Cost æ•°æ®é›†
        if 'source' in ds_cost_filled.dims:
            total_cost = ds_cost_filled.sum(dim='source')
        else:
            total_cost = ds_cost_filled
        total_revenue, total_cost = xr.align(
            total_revenue,
            total_cost,
            join='outer',  # ä¿ç•™æ‰€æœ‰åæ ‡ï¼ˆå¹¶é›†ï¼‰
            fill_value=0  # ç¼ºå¤±ä½ç½®å¡«å…… 0
        )
        profit = total_revenue - total_cost
        profit_out_path = os.path.join(out_path, run_name, str(year))
        os.makedirs(profit_out_path, exist_ok=True)

        # ä¸ºäº†åŒºåˆ†ï¼Œæˆ‘ä»¬ç»™æ–‡ä»¶ååŠ ä¸Š profit å‰ç¼€
        profit_filename = f'xr_profit_{cost_basename.replace("xr_cost_", "")}_{year}.nc'
        save2nc(profit, os.path.join(profit_out_path, profit_filename))

        return f"âœ… Profit: Calculated for {os.path.basename(out_path)}/{profit_filename}"




# ==============================================================================


def calculate_policy_cost(year, output_path, run_all_names, cost_category, policy_type, cost_names):
    """
    åŸºäºåˆ©æ¶¦å·®è®¡ç®—æ”¿ç­–æˆæœ¬ (Carbon æˆ– Bio)ã€‚ã€ä¼˜åŒ–ç‰ˆã€‘
    """
    tprint(f"Calculating policy cost for {policy_type}/{cost_category} in year {year}...")
    profit_file_basename = f'xr_profit_{cost_category}_{year}.nc'

    if policy_type == 'carbon':
        input_all_names_dif = [run_all_names[1], run_all_names[0]]
        caculate_diff_two_scenarios(input_all_names_dif, cost_names, output_path, year, profit_file_basename, f"xr_cost_{cost_category}")

    elif policy_type == 'bio':
        input_all_names_dif = [run_all_names[2], run_all_names[1]]
        caculate_diff_two_scenarios(input_all_names_dif, cost_names, output_path, year, profit_file_basename, f"xr_cost_{cost_category}")

    elif policy_type == 'counter':
        input_all_names_dif = [run_all_names[2], run_all_names[0]]
        caculate_diff_two_scenarios(input_all_names_dif, cost_names, output_path, year, profit_file_basename, f"xr_cost_{cost_category}")

    tprint(f"âœ… All {policy_type} policy cost calculations complete for year {year}.")
    return


def calculate_transition_cost_diff(year, output_path, run_all_names, tran_cost_file, policy_type, cost_names):
    """
    è®¡ç®—è½¬å‹æˆæœ¬æ–‡ä»¶çš„å·®å€¼ (Run1-Run0 æˆ– Run2-Run1)ã€‚
    ã€ä¼˜åŒ–ç‰ˆã€‘: ä½¿ç”¨ .persist() é¿å…åœ¨å¾ªç¯ä¸­é‡å¤è¯»å–æ–‡ä»¶ï¼Œæé«˜æ€§èƒ½å¹¶å¢å¼ºå¹¶è¡Œç¨³å®šæ€§ã€‚
    """
    # tprint(f"Calculating transition cost diff for {tran_cost_file} {policy_type} in year {year}...")

    tran_file_basename = f"{tran_cost_file}_{year}.nc"

    if policy_type == 'carbon':
        input_all_names_dif = [run_all_names[0], run_all_names[1]]
        caculate_diff_two_scenarios(input_all_names_dif, cost_names, output_path, year, tran_file_basename,f"{tran_cost_file}_diff")

    elif policy_type == "bio":
        input_all_names_dif = [run_all_names[1], run_all_names[2]]
        caculate_diff_two_scenarios(input_all_names_dif, cost_names, output_path, year, tran_file_basename,f"{tran_cost_file}_diff")

    elif policy_type == "counter":
        input_all_names_dif = [run_all_names[0], run_all_names[2]]
        caculate_diff_two_scenarios(input_all_names_dif, cost_names, output_path, year, tran_file_basename,f"{tran_cost_file}_diff")
    else:
        raise ValueError(f"Invalid policy_type '{policy_type}'. Use 'carbon' or 'bio'.")

    tprint(f"âœ… All  {tran_cost_file} {policy_type} cost diff calculations complete for year {year}.")
    return


def caculate_diff_two_scenarios(input_all_names, output_names, output_path, year, env_file_basename,output_part_name):

    for i, (run_name_0, run_name_1) in enumerate(zip(input_all_names[0], input_all_names[1])):
        output_subdir = output_names[i]
        run0_path = os.path.join(output_path, run_name_0, str(year), env_file_basename)
        run1_path = os.path.join(output_path, run_name_1, str(year), env_file_basename)

        # ç°åœ¨ï¼Œds_A ç›´æ¥ä»å†…å­˜ä¸­è¯»å–ï¼Œds_B ä»ç£ç›˜è¯»å–
        with xr.open_dataset(run0_path, chunks='auto') as ds_0, xr.open_dataset(run1_path, chunks='auto') as ds_1:
            ds_0 = filter_all_from_dims(ds_0)
            ds_1 = filter_all_from_dims(ds_1)
            ds_0, ds_1 = xr.align(
                ds_0,
                ds_1,
                join='outer',  # ä¿ç•™æ‰€æœ‰åæ ‡ï¼ˆå¹¶é›†ï¼‰
                fill_value=0  # ç¼ºå¤±ä½ç½®å¡«å…… 0
            )
            if 'GHG' in env_file_basename:
                env_diff = ds_0 - ds_1
            else:
                env_diff = ds_1 - ds_0
            env_diff = env_diff.compute()
        # ä¿å­˜ç»“æœ
        output_dir = os.path.join(output_path, output_subdir, str(year))
        os.makedirs(output_dir, exist_ok=True)
        output_filename = f"{output_part_name}_{output_subdir}_{year}.nc"
        save2nc(env_diff, os.path.join(output_dir, output_filename))
        tprint(f"  - Saved: {output_filename}")

def calculate_env_diff(year, output_path, input_all_names, env_file, output_names):
    env_file_basename = f"{env_file}_{year}.nc"
    input_all_names_dif = [input_all_names[0], input_all_names[1]]
    caculate_diff_two_scenarios(input_all_names_dif, output_names[0:10], output_path, year, env_file_basename, env_file)

    input_all_names_dif = [input_all_names[1], input_all_names[2]]
    caculate_diff_two_scenarios(input_all_names_dif, output_names[10:20], output_path, year, env_file_basename, env_file)

    input_all_names_dif = [input_all_names[0], input_all_names[2]]
    caculate_diff_two_scenarios(input_all_names_dif, output_names[20:30], output_path, year, env_file_basename, env_file)
    return

def aggregate_and_save_cost(year, output_path, cost_names):
    """
    ã€æœ€ç»ˆç‰ˆã€‘èšåˆå•ä¸ªå¹´ä»½çš„æˆæœ¬æ–‡ä»¶ï¼Œä½¿ç”¨ä¸€ä¸ªç²¾ç¡®çš„æ–‡ä»¶åˆ—è¡¨ã€‚
    """

    base_names = [
        'xr_cost_ag',
        'xr_cost_agricultural_management',
        'xr_cost_non_ag',
        'xr_cost_transition_ag2ag_diff',
    ]
    # æ³¨æ„ï¼šä½ çš„è¾“å…¥åå¸¦æœ‰ _diffï¼Œè¿™é‡Œå…¼å®¹å¹¶æ®æ­¤åˆ¤æ–­ am_type
    add_variants = [
        'xr_transition_cost_ag2non_ag_amortised_diff',
        'xr_transition_cost_ag2non_ag_diff',
    ]
    for i in range(len(cost_names)):
        file_dir = os.path.join(output_path, f'{cost_names[i]}', str(year))

        for add_name in add_variants:
            data_type_names_all = base_names + [add_name]

            # 1) å…ˆç”Ÿæˆå…¨è·¯å¾„å¹¶é€ä¸€æ ¡éªŒå­˜åœ¨æ€§ï¼›ç¼ºå“ªä¸ªç«‹å³æŠ¥é”™
            full_paths = [
                os.path.join(file_dir, f'{basename}_{cost_names[i]}_{year}.nc')
                for basename in data_type_names_all
            ]

            # 2) åˆå§‹åŒ–ç´¯åŠ å™¨
            total_sum_ds = None

            # 3) é€ä¸ªæ–‡ä»¶è¯»å– -> é¢„æ£€æŸ¥ -> æ±‚å’Œ -> ç´¯åŠ 

            # 5) ä¿å­˜ï¼šæ ¹æ®æ˜¯å¦åŒ…å« 'amortised' åˆ¤å®š am_type
            am_type = 'amortised' if 'amortised' in add_name else 'original'
            final_path = os.path.join(file_dir, f'xr_total_cost_{cost_names[i]}_{am_type}_{year}.nc')

            for file_path in full_paths:
                tprint(f"Aggregated total cost file: {file_path}")
                with xr.open_dataset(file_path,chunks='auto') as ds:
                    ds = filter_all_from_dims(ds)
                    # å°†é™¤ 'cell' å¤–çš„ç»´åº¦å…¨éƒ¨æ±‚å’Œ
                    sum_dims = [d for d in ds.dims if d != 'cell']
                    summed_single_ds = ds.sum(dim=sum_dims) if sum_dims else ds

                    if total_sum_ds is None:
                        total_sum_ds = summed_single_ds
                    else:
                        total_sum_ds, summed_single_ds = xr.align(
                            total_sum_ds,
                            summed_single_ds,
                            join='outer',  # ä¿ç•™æ‰€æœ‰åæ ‡ï¼ˆå¹¶é›†ï¼‰
                            fill_value=0  # ç¼ºå¤±ä½ç½®å¡«å…… 0
                        )
                        total_sum_ds = total_sum_ds + summed_single_ds
            # 5) ä¿å­˜ï¼šæ ¹æ®æ˜¯å¦åŒ…å« 'amortised' åˆ¤å®š am_type
            am_type = 'amortised' if 'amortised' in add_name else 'original'
            final_path = os.path.join(file_dir, f'xr_total_cost_{cost_names[i]}_{am_type}_{year}.nc')

            save2nc(total_sum_ds, final_path)

            tprint(f"Saved aggregated total cost to {final_path}")
    return

def aggregate_and_save_cost_sol(year, output_path, cost_names):
    """
    ã€æœ€ç»ˆç‰ˆã€‘èšåˆå•ä¸ªå¹´ä»½çš„æˆæœ¬æ–‡ä»¶ï¼Œä½¿ç”¨ä¸€ä¸ªç²¾ç¡®çš„æ–‡ä»¶åˆ—è¡¨ã€‚
    """

    base_names = [
        # 'xr_cost_agricultural_management',
        'xr_cost_non_ag',
        'xr_transition_cost_ag2non_ag_amortised_diff',
    ]
    # æ³¨æ„ï¼šä½ çš„è¾“å…¥åå¸¦æœ‰ _diffï¼Œè¿™é‡Œå…¼å®¹å¹¶æ®æ­¤åˆ¤æ–­ am_type

    for i in range(len(cost_names)):
        file_dir = os.path.join(output_path, f'{cost_names[i]}', str(year))

        # 1) å…ˆç”Ÿæˆå…¨è·¯å¾„å¹¶é€ä¸€æ ¡éªŒå­˜åœ¨æ€§ï¼›ç¼ºå“ªä¸ªç«‹å³æŠ¥é”™
        full_paths = [
            os.path.join(file_dir, f'{basename}_{cost_names[i]}_{year}.nc')
            for basename in base_names
        ]

        # 2) åˆå§‹åŒ–ç´¯åŠ å™¨
        total_sum_ds = None

        # 3) é€ä¸ªæ–‡ä»¶è¯»å– -> é¢„æ£€æŸ¥ -> æ±‚å’Œ -> ç´¯åŠ 

        # 5) ä¿å­˜ï¼šæ ¹æ®æ˜¯å¦åŒ…å« 'amortised' åˆ¤å®š am_type
        final_path = os.path.join(file_dir, f'xr_total_sol_cost_{cost_names[i]}_{year}.nc')

        for file_path in full_paths:
            tprint(f"Aggregated total cost file: {file_path}")
            with xr.open_dataset(file_path,chunks='auto') as ds:
                ds = filter_all_from_dims(ds)
                # å°†é™¤ 'cell' å¤–çš„ç»´åº¦å…¨éƒ¨æ±‚å’Œ
                sum_dims = [d for d in ds.dims if d != 'cell']
                summed_single_ds = ds.sum(dim=sum_dims) if sum_dims else ds

                if total_sum_ds is None:
                    total_sum_ds = summed_single_ds
                else:
                    total_sum_ds, summed_single_ds = xr.align(
                        total_sum_ds,
                        summed_single_ds,
                        join='outer',  # ä¿ç•™æ‰€æœ‰åæ ‡ï¼ˆå¹¶é›†ï¼‰
                        fill_value=0  # ç¼ºå¤±ä½ç½®å¡«å…… 0
                    )
                    total_sum_ds = total_sum_ds + summed_single_ds
        save2nc(total_sum_ds, final_path)

        tprint(f"Saved aggregated total cost to {final_path}")
    return

def aggregate_and_save_summary(year, output_path, data_type_names, input_files_names, type):
    # 1. ã€å…³é”®ä¿®æ”¹ã€‘æ ¹æ®ä¼ å…¥çš„åˆ—è¡¨æ„å»ºå®Œæ•´çš„æ–‡ä»¶è·¯å¾„
    for i in range(len(input_files_names)):
        tprint(f"Aggregating summary for {input_files_names[i]} in year {year}...")
        input_files_name = input_files_names[i]
        file_dir = os.path.join(output_path, f'{input_files_name}', str(year))

        final_dir = os.path.join(output_path, input_files_name, str(year))
        os.makedirs(final_dir, exist_ok=True)

        # 2. åˆå§‹åŒ–ç´¯åŠ å™¨
        total_sum_ds = None

        # 3. å¾ªç¯å¤„ç†æ¯ä¸€ä¸ªæ–‡ä»¶
        for basename in data_type_names:
            file_path = os.path.join(file_dir, f'{basename}_{input_files_name}_{year}.nc')
            with xr.open_dataset(file_path,chunks='auto') as ds:
                filtered_ds = filter_all_from_dims(ds)
                summed_single_ds = filtered_ds.sum(dim=[d for d in filtered_ds.dims if d != 'cell'])
                if total_sum_ds is None:
                    total_sum_ds = summed_single_ds
                else:
                    total_sum_ds, summed_single_ds = xr.align(
                        total_sum_ds,
                        summed_single_ds,
                        join='outer',  # ä¿ç•™æ‰€æœ‰åæ ‡ï¼ˆå¹¶é›†ï¼‰
                        fill_value=0  # ç¼ºå¤±ä½ç½®å¡«å…… 0
                    )
                    total_sum_ds += summed_single_ds

        # 5. ä¿å­˜
        final_path = os.path.join(final_dir, f'xr_total_{type}_{input_files_name}_{year}.nc')
        save2nc(total_sum_ds, final_path)
    return


def calculate_cell_price(input_file, year, base_dir,type,chunks='auto'):
    tprint(f"Processing price {input_file} for year {year}...")

    output_path = os.path.join(base_dir, input_file, str(year), f"xr_{type}_price_{input_file}_{year}.nc")
    cost_path = os.path.join(base_dir, input_file, str(year), f"xr_total_cost_{input_file}_amortised_{year}.nc")
    env_path = os.path.join(base_dir, input_file, str(year), f"xr_total_{type}_{input_file}_{year}.nc")

    with xr.open_dataarray(cost_path, chunks=chunks) as cost_da, xr.open_dataarray(env_path, chunks=chunks) as env_da:
        mask_da = (cost_da >= 1) & (env_da >= 1)
        price_da = cost_da / env_da
        price_da = price_da.where(mask_da, np.nan)
        save2nc(price_da, output_path)

def calculate_cell_price_sol(input_file, year, base_dir,type,chunks='auto'):
    tprint(f"Processing price {input_file} for year {year}...")

    output_path = os.path.join(base_dir, input_file, str(year), f"xr_{type}_price_{input_file}_{year}.nc")
    cost_path = os.path.join(base_dir, input_file, str(year), f"xr_total_sol_cost_{input_file}_{year}.nc")
    env_path = os.path.join(base_dir, input_file, str(year), f"xr_total_{type}_{input_file}_{year}.nc")

    with xr.open_dataarray(cost_path, chunks=chunks) as cost_da, xr.open_dataarray(env_path, chunks=chunks) as env_da:
        mask_da = (cost_da >= 1) & (env_da >= 1)
        price_da = cost_da / env_da
        price_da = price_da.where(mask_da, np.nan)
        save2nc(price_da, output_path)


def xarrays_to_tifs(env_cat, file_part, base_dir, tif_dir, data, remove_negative=True, per_ha=True):
    """å¤„ç†ä¸€ä¸ªç±»åˆ«+æ–‡ä»¶éƒ¨åˆ†ï¼Œå¹¶è¾“å‡ºtif"""
    print(f"Processing {env_cat} - {file_part}")

    # æ„é€ è¾“å…¥è·¯å¾„
    if file_part == 'total_cost':
        input_path = f"{base_dir}/{env_cat}/2050/xr_{file_part}_{env_cat}_amortised_2050.nc"
    else:
        input_path = f"{base_dir}/{env_cat}/2050/xr_{file_part}_{env_cat}_2050.nc"

    # è¯»å–å’Œå¤„ç†
    da = xr.open_dataarray(input_path)
    da = da.sum(dim=[d for d in da.dims if d != 'cell'])

    if remove_negative:
        da = da.where(da >= 0, np.nan)
    if per_ha:
        da = da / data.REAL_AREA
        out_tif = f"{tif_dir}/{env_cat}/xr_{file_part}_ha_{env_cat}_2050.tif"
    else:
        out_tif = f"{tif_dir}/{env_cat}/xr_{file_part}_cell_{env_cat}_2050.tif"

    # è¾“å‡º cell ç‰ˆæœ¬

    os.makedirs(os.path.dirname(out_tif), exist_ok=True)
    nc_to_tif(data, da, out_tif)

    return out_tif

def subtract_tifs(a_path, b_path, out_path):
    with rasterio.open(a_path) as A, rasterio.open(b_path) as B:
        # 1) åŸºæœ¬ä¸€è‡´æ€§æ£€æŸ¥
        if (A.width, A.height) != (B.width, B.height) or A.transform != B.transform or A.crs != B.crs:
            raise ValueError("è¾“å…¥å½±åƒçš„å¤§å°/transform/CRS ä¸ä¸€è‡´ï¼Œè¯·å…ˆé‡é‡‡æ ·/é‡æŠ•å½±å¯¹é½ã€‚")

        # 2) è¯»ä¸º masked arrayï¼Œè½¬ä¸ºå« NaN çš„æ•°ç»„
        arr_a = A.read(1, masked=True).filled(np.nan).astype(np.float32)
        arr_b = B.read(1, masked=True).filled(np.nan).astype(np.float32)

        arr_a[arr_a < 0] = np.nan
        arr_b[arr_b < 0] = np.nan

        # 3) è®°å½•å…¨æ˜¯nançš„åœ°æ–¹
        all_nan_mask = np.isnan(arr_a) & np.isnan(arr_b)

        # 4) åšå·®ï¼Œnanè¡¥0
        arr_a_no_nan = np.nan_to_num(arr_a, nan=0.0)
        arr_b_no_nan = np.nan_to_num(arr_b, nan=0.0)
        out = arr_a_no_nan - arr_b_no_nan

        # 5) ç»“æœä¸­ï¼Œall_nan_maskè®¾ä¸ºnanï¼Œå…¶ä½™ â‰¤0 ä¹Ÿè®¾ä¸ºnan
        out[all_nan_mask] = np.nan
        out[out <= 0] = np.nan

        # 6) å†™å‡º
        nodata_value = -9999
        profile = A.profile.copy()
        profile.update(dtype="float32", compress="lzw", nodata=nodata_value)
        out = np.where(np.isnan(out), nodata_value, out)

        with rasterio.open(out_path, "w", **profile) as dst:
            dst.write(out, 1)

def plus_tifs(base_dir, env_cat, cost_names, outpath_part, remove_negative=True):
    for type in ['cell', 'ha']:
        cost_arrs = []
        for fname_part in cost_names:
            fname = f"{base_dir}/{env_cat}/xr_{fname_part}_{type}_{env_cat}_2050.tif"
            with rasterio.open(fname) as src:
                arr = src.read(1, masked=True).filled(np.nan).astype(np.float32)
                cost_arrs.append(arr)
                if len(cost_arrs) == 1:
                    cost_profile = src.profile.copy()

        cost_stack = np.stack(cost_arrs, axis=0)  # shape: (n_files, height, width)

        # 1. è®°å½•æ‰€æœ‰å±‚éƒ½æ˜¯nançš„åƒå…ƒ
        all_nan_mask = np.all(np.isnan(cost_stack), axis=0)  # Trueè¡¨ç¤ºæ‰€æœ‰å±‚éƒ½æ˜¯nan

        # 2. æ±‚å’Œæ—¶æŠŠnanå½“æˆ0
        cost_stack_no_nan = np.nan_to_num(cost_stack, nan=0.0)  # nanå˜æˆ0
        cost_sum = np.sum(cost_stack_no_nan, axis=0)

        # 3. æ±‚å’Œåå†æŠŠæ‰€æœ‰å±‚éƒ½æ˜¯nançš„åœ°æ–¹è®¾ä¸ºnan
        cost_sum[all_nan_mask] = np.nan

        # 4. nodataå¤„ç†
        nodata_value = -9999
        cost_sum[np.isnan(cost_sum)] = nodata_value
        if remove_negative:
            cost_sum[cost_sum < 1] = nodata_value

        profile = cost_profile.copy()
        profile.update(dtype="float32", compress="lzw", nodata=nodata_value)

        out_path = f"{base_dir}/{env_cat}/xr_{outpath_part}_{type}_{env_cat}_2050.tif"
        with rasterio.open(out_path, "w", **profile) as dst:
            dst.write(cost_sum, 1)

def divide_tifs(base_dir,env_cat, cost_name, benefit_name, outpath_part):
    """
    ç”¨ cost_names çš„æ‰€æœ‰ tif æ±‚å’Œï¼ˆå»æ‰å°äº1çš„ï¼‰ï¼Œ
    ç”¨ benefit_names çš„æ‰€æœ‰ tif æ±‚å’Œï¼ˆå»æ‰å°äº1çš„ï¼‰ï¼Œ
    ç„¶åç›¸é™¤ï¼Œè¾“å‡ºç»“æœä¸º tifã€‚
    """
    # è¯»å–å¹¶ç´¯åŠ æˆæœ¬å½±åƒ
    cost_path = f"{base_dir}/{env_cat}/xr_{cost_name}_cell_{env_cat}_2050.tif"
    with rasterio.open(cost_path) as src:
        cost_arr = src.read(1, masked=True).filled(np.nan).astype(np.float32)
        cost_arr[cost_arr < 1] = np.nan
        cost_profile = src.profile.copy()

    benefit_path = f"{base_dir}/{env_cat}/xr_{benefit_name}_cell_{env_cat}_2050.tif"
    with rasterio.open(benefit_path) as src:
        benefit_arr = src.read(1, masked=True).filled(np.nan).astype(np.float32)
        benefit_arr[cost_arr < 1] = np.nan

    # ç›¸é™¤
    out = cost_arr / benefit_arr

    # åªä¿ç•™æœ‰æ•ˆå€¼ï¼Œå…¶ä»–ä½ç½®è®¾ä¸º nodata
    nodata_value = -9999
    out[np.isnan(out)] = nodata_value
    out[benefit_arr < 1] = nodata_value  # é¿å…é™¤ä»¥å°äº1çš„æ•ˆç›Š
    out[cost_arr < 1] = nodata_value     # é¿å…æˆæœ¬å°äº1

    # æ›´æ–° profile
    profile = cost_profile.copy()
    profile.update(dtype="float32", compress="lzw", nodata=nodata_value)

    # å†™å‡º
    out_path = f"{base_dir}/{env_cat}/xr_{outpath_part}_{env_cat}_2050.tif"
    with rasterio.open(out_path, "w", **profile) as dst:
        dst.write(out, 1)

def xarrays_to_tifs_by_type(
    env_cat,
    file_part,
    base_dir,
    tif_dir,
    data,
    sum_dim,                # ä½ è¦åˆå¹¶çš„ç¬¬äºŒä¸ªç»´åº¦ï¼ˆæ¯”å¦‚ "year"ï¼‰
    remove_negative=False,
    per_ha=True
):
    """
    æŒ‰ç…§ 'cell' å’Œ sum_dim å¯¹æ•°æ®æ±‚å’Œï¼Œåˆ†åˆ«è¾“å‡ºæ¯ä¸ª sum_dim åæ ‡çš„ tif æ–‡ä»¶ï¼Œ
    å¹¶å…ˆè¾“å‡ºæ€»å’Œç‰ˆæœ¬ï¼ˆå¯¹é™¤äº†cellçš„æ‰€æœ‰ç»´åº¦æ±‚å’Œï¼‰

    Parameters
    ----------
    env_cat: str
    file_part: str
    base_dir: str
    tif_dir: str
    data: object
    sum_dim: str   # ä½ è¦åˆ†ç»„çš„ç»´åº¦ï¼Œæ¯”å¦‚ 'year'
    remove_negative: bool
    per_ha: bool
    """
    print(f"Processing {env_cat} - {file_part} by {sum_dim}")

    # æ„é€ è¾“å…¥è·¯å¾„
    input_path = f"{base_dir}/{env_cat}/2050/xr_{file_part}_2050.nc"

    # è¯»å–å’Œå¤„ç†
    da = xr.open_dataarray(input_path)

    # ----------- 1. æ±‚æ€»å’Œç‰ˆæœ¬ï¼ˆé™¤äº†cellçš„æ‰€æœ‰ç»´åº¦éƒ½æ±‚å’Œï¼‰ -----------
    sum_dims_total = [d for d in da.dims if d != 'cell']
    da_total = da.sum(dim=sum_dims_total)

    if per_ha:
        da_total = da_total / data.REAL_AREA
    if remove_negative:
        da_total = da_total.where(da_total >= 0, np.nan)

    out_total_tif = f"{tif_dir}/{env_cat}/xr_total_{file_part}_{env_cat}_2050.tif"
    os.makedirs(os.path.dirname(out_total_tif), exist_ok=True)
    nc_to_tif(data, da_total, out_total_tif)
    print(f"Saved {out_total_tif}")

    # ----------- 2. æŒ‰ sum_dim è¾“å‡ºåˆ†ç»„ tif -----------
    if sum_dim not in da.dims:
        raise ValueError(f"{sum_dim} ä¸åœ¨æ•°æ®çš„ç»´åº¦ {da.dims} ä¸­ï¼")

    results = [out_total_tif]
    # éå†æ–°ç»´åº¦çš„æ‰€æœ‰åæ ‡
    for coord_val in da[sum_dim].values:
        da_slice = da.sel({sum_dim: coord_val})
        sum_dims = [d for d in da_slice.dims if d != 'cell']
        da_out = da_slice.sum(dim=sum_dims)

        if per_ha:
            da_out = da_out / data.REAL_AREA
        if remove_negative:
            da_out = da_out.where(da_out >= 0, np.nan)

        out_tif = f"{tif_dir}/{env_cat}/xr_{file_part}_{env_cat}_{coord_val}_2050.tif"
        os.makedirs(os.path.dirname(out_tif), exist_ok=True)
        nc_to_tif(data, da_out, out_tif)
        results.append(out_tif)
        print(f"Saved {out_tif}")

    return results


def create_shp(env_cat, shp_name, file_parts, tif_dir):
    for file_part in file_parts:
        tif_env_dir = os.path.join(tif_dir, env_cat)
        input_tif_name = f'xr_{file_part}_{env_cat}_2050.tif'
        out_shp = os.path.join(tif_env_dir, f'{shp_name}', f'{shp_name}_{file_part}_{env_cat}_2050.shp')
        os.makedirs(os.path.dirname(out_shp), exist_ok=True)
        shp_path = f"../Map/{shp_name}.shp"
        zonal_stats_rasterized(tif_env_dir, input_tif_name, shp_path, out_shp)

def zonal_stats_rasterized(input_tif_dir, input_tif_name, shp_path, out_shp,
                           extra_nodata_vals=(-9999.0,), drop_allnan=True):
    # 1) è¯» shp ä¸ tif
    gdf = gpd.read_file(shp_path)
    input_tif = os.path.join(input_tif_dir, input_tif_name)

    with rasterio.open(input_tif) as src:
        img_m = src.read(1, masked=True)  # MaskedArrayï¼ˆè‹¥ nodata æœªè®¾ç½®ï¼Œmask å¯èƒ½æ— æ•ˆï¼‰
        transform = src.transform
        shape = (src.height, src.width)
        if gdf.crs is not None and src.crs is not None and gdf.crs != src.crs:
            gdf = gdf.to_crs(src.crs)

    n_shapes = len(gdf)

    # 2) å°†æ©è†œä¸å“¨å…µå€¼ç»Ÿä¸€è½¬ä¸º NaN
    arr = img_m.filled(np.nan).astype('float64', copy=False)
    for nd in (extra_nodata_vals or ()):
        arr[np.isclose(arr, nd)] = np.nan

    # 3) æ …æ ¼åŒ–çŸ¢é‡ï¼šåƒå…ƒå€¼=1..n_shapesï¼›0 ä¸ºèƒŒæ™¯
    shapes = ((geom, i + 1) for i, geom in enumerate(gdf.geometry))
    id_arr = rasterize(shapes, out_shape=shape, transform=transform, fill=0, dtype="int32")

    # 4) åªç»Ÿè®¡æœ‰æ•ˆåƒå…ƒï¼ˆåŒºåŸŸå†… ä¸” é NaNï¼‰
    valid_mask = (id_arr > 0) & np.isfinite(arr)
    if not np.any(valid_mask):
        if drop_allnan:
            print("âš ï¸ æ‰€æœ‰å¤šè¾¹å½¢å‡æ— æœ‰æ•ˆåƒå…ƒï¼Œæœªè¾“å‡ºã€‚")
            return
        # ä¸åˆ é™¤åˆ™å†™å‡ºå…¨ NaN çš„ç»“æœ
        gdf["sum"] = np.nan
        gdf["mean"] = np.nan
        gdf.to_file(out_shp)
        print(f"âœ… Saved {out_shp} (all NaN)")
        return

    vals = arr[valid_mask]
    ids = id_arr[valid_mask]

    # 5) åˆ†ç»„èšåˆ
    sum_per_id = np.bincount(ids, weights=vals, minlength=n_shapes + 1)
    cnt_per_id = np.bincount(ids, minlength=n_shapes + 1)

    sum_stat = sum_per_id[1:]
    cnt_stat = cnt_per_id[1:]

    mean_stat = np.full_like(sum_stat, np.nan, dtype="float64")
    np.divide(sum_stat, cnt_stat, out=mean_stat, where=cnt_stat > 0)

    if 'total_carbon' in input_tif_name:
        sum_stat = sum_stat / 1e6
        mean_stat = mean_stat / 1e6

    # 6) èµ‹å€¼åˆ° gdf
    gdf["sum"] = sum_stat
    gdf["mean"] = mean_stat
    gdf["count"] = cnt_stat  # æ–¹ä¾¿ç­›é€‰

    # 7) ï¼ˆæ–°å¢ï¼‰åˆ é™¤å…¨ NaNï¼ˆå³ count==0ï¼‰çš„è¦ç´ 
    if drop_allnan:
        before = len(gdf)
        gdf = gdf[gdf["count"] > 0].copy()
        removed = before - len(gdf)
        print(f"ğŸ§¹ ç§»é™¤äº† {removed} ä¸ªå…¨ NaN çš„å¤šè¾¹å½¢ã€‚")

        if gdf.empty:
            print("âš ï¸ è¿‡æ»¤åæ— è¦ç´ ï¼Œæœªè¾“å‡ºã€‚")
            return

    # å¯é€‰ï¼šä¸æƒ³ä¿ç•™ count å­—æ®µå°±æ³¨é‡Šæ‰ä¸‹ä¸€è¡Œ
    # gdf = gdf.drop(columns=["count"])

    # 8) è¾“å‡º
    gdf.to_file(out_shp)
    print(f"âœ… Saved {out_shp}ï¼ˆå…± {len(gdf)} ä¸ªè¦ç´ ï¼‰")

def main(task_dir, njobs):
    # ============================================================================
    output_path = f'{task_dir}/carbon_price/0_base_data'
    os.makedirs(output_path, exist_ok=True)
    tprint(f"ä»»åŠ¡ç›®å½•: {task_dir}")

    area_files = ['xr_area_agricultural_landuse', 'xr_area_agricultural_management','xr_area_non_agricultural_landuse']
    cost_files = ['xr_cost_ag', 'xr_cost_agricultural_management', 'xr_cost_non_ag', 'xr_cost_transition_ag2ag',
                  'xr_transition_cost_ag2non_ag']
    revenue_files = ['xr_revenue_ag', 'xr_revenue_agricultural_management', 'xr_revenue_non_ag']
    carbon_files = ['xr_GHG_ag', 'xr_GHG_ag_management', 'xr_GHG_non_ag', 'xr_transition_GHG']
    bio_files = ['xr_biodiversity_GBF2_priority_ag', 'xr_biodiversity_GBF2_priority_ag_management',
                 'xr_biodiversity_GBF2_priority_non_ag']
    carbon_sol_files = ['xr_GHG_ag', 'xr_GHG_non_ag']
    bio_sol_files = ['xr_biodiversity_GBF2_priority_ag','xr_biodiversity_GBF2_priority_non_ag']

    amortize_files = ['xr_transition_cost_ag2non_ag']
    economic_files = config.economic_files
    env_files = carbon_files + bio_files

    economic_sol_files = ['xr_cost_non_ag', 'xr_transition_cost_ag2non_ag_amortised', 'xr_revenue_non_ag']

    input_files_0 = config.input_files_0
    input_files_1 = config.input_files_1
    input_files_2 = config.input_files_2
    input_files = input_files_0 + input_files_1 + input_files_2
    input_all_names = [input_files_0, input_files_1, input_files_2]

    carbon_names = config.carbon_names
    carbon_bio_names = config.carbon_bio_names
    counter_carbon_bio_names = config.counter_carbon_bio_names
    output_all_names = carbon_names + carbon_bio_names + counter_carbon_bio_names


    years = [i for i in range(2010, 2051)]

    # ============================================================================
    # ç¬¬ä¸€æ‰¹ï¼šæ•°æ®é¢„å¤„ç†é˜¶æ®µ (æ‘Šé”€æˆæœ¬è®¡ç®— + æ–‡ä»¶å¤åˆ¶/å·®å¼‚è®¡ç®—)
    # ============================================================================
    start_time = time.time()

    tprint("=" * 80)

    # --- ç¬¬ä¸€æ‰¹ä»»åŠ¡ (æ‹†åˆ†ä¸ºä¸¤ä¸ªç‹¬ç«‹çš„ç»„) ---
    # ----------------------------------------------------------------------------
    # ===========================================================================
    # # --- é˜¶æ®µ 1: æ–‡ä»¶å¤„ç† ---
    tprint("\n--- æ–‡ä»¶copy ---")

    for input_file in list(dict.fromkeys(input_files)):
        # origin_path_name = os.path.join(task_dir, input_file,'Run_Archive.zip')
        origin_path_name = get_path(config.TASK_NAME, input_file)
        target_path_name = os.path.join(output_path, input_file)
        tprint(f"  -> æ­£åœ¨copy: {origin_path_name}")
        copy_files = cost_files + revenue_files + carbon_files + bio_files + area_files
        # ç›´æ¥è°ƒç”¨å‡½æ•°ï¼Œè€Œä¸æ˜¯ç”¨ delayed åŒ…è£…

        # --- 1. å¹¶è¡ŒåŒ–æ–‡ä»¶å¤åˆ¶ (é€»è¾‘ä¸å˜) ---
        if copy_files:
            # æ­¥éª¤1: ä¸€æ¬¡æ€§æå–æ‰€æœ‰æ–‡ä»¶åˆ°å†…å­˜ï¼ˆä¸²è¡Œï¼Œä½†åªæ‰§è¡Œä¸€æ¬¡ï¼‰
            files_in_memory = extract_files_from_zip(
                origin_path_name,
                copy_files,
                years,
                allow_missing_2010=True
            )

            # æ­¥éª¤2: å¹¶è¡Œå¤„ç†æ‰€æœ‰æ–‡ä»¶ï¼ˆæ— é”ï¼Œå……åˆ†å¹¶è¡Œï¼‰
            if njobs == 0:
                # ä¸²è¡Œå¤„ç†
                for (var_prefix, year), file_bytes in files_in_memory.items():
                    process_single_file_from_memory(
                        file_bytes, var_prefix, year, target_path_name, dims_to_sum=('source',)
                    )
            else:
                # å¹¶è¡Œå¤„ç†
                Parallel(n_jobs=njobs)(
                    delayed(process_single_file_from_memory)(
                        file_bytes, var_prefix, year, target_path_name, dims_to_sum=('source',)
                    )
                    for (var_prefix, year), file_bytes in files_in_memory.items()
                )

    tprint(f"âœ… æ–‡ä»¶copyä»»åŠ¡å®Œæˆ!")

    if njobs == 0:
        for i in range(len(list(dict.fromkeys(input_files)))):
            data_path_name = os.path.join(output_path, list(dict.fromkeys(input_files))[i])
            amortize_costs(data_path_name, amortize_files[0], years, njobs=njobs)
    else:
        Parallel(n_jobs=5, backend="loky")(
            delayed(amortize_costs)(
                os.path.join(output_path, run_name),  # data_path_name
                amortize_files[0],  # ä½ çš„ç¬¬äºŒä¸ªå‚æ•°
                years,
                njobs=1  # ä¼ ç»™å†…éƒ¨çš„å¹¶è¡Œå‚æ•°ï¼ˆè‹¥æœ‰ï¼‰
            )
            for run_name in list(list(dict.fromkeys(input_files)))
        )
    tprint("æ‘Šé”€æˆæœ¬è®¡ç®— å®Œæˆ!")
    #
    ##--- é˜¶æ®µ 2: carbon & bioè®¡ç®— ---
    if njobs == 0:
        for env_file in env_files:
            for year in years[1:]:
                calculate_env_diff(year, output_path, input_all_names, env_file, output_all_names)
    else:
        for env_file in env_files:
            Parallel(n_jobs=njobs)(
                delayed(calculate_env_diff)(year, output_path, input_all_names, env_file, output_all_names)
                for year in years[1:]
            )

# #
    tprint("\n--- é˜¶æ®µ 2: æ±‡æ€»carbon & bioè®¡ç®— ---")
    if njobs == 0:
        for year in years[1:]:
            # ç›´æ¥è°ƒç”¨
            aggregate_and_save_summary(year, output_path, carbon_files, output_all_names,'carbon')
            aggregate_and_save_summary(year, output_path, bio_files, output_all_names,'bio')
    else:
        Parallel(n_jobs=njobs)(
            delayed(aggregate_and_save_summary)(year, output_path, carbon_files, output_all_names,'carbon')
            for year in years[1:]
        )
        Parallel(n_jobs=njobs)(
            delayed(aggregate_and_save_summary)(year, output_path, bio_files, output_all_names,'bio')
            for year in years[1:]
        )

    if njobs == 0:
        for year in years[1:]:
            # ç›´æ¥è°ƒç”¨
            aggregate_and_save_summary(year, output_path, carbon_sol_files, output_all_names,'sol_carbon')
            aggregate_and_save_summary(year, output_path, bio_sol_files, output_all_names,'sol_bio')
    else:
        Parallel(n_jobs=njobs)(
            delayed(aggregate_and_save_summary)(year, output_path, carbon_sol_files, output_all_names,'sol_carbon')
            for year in years[1:]
        )
        Parallel(n_jobs=njobs)(
            delayed(aggregate_and_save_summary)(year, output_path, bio_sol_files, output_all_names,'sol_bio')
            for year in years[1:]
        )

    tprint(f"âœ… ç¬¬2æ‰¹ä»»åŠ¡æ±‡æ€»carbon & bioå®Œæˆ! ")

    # --- é˜¶æ®µ 3: åˆ©æ¶¦è®¡ç®— ---
    tprint("\n--- é˜¶æ®µ 3: åˆ©æ¶¦è®¡ç®— ---")
    profit_categories = zip(cost_files, revenue_files)
    for cost_base, rev_base in profit_categories:
        if njobs == 0:
            for run_names in input_all_names:
                for run_name in run_names:
                    for year in years:
                        # ç›´æ¥è°ƒç”¨
                        calculate_profit_for_run(year, output_path, run_name, cost_base, rev_base)
        else:
            for run_names in input_all_names:
                for run_name in run_names:
                    Parallel(n_jobs=njobs)(
                        delayed(calculate_profit_for_run)(year, output_path, run_name, cost_base, rev_base)
                        for year in years
                    )
    tprint(f"âœ… ç¬¬3æ‰¹ä»»åŠ¡å®Œæˆ!")

    ##--- é˜¶æ®µ 4: æ”¿ç­–æˆæœ¬è®¡ç®— ---
    tprint("\n--- é˜¶æ®µ 4: æ”¿ç­–æˆæœ¬è®¡ç®— ---")
    category_costs = ['agricultural_management','ag', 'non_ag']
    for category in category_costs:
        if njobs == 0:
            for year in years[1:]:
                # ç›´æ¥è°ƒç”¨
                calculate_policy_cost(year, output_path, input_all_names, category, 'carbon',carbon_names)
                calculate_policy_cost(year, output_path, input_all_names, category, 'bio', carbon_bio_names)
                calculate_policy_cost(year, output_path, input_all_names, category, 'counter', counter_carbon_bio_names)
        else:
            Parallel(n_jobs=njobs)(
                delayed(calculate_policy_cost)(year, output_path, input_all_names, category, 'carbon', carbon_names)
                for year in years[1:]
            )
            Parallel(n_jobs=njobs)(
                delayed(calculate_policy_cost)(year, output_path, input_all_names, category, 'bio', carbon_bio_names)
                for year in years[1:]
            )
            Parallel(n_jobs=njobs)(
                delayed(calculate_policy_cost)(year, output_path, input_all_names, category, 'counter', counter_carbon_bio_names)
                for year in years[1:]
            )
    tprint(f"âœ… ç¬¬4æ‰¹ä»»åŠ¡å®Œæˆ! ")

    ##--- é˜¶æ®µ 5: è½¬å‹æˆæœ¬å·®å€¼è®¡ç®— (ä»…ç‹¬ç«‹éƒ¨åˆ†) ---
    tprint("\n--- é˜¶æ®µ 5: è½¬å‹æˆæœ¬å·®å€¼è®¡ç®— ---")
    independent_tran_files = ['xr_cost_transition_ag2ag', 'xr_transition_cost_ag2non_ag',
                              'xr_transition_cost_ag2non_ag_amortised']
    for tran_file in independent_tran_files:
        tprint(f"Processing transition cost file: {tran_file}...")
        if njobs == 0:
            for year in years[1:]:
                # ç›´æ¥è°ƒç”¨
                calculate_transition_cost_diff(year, output_path, input_all_names, tran_file, 'carbon', carbon_names)
                calculate_transition_cost_diff(year, output_path, input_all_names, tran_file, 'bio', carbon_bio_names)
                calculate_transition_cost_diff(year, output_path, input_all_names, tran_file, 'counter', counter_carbon_bio_names)
        else:
            Parallel(n_jobs=math.ceil(njobs/2))(
                delayed(calculate_transition_cost_diff)(year, output_path, input_all_names, tran_file, 'carbon', carbon_names)
                for year in years[1:]
            )
            Parallel(n_jobs=math.ceil(njobs/2))(
                delayed(calculate_transition_cost_diff)(year, output_path, input_all_names, tran_file, 'bio', carbon_bio_names)
                for year in years[1:]
            )
            Parallel(n_jobs=math.ceil(njobs/2))(
                delayed(calculate_transition_cost_diff)(year, output_path, input_all_names, tran_file, 'counter', counter_carbon_bio_names)
                for year in years[1:]
            )
    tprint(f"âœ… ç¬¬5æ‰¹ è½¬å‹æˆæœ¬å·®å€¼è®¡ç®— ä»»åŠ¡å®Œæˆ! ")

    # --- é˜¶æ®µ 6: æˆæœ¬èšåˆ ---
    tprint("\n--- é˜¶æ®µ 6: æˆæœ¬èšåˆ ---")

    if njobs == 0:
        for year in years[1:]:
            # ç›´æ¥è°ƒç”¨
            aggregate_and_save_cost(year, output_path,carbon_names)
            aggregate_and_save_cost(year, output_path,carbon_bio_names)
            aggregate_and_save_cost(year, output_path,counter_carbon_bio_names)
    else:
        Parallel(n_jobs=njobs)(
            delayed(aggregate_and_save_cost)(year, output_path, carbon_names)
            for year in years[1:]
        )
        Parallel(n_jobs=njobs)(
            delayed(aggregate_and_save_cost)(year, output_path, carbon_bio_names)
            for year in years[1:]
        )
        Parallel(n_jobs=njobs)(
            delayed(aggregate_and_save_cost)(year, output_path, counter_carbon_bio_names)
            for year in years[1:]
        )

    if njobs == 0:
        for year in years[1:]:
            # ç›´æ¥è°ƒç”¨
            aggregate_and_save_cost_sol(year, output_path,carbon_names)
            aggregate_and_save_cost_sol(year, output_path,carbon_bio_names)
            aggregate_and_save_cost_sol(year, output_path,counter_carbon_bio_names)
    else:
        Parallel(n_jobs=njobs)(
            delayed(aggregate_and_save_cost_sol)(year, output_path, carbon_names)
            for year in years[1:]
        )
        Parallel(n_jobs=njobs)(
            delayed(aggregate_and_save_cost_sol)(year, output_path, carbon_bio_names)
            for year in years[1:]
        )
        Parallel(n_jobs=njobs)(
            delayed(aggregate_and_save_cost_sol)(year, output_path, counter_carbon_bio_names)
            for year in years[1:]
        )

    tprint(f"âœ… ç¬¬6æ‰¹ (æœ€ç»ˆèšåˆ) ä»»åŠ¡å®Œæˆ! ")

    ## --- é˜¶æ®µ 7: ä»·æ ¼è®¡ç®— ---
    tprint("\n--- é˜¶æ®µ 7: ä»·æ ¼è®¡ç®— ---")

    if njobs == 0:
        for input_file in output_all_names:
            for year in years[1:]:
                calculate_cell_price(input_file, year, output_path,'carbon')
                calculate_cell_price(input_file, year, output_path,'bio')
    else:
        for input_file in output_all_names:
            Parallel(n_jobs=njobs)(
                delayed(calculate_cell_price)(input_file, year, output_path,'carbon')
                for year in years[1:]
            )
            Parallel(n_jobs=njobs)(
                delayed(calculate_cell_price)(input_file, year, output_path,'bio')
                for year in years[1:]
            )

    if njobs == 0:
        for input_file in output_all_names:
            for year in years[1:]:
                calculate_cell_price_sol(input_file, year, output_path,'carbon')
                calculate_cell_price_sol(input_file, year, output_path,'bio')
    else:
        for input_file in output_all_names:
            Parallel(n_jobs=njobs)(
                delayed(calculate_cell_price_sol)(input_file, year, output_path,'carbon')
                for year in years[1:]
            )
            Parallel(n_jobs=njobs)(
                delayed(calculate_cell_price_sol)(input_file, year, output_path,'bio')
                for year in years[1:]
            )

    tprint(f"âœ… ç¬¬7æ‰¹ ä»·æ ¼è®¡ç®— ä»»åŠ¡å®Œæˆ! ")
   # ==========================================================================

# ============================================================================
    excel_path = f"../../../output/{config.TASK_NAME}/carbon_price/1_excel"
    os.makedirs(excel_path, exist_ok=True)

    for input_file in list(dict.fromkeys(input_files)):
        print(f"carbon: {input_file}")
        df = summarize_netcdf_to_excel(input_file, years[1:], carbon_files, njobs, 'carbon')
    for input_file in list(dict.fromkeys(input_files)):
        print(f"biodiversity: {input_file}")
        df = summarize_netcdf_to_excel(input_file, years[1:], bio_files, njobs, 'biodiversity')
    for input_file in list(dict.fromkeys(input_files)):
        print(f"economic: {input_file}")
        df = summarize_netcdf_to_excel(input_file, years[1:], economic_files, np.ceil(njobs/2), 'economic')
#
#     # ---------------------------------------make excel 1_cost---------------------------------------
    profit_0_list = []
    for input_file in input_files_0:
        profit_0_list.append(create_profit_for_cost(excel_path, input_file))
    profit_1_list = []
    for input_file in input_files_1:
        profit_1_list.append(create_profit_for_cost(excel_path, input_file))
    profit_2_list = []
    for input_file in input_files_2:
        profit_2_list.append(create_profit_for_cost(excel_path, input_file))

    for i in range(len(input_files_1)):
        df = profit_0_list[i] - profit_1_list[i]
        df.columns = df.columns.str.replace('profit', '')
        df['Total'] = df.sum(axis=1)
        df.to_excel(os.path.join(excel_path, f'1_Cost_{carbon_names[i]}.xlsx'))

        df = profit_1_list[i] - profit_2_list[i]
        df.columns = df.columns.str.replace('profit', '')
        df['Total'] = df.sum(axis=1)
        df.to_excel(os.path.join(excel_path, f'1_Cost_{carbon_bio_names[i]}.xlsx'))

        df = profit_0_list[i] - profit_2_list[i]
        df.columns = df.columns.str.replace('profit', '')
        df['Total'] = df.sum(axis=1)
        df.to_excel(os.path.join(excel_path, f'1_Cost_{counter_carbon_bio_names[i]}.xlsx'))


    # -----------------------------------make excel 1_processed carbon/bio---------------------------------------
    for input_file in dict.fromkeys(input_files):
        df = pd.read_excel(os.path.join(excel_path, f'0_Origin_carbon_{input_file}.xlsx'), index_col=0)
        df.columns = df.columns.str.replace(' GHG', '')
        new_rows_list = []

        # ä»ç¬¬äºŒè¡Œå¼€å§‹å¾ªç¯ (ç´¢å¼• i ä» 1 åˆ° df çš„æœ«å°¾)
        for i in range(1, len(df)):
            # å–å‡ºå½“å‰è¡Œå¹¶å–è´Ÿ
            new_row = df.iloc[i].copy()
            new_row = new_row * -1

            # å…³é”®æ­¥éª¤ï¼šæ–°è¡Œçš„ç¬¬ä¸€åˆ— = (åŸå€¼å–è´Ÿ) + (åŸdfä¸­ä¸Šä¸€è¡Œç¬¬ä¸€åˆ—çš„å€¼)
            new_row.iloc[0] = -df.iloc[i, 0] + df.iloc[i - 1, 0]

            # å°†è®¡ç®—å‡ºçš„æ–°è¡Œï¼ˆè¿™æ˜¯ä¸€ä¸ª Seriesï¼‰æ·»åŠ åˆ°åˆ—è¡¨ä¸­
            new_rows_list.append(new_row)

        # ä½¿ç”¨æ”¶é›†åˆ°çš„è¡Œåˆ—è¡¨ä¸€æ¬¡æ€§åˆ›å»ºæ–°çš„ DataFrame
        # è¿™æ ·åšæ¯”åœ¨å¾ªç¯ä¸­åå¤ concat æ›´é«˜æ•ˆ
        new_df = pd.DataFrame(new_rows_list)

        # å°†æ–° DataFrame çš„ç´¢å¼•è®¾ç½®ä¸ºä¸åŸæ•°æ®å¯¹åº”ï¼ˆä» 1 å¼€å§‹ï¼‰
        new_df.index = df.index[1:]
        new_df['Total'] = new_df.sum(axis=1)
        new_df.to_excel(os.path.join(excel_path, f'1_Processed_carbon_{input_file}.xlsx'))

    for input_file in dict.fromkeys(input_files):
        df = pd.read_excel(os.path.join(excel_path, f'0_Origin_biodiversity_{input_file}.xlsx'), index_col=0)
        df.columns = df.columns.str.replace(' biodiversity', '')
        new_rows_list = []

        # ä»ç¬¬äºŒè¡Œå¼€å§‹å¾ªç¯ (ç´¢å¼• i ä» 1 åˆ° df çš„æœ«å°¾)
        for i in range(1, len(df)):
            # å–å‡ºå½“å‰è¡Œå¹¶å–è´Ÿ
            new_row = df.iloc[i].copy()

            new_row.iloc[0] = df.iloc[i, 0] - df.iloc[i - 1, 0]

            # å°†è®¡ç®—å‡ºçš„æ–°è¡Œï¼ˆè¿™æ˜¯ä¸€ä¸ª Seriesï¼‰æ·»åŠ åˆ°åˆ—è¡¨ä¸­
            new_rows_list.append(new_row)

        # ä½¿ç”¨æ”¶é›†åˆ°çš„è¡Œåˆ—è¡¨ä¸€æ¬¡æ€§åˆ›å»ºæ–°çš„ DataFrame
        # è¿™æ ·åšæ¯”åœ¨å¾ªç¯ä¸­åå¤ concat æ›´é«˜æ•ˆ
        new_df = pd.DataFrame(new_rows_list)

        # å°†æ–° DataFrame çš„ç´¢å¼•è®¾ç½®ä¸ºä¸åŸæ•°æ®å¯¹åº”ï¼ˆä» 1 å¼€å§‹ï¼‰
        new_df.index = df.index[1:]
        new_df['Total'] = new_df.sum(axis=1)
        new_df.to_excel(os.path.join(excel_path, f'1_Processed_bio_{input_file}.xlsx'))


    # -----------------------------------make excel 2_cost & carbon/bio & average price---------------------------------------
    colnames = ["GHG benefits (Mt CO2e)", "Carbon cost (M AUD$)", "Average Carbon price (AUD$/t CO2e)"]
    if njobs == 0:
        for carbon_name in output_all_names:
            create_summary(carbon_name, years[1:], output_path,'carbon', colnames)
    else:
        Parallel(n_jobs=njobs)(
            delayed(create_summary)(carbon_name, years[1:], output_path,'carbon', colnames)
            for carbon_name in output_all_names
        )


    colnames = ["Biodiversity benefits (Mt CO2e)", "Biodiversity cost (M AUD$)",
                "Average Biodiversity price (AUD$/t CO2e)"]
    if njobs == 0:
        for bio_name in output_all_names:
            create_summary(bio_name, years[1:], output_path,'bio', colnames)
    else:
        Parallel(n_jobs=njobs)(
            delayed(create_summary)(bio_name, years[1:], output_path,'bio', colnames)
            for bio_name in output_all_names
        )


    summarize_to_category(output_all_names, years[1:], carbon_files, 'xr_total_carbon', n_jobs=41)
    summarize_to_category(output_all_names, years[1:], bio_files, 'xr_total_bio', n_jobs=41)

    summarize_to_category(list(dict.fromkeys(input_files)), years[1:], carbon_files, 'xr_total_carbon_original', n_jobs=41,scenario_name=False)
    summarize_to_category(list(dict.fromkeys(input_files)), years[1:], bio_files, 'xr_total_bio_original', n_jobs=41,scenario_name=False)

    profit_da = summarize_to_category(list(dict.fromkeys(input_files)), years[1:], economic_files, 'xr_cost_for_profit', n_jobs=41,scenario_name=False)
    build_profit_and_cost_nc(profit_da, list(dict.fromkeys(input_files_0)), input_files_1, input_files_2, carbon_names, carbon_bio_names,
                             counter_carbon_bio_names)

    make_prices_nc(output_all_names)

    summarize_to_category(output_all_names, years[1:], carbon_sol_files, 'xr_total_sol_carbon', n_jobs=41)
    summarize_to_category(output_all_names, years[1:], bio_sol_files, 'xr_total_sol_bio', n_jobs=41)

    profit_sol_da = summarize_to_category(list(dict.fromkeys(input_files)), years[1:], economic_sol_files, 'xr_sol_cost_for_profit', n_jobs=41,scenario_name=False)
    build_sol_profit_and_cost_nc(profit_sol_da, list(dict.fromkeys(input_files_0)), input_files_1, input_files_2, carbon_names, carbon_bio_names,
                                 counter_carbon_bio_names)

    make_sol_prices_nc(output_all_names)

    files = ['xr_cost_agricultural_management', 'xr_cost_non_ag', 'xr_transition_cost_ag2non_ag_amortised_diff',
             'xr_GHG_ag_management', 'xr_GHG_non_ag', 'xr_biodiversity_GBF2_priority_ag_management',
             'xr_biodiversity_GBF2_priority_non_ag']
    dim_names = ['am', 'lu', 'To-land-use', 'am', 'lu', 'am', 'lu']

    for file, dim_name in zip(files, dim_names):
        summarize_to_type(
            scenarios=output_all_names,
            years=years[1:],
            file=file,
            keep_dim=dim_name,
            output_file=f'{file}',
            var_name='data',
            scale=1e6,
            n_jobs=njobs,
            dtype='float32',
        )

    files = ['xr_area_agricultural_management','xr_area_non_agricultural_landuse',
             'xr_biodiversity_GBF2_priority_ag_management','xr_biodiversity_GBF2_priority_non_ag',
             'xr_GHG_ag_management','xr_GHG_non_ag',
             'xr_cost_agricultural_management', 'xr_cost_non_ag', 'xr_transition_cost_ag2non_ag_amortised']
    dim_names = ['am','lu','am','lu','am','lu','am', 'lu', 'To-land-use']

    for file, dim_name in zip(files, dim_names):
        summarize_to_type(
            scenarios=list(dict.fromkeys(input_files)),
            years=years[1:],
            file=file,
            keep_dim=dim_name,
            output_file=f'{file}',
            var_name='data',
            scale=1e6,
            n_jobs=njobs,
            dtype='float32',
            scenario_name=False
        )

    # =================================================================

    tif_dir = f"../../../output/{config.TASK_NAME}/carbon_price/4_tif"
    output_path = f"../../../output/{config.TASK_NAME}/carbon_price/0_base_data"
    data = get_data_RES(config.TASK_NAME, input_files_0[0])

    cost_file_parts = ['total_cost', 'cost_agricultural_management', 'cost_non_ag',
                       'transition_cost_ag2non_ag_amortised_diff']
    GHG_file_parts = ['total_carbon', 'GHG_ag_management', 'GHG_non_ag']
    bio_file_parts = ['total_bio', 'biodiversity_GBF2_priority_ag_management', 'biodiversity_GBF2_priority_non_ag']
    agmgt_file_parts = ['area_agricultural_management']
    nonag_file_parts = ['area_non_agricultural_landuse']

    # 1. å®šä¹‰æ‰€æœ‰ä»»åŠ¡ç»„åˆ
    cost_tasks = [(env_cat, file_part) for env_cat in output_all_names for file_part in cost_file_parts]
    GHG_tasks = [(env_cat, file_part) for env_cat in output_all_names for file_part in GHG_file_parts]
    bio_tasks = [(env_cat, file_part) for env_cat in output_all_names for file_part in bio_file_parts]
    agmgt_tasks = [(env_cat, file_part) for env_cat in input_files for file_part in agmgt_file_parts]
    nonag_tasks = [(env_cat, file_part) for env_cat in input_files for file_part in nonag_file_parts]

    # 2. ç»Ÿä¸€å¹¶è¡Œè°ƒç”¨
    Parallel(n_jobs=njobs)(
        delayed(xarrays_to_tifs)(env_cat, file_part, output_path, tif_dir, data)
        for env_cat, file_part in cost_tasks
    )
    Parallel(n_jobs=njobs)(
        delayed(xarrays_to_tifs)(env_cat, file_part, output_path, tif_dir, data, remove_negative=False)
        for env_cat, file_part in GHG_tasks + bio_tasks
    )
    Parallel(n_jobs=njobs)(
        delayed(xarrays_to_tifs)(env_cat, file_part, output_path, tif_dir, data, per_ha=False)
        for env_cat, file_part in cost_tasks
    )
    Parallel(n_jobs=njobs)(
        delayed(xarrays_to_tifs)(env_cat, file_part, output_path, tif_dir, data, remove_negative=False, per_ha=False)
        for env_cat, file_part in GHG_tasks + bio_tasks
    )
    Parallel(n_jobs=njobs)(
        delayed(xarrays_to_tifs_by_type)(
            env_cat, file_part, output_path, tif_dir, data,
            sum_dim='am'
        )
        for env_cat, file_part in agmgt_tasks
    )
    Parallel(n_jobs=njobs)(
        delayed(xarrays_to_tifs_by_type)(
            env_cat, file_part, output_path, tif_dir, data,
            sum_dim='lu'
        )
        for env_cat, file_part in nonag_tasks
    )

    # 3. æ±‚è§£æˆæœ¬ä¸æ•ˆç›Šçš„åˆå¹¶åŠæ¯”å€¼
    solution_cost_parts = ['cost_agricultural_management', 'cost_non_ag', 'transition_cost_ag2non_ag_amortised_diff']
    solution_ghg_benefit_parts = ['GHG_ag_management', 'GHG_non_ag']
    solution_bio_benefit_parts = ['biodiversity_GBF2_priority_ag_management', 'biodiversity_GBF2_priority_non_ag']

    solution_cost_parts = ['cost_non_ag', 'transition_cost_ag2non_ag_amortised_diff']
    solution_ghg_benefit_parts = ['GHG_non_ag']
    solution_bio_benefit_parts = ['biodiversity_GBF2_priority_non_ag']

    Parallel(n_jobs=njobs)(
        delayed(plus_tifs)(tif_dir, env_cat, solution_cost_parts, "total_sol_cost")
        for env_cat in output_all_names
    )
    Parallel(n_jobs=njobs)(
        delayed(plus_tifs)(tif_dir, env_cat, solution_ghg_benefit_parts, "total_sol_ghg_benefit", remove_negative=False)
        for env_cat in output_all_names
    )
    Parallel(n_jobs=njobs)(
        delayed(divide_tifs)(tif_dir, env_cat, 'total_sol_cost', 'total_sol_ghg_benefit', "carbon_sol_price")
        for env_cat in output_all_names
    )
    Parallel(n_jobs=njobs)(
        delayed(plus_tifs)(tif_dir, env_cat, solution_bio_benefit_parts, "total_sol_bio_benefit", remove_negative=False)
        for env_cat in output_all_names
    )
    Parallel(n_jobs=njobs)(
        delayed(divide_tifs)(tif_dir, env_cat, 'total_sol_cost', 'total_sol_bio_benefit', "bio_sol_price")
        for env_cat in output_all_names
    )

    # 4. å·®å€¼è®¡ç®—
    tif_path_1 = os.path.join(tif_dir, 'carbon_high_50', "xr_carbon_sol_price_carbon_high_50_2050.tif")
    tif_path_2 = os.path.join(tif_dir, 'Counterfactual_carbon_high_bio_50',
                              "xr_carbon_sol_price_Counterfactual_carbon_high_bio_50_2050.tif")
    tif_output = os.path.join(tif_dir, 'carbon_high_bio_50', "xr_carbon_sol_price_carbon_high_bio_50_2050.tif")
    subtract_tifs(tif_path_2, tif_path_1, tif_output)
    #

    # --- æ€»ç»“ ---
    end_time = time.time()
    total_time = end_time - start_time
    tprint("\n" + "=" * 80)
    tprint("æ‰€æœ‰ä»»åŠ¡å·²æŒ‰é¡ºåºæ‰§è¡Œå®Œæ¯•")
    tprint(f"æ€»æ‰§è¡Œæ—¶é—´: {total_time / 60 / 60:.2f} å°æ—¶ )")
    tprint("=" * 80)
    return

def run(task_dir, njobs):
    save_dir = os.path.join(task_dir, 'carbon_price')
    log_path = os.path.join(save_dir,'log_0_preprocess')
    @LogToFile(log_path)
    def _run():
        # Start recording memory usage
        stop_event = threading.Event()
        memory_thread = threading.Thread(target=log_memory_usage, args=(save_dir, 'a', 1, stop_event))
        memory_thread.start()

        try:
            print('\n')
            main(task_dir, njobs)
        except Exception as e:
            print(f"An error occurred during the simulation: {e}")
            raise e
        finally:
            # Ensure the memory logging thread is stopped
            stop_event.set()
            memory_thread.join()

    return _run()

if __name__ == "__main__":
    task_name = config.TASK_NAME
    njobs = math.ceil(41/1)
    task_dir = f'../../../output/{task_name}'

    run(task_dir, njobs)