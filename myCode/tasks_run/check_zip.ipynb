{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cac93ebf69d9ba",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-05T11:44:17.424026800Z",
     "start_time": "2025-10-05T11:44:16.895901600Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "import zipfile\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "def clean_and_recompress(root_path, njobs=-1, archive_root=True):\n",
    "    # 1. 找到所有Run_Archive.zip\n",
    "    run_zip_paths = []\n",
    "    for dirpath, dirnames, filenames in os.walk(root_path):\n",
    "        for filename in filenames:\n",
    "            if filename == \"Run_Archive.zip\":\n",
    "                run_zip_paths.append(os.path.join(dirpath, filename))\n",
    "    \n",
    "    def _process_zip(zip_path):\n",
    "        print(f\"Processing {zip_path}\")\n",
    "        with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
    "            names_to_keep = [name for name in zf.namelist() if name.startswith(\"DATA_REPORT/\")]\n",
    "            keep_files = {name: zf.read(name) for name in names_to_keep if not name.endswith('/')}\n",
    "        # 在目标目录创建临时文件\n",
    "        target_dir = os.path.dirname(zip_path)\n",
    "        with tempfile.NamedTemporaryFile(delete=False, dir=target_dir) as tmp:\n",
    "            tmp_zip_path = tmp.name\n",
    "        with zipfile.ZipFile(tmp_zip_path, \"w\", zipfile.ZIP_DEFLATED) as zf:\n",
    "            for name, data in keep_files.items():\n",
    "                zf.writestr(name, data)\n",
    "        os.replace(tmp_zip_path, zip_path)\n",
    "            \n",
    "    # 2. 并行处理每个Run_Archive.zip\n",
    "    Parallel(n_jobs=njobs)(delayed(_process_zip)(zip_path) for zip_path in run_zip_paths)\n",
    "\n",
    "    # 3. 可选：压缩整个root_path到上一级目录\n",
    "    if archive_root:\n",
    "        parent_dir = os.path.dirname(root_path)\n",
    "        base_name = os.path.basename(root_path)\n",
    "        archive_path = os.path.join(parent_dir, base_name)\n",
    "        with zipfile.ZipFile(f\"{archive_path}.zip\", 'w', zipfile.ZIP_DEFLATED, compresslevel=3) as zipf:\n",
    "            for root, dirs, files in os.walk(root_path):\n",
    "                for file in files:\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    arcname = os.path.relpath(file_path, root_path)\n",
    "                    zipf.write(file_path, arcname)\n",
    "        print(f\"Recompressed whole directory to {archive_path}.zip\")\n",
    "\n",
    "def find_missing_reports_by_col(path):\n",
    "    # 读取csv列名\n",
    "    csv_path = os.path.join(path, \"grid_search_template.csv\")\n",
    "    df = pd.read_csv(csv_path,index_col=0)\n",
    "    col_names = df.columns.tolist()\n",
    "\n",
    "    missing_cols = []\n",
    "    for col_name in col_names:\n",
    "        new_path = os.path.join(path, str(col_name))\n",
    "        zip_path = os.path.join(new_path, \"Run_Archive.zip\")\n",
    "        if not os.path.exists(zip_path):\n",
    "            missing_cols.append(col_name)\n",
    "    return missing_cols "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "69ebbb3d62770bcb"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eab9b909aec744aa",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-05T11:44:21.668029500Z",
     "start_time": "2025-10-05T11:44:20.486750300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Run_91_GBF2_off_CUT_50_CarbonPrice_133.84', 'Run_92_GBF2_off_CUT_50_CarbonPrice_178.46', 'Run_93_GBF2_off_CUT_50_CarbonPrice_233.07', 'Run_94_GBF2_off_CUT_50_CarbonPrice_267.69', 'Run_95_GBF2_off_CUT_50_CarbonPrice_312.3', 'Run_96_GBF2_off_CUT_50_CarbonPrice_356.92']\n"
     ]
    }
   ],
   "source": [
    "path = \"../../output/20251004_Cost_curve_task\"\n",
    "print(find_missing_reports_by_col(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ce7b9859b1d9c7a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-05T12:14:17.231820100Z",
     "start_time": "2025-10-05T11:44:24.394673400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recompressed whole directory to ../../output\\20251004_Cost_curve_task.zip\n"
     ]
    }
   ],
   "source": [
    "clean_and_recompress(path, archive_root=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8c556dee3d9ae778"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
