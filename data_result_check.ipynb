{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T06:45:20.071729400Z",
     "start_time": "2026-02-18T06:45:19.942020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import xarray as xr\n",
    "import cf_xarray as cfxr\n",
    "import pandas as pd\n",
    "\n",
    "def load_from_nc(load_path: str, var_name: str = 'data') -> xr.DataArray:\n",
    "    \"\"\"\n",
    "    从 NetCDF 文件恢复 DataArray,自动处理 multi-index\n",
    "    \"\"\"\n",
    "    ds = xr.open_dataset(load_path)\n",
    "\n",
    "    # 尝试解码 multi-index\n",
    "    try:\n",
    "        has_compress = any(\n",
    "            'compress' in ds[var].attrs\n",
    "            for var in ds.coords\n",
    "            if var in ds.variables\n",
    "        )\n",
    "        if has_compress:\n",
    "            ds = cfxr.decode_compress_to_multi_index(ds, 'layer')\n",
    "    except (ValueError, KeyError):\n",
    "        pass\n",
    "\n",
    "    # 提取 DataArray\n",
    "    if var_name in ds.data_vars:\n",
    "        da = ds[var_name]\n",
    "    else:\n",
    "        var_name = list(ds.data_vars)[0]\n",
    "        da = ds[var_name]\n",
    "\n",
    "    return da"
   ],
   "id": "c326b5913ee0e13d",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-18T07:00:56.472128900Z",
     "start_time": "2026-02-18T07:00:56.400221500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_path = r'output/20260213_Paper2_Results_test/carbon_price\\0_base_data\\Counterfactual_carbon_low_bio_10\\2011\\xr_cost_agricultural_management_Counterfactual_carbon_low_bio_10_2011.nc'\n",
    "xr_arr = xr.open_dataset(load_path)\n",
    "print(xr_arr)"
   ],
   "id": "c50805998fd8a6bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 1MB\n",
      "Dimensions:  (am: 1, lu: 16, cell: 18769)\n",
      "Coordinates:\n",
      "  * am       (am) <U21 84B 'Precision Agriculture'\n",
      "  * lu       (lu) <U22 1kB 'Other non-cereal crops' 'Cotton' ... 'Vegetables'\n",
      "  * cell     (cell) int32 75kB 0 1 2 3 4 5 ... 18764 18765 18766 18767 18768\n",
      "Data variables:\n",
      "    data     (cell, am, lu) float32 1MB ...\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T06:45:20.888065600Z",
     "start_time": "2026-02-18T06:45:20.858158100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_path = \"output/20260213_Paper2_Results_test/carbon_price/0_base_data\\Run_25_GHG_off_BIO_off_CUT_10/2014/xr_transition_cost_ag2non_ag_amortised_2014.nc\"\n",
    "xr_arr = xr.open_dataset(load_path)\n",
    "print(xr_arr)"
   ],
   "id": "5322e654dbfaf8a3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\R'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\R'\n",
      "C:\\Users\\local_s222552331\\Temp\\2\\ipykernel_76492\\2835197699.py:1: SyntaxWarning: invalid escape sequence '\\R'\n",
      "  load_path = \"output/20260213_Paper2_Results_test/carbon_price/0_base_data\\Run_25_GHG_off_BIO_off_CUT_10/2014/xr_transition_cost_ag2non_ag_amortised_2014.nc\"\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T06:45:20.911058800Z",
     "start_time": "2026-02-18T06:45:20.897555900Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "bd0b91c51f3e9047",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T06:45:20.927544800Z",
     "start_time": "2026-02-18T06:45:20.912130100Z"
    }
   },
   "cell_type": "code",
   "source": "xr_arr.coords['From-land-use'].values",
   "id": "d1fa64245023fc2b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sheep - modified land'], dtype='<U21')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T06:45:20.945176200Z",
     "start_time": "2026-02-18T06:45:20.928332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from typing import Union, Iterable, Optional\n",
    "\n",
    "\n",
    "def _ensure_layer_multiindex_strict(\n",
    "    da: xr.DataArray,\n",
    "    layer_dim: str = \"layer\",\n",
    "    level_order: Optional[Iterable[str]] = None,\n",
    ") -> xr.DataArray:\n",
    "    \"\"\"\n",
    "    严格确保 da 的 layer 是 MultiIndex。\n",
    "    规则：\n",
    "    - 如果 layer 已经是 MultiIndex：直接返回\n",
    "    - 否则要求存在 coords(dims=(layer,)) 的 level 变量（如 am/lm/lu/source...）\n",
    "      用 set_index(layer=[...]) 构造 MultiIndex\n",
    "    - 如果没有 level 变量：直接报错（因为无法还原）\n",
    "    \"\"\"\n",
    "    if layer_dim not in da.dims:\n",
    "        return da\n",
    "\n",
    "    idx = da.indexes.get(layer_dim, None)\n",
    "    if isinstance(idx, pd.MultiIndex):\n",
    "        return da\n",
    "\n",
    "    layer_level_vars = [\n",
    "        c for c in da.coords\n",
    "        if c != layer_dim and da.coords[c].dims == (layer_dim,)\n",
    "    ]\n",
    "    if not layer_level_vars:\n",
    "        raise ValueError(\n",
    "            f\"'{layer_dim}' is not a MultiIndex and no layer-level coords exist to rebuild it. \"\n",
    "            f\"Available coords with dims=('layer',): {layer_level_vars}\"\n",
    "        )\n",
    "\n",
    "    if level_order is not None:\n",
    "        level_order = list(level_order)\n",
    "        layer_level_vars = [c for c in level_order if c in layer_level_vars] + \\\n",
    "                           [c for c in layer_level_vars if c not in level_order]\n",
    "\n",
    "    return da.set_index({layer_dim: layer_level_vars})\n",
    "\n",
    "\n",
    "def filter_all_from_dims(\n",
    "    obj: Union[xr.Dataset, xr.DataArray],\n",
    "    layer_dim: str = \"layer\",\n",
    "    strict_layer_multiindex: bool = True,\n",
    "    layer_level_order: Optional[Iterable[str]] = None,\n",
    ") -> Union[xr.Dataset, xr.DataArray]:\n",
    "    \"\"\"\n",
    "    同时过滤：\n",
    "    1) 正常 dims 中坐标值为 'ALL' 的部分\n",
    "    2) 如果存在 (cell, layer) 且 'ALL' 出现在 layer-level coords（dims=('layer',)），也过滤掉这些 layer\n",
    "\n",
    "    不使用 try；如果 strict 且 layer 无法成为 MultiIndex，则直接报错。\n",
    "    \"\"\"\n",
    "\n",
    "    def _filter_da(da: xr.DataArray) -> xr.DataArray:\n",
    "        out = da\n",
    "\n",
    "        # ---------- A) 过滤真正 dims 中的 ALL ----------\n",
    "        for dim in list(out.dims):\n",
    "            if dim in out.coords and out[dim].dtype.kind in (\"U\", \"S\", \"O\"):\n",
    "                vals = out[dim].values\n",
    "                if np.isin(vals, [\"ALL\"]).any():\n",
    "                    out = out.sel({dim: out[dim] != \"ALL\"})\n",
    "\n",
    "        # ---------- B) 过滤 layer-level coords 中的 ALL ----------\n",
    "        if layer_dim in out.dims:\n",
    "            # 仅当存在 layer-level coords 才做\n",
    "            layer_level_vars = [\n",
    "                c for c in out.coords\n",
    "                if c != layer_dim and out.coords[c].dims == (layer_dim,)\n",
    "            ]\n",
    "            if layer_level_vars:\n",
    "                if strict_layer_multiindex:\n",
    "                    out = _ensure_layer_multiindex_strict(\n",
    "                        out, layer_dim=layer_dim, level_order=layer_level_order\n",
    "                    )\n",
    "\n",
    "                # 现在 layer 必须是 MultiIndex（strict 情况下）\n",
    "                if strict_layer_multiindex:\n",
    "                    idx = out.indexes[layer_dim]\n",
    "                    if not isinstance(idx, pd.MultiIndex):\n",
    "                        raise ValueError(f\"Expected '{layer_dim}' to be MultiIndex after ensure, got {type(idx)}\")\n",
    "\n",
    "                    # 过滤：任意 level == 'ALL' 的 layer 都删掉\n",
    "                    keep = np.ones(len(idx), dtype=bool)\n",
    "                    for lvl in idx.names:\n",
    "                        # idx.get_level_values 返回 Index，可直接比较\n",
    "                        keep &= (idx.get_level_values(lvl) != \"ALL\")\n",
    "\n",
    "                    out = out.isel({layer_dim: keep})\n",
    "\n",
    "        return out\n",
    "\n",
    "    # Dataset：对每个变量应用（coords 保持）\n",
    "    if isinstance(obj, xr.Dataset):\n",
    "        new_vars = {}\n",
    "        for v in obj.data_vars:\n",
    "            new_vars[v] = _filter_da(obj[v])\n",
    "        # 注意：不同变量过滤后 layer 可能不同长度；通常你是逐文件逐变量处理，这样是 OK 的\n",
    "        return xr.Dataset(new_vars, attrs=obj.attrs)\n",
    "\n",
    "    # DataArray\n",
    "    return _filter_da(obj)\n",
    "\n",
    "from typing import Sequence\n",
    "\n",
    "\n",
    "def reduce_layered_da(\n",
    "    da: xr.DataArray,\n",
    "    dims_to_sum: Sequence[str],\n",
    "    layer_dim: str = \"layer\",\n",
    "    keep_attrs: bool = True,\n",
    "    skipna: bool = True,\n",
    "    layer_level_order: Optional[Iterable[str]] = None,\n",
    ") -> xr.DataArray:\n",
    "    \"\"\"\n",
    "    输入：da dims 通常为 ('cell','layer')，且 layer 是 MultiIndex（或可由 layer-level coords 严格重建）\n",
    "    输出：仍为 ('cell','layer')，并保持 layer 为 MultiIndex（多级索引坐标可恢复、可 sel）\n",
    "\n",
    "    不使用 try；无法 unstack 就直接报错。\n",
    "    \"\"\"\n",
    "    if not np.issubdtype(da.dtype, np.number):\n",
    "        return da\n",
    "\n",
    "    if layer_dim not in da.dims:\n",
    "        # 没有 layer，就按普通 dims_to_sum 求和\n",
    "        present = [d for d in dims_to_sum if d in da.dims]\n",
    "        return da.sum(dim=present, keep_attrs=keep_attrs, skipna=skipna) if present else da\n",
    "\n",
    "    # 1) 严格确保 layer 是 MultiIndex\n",
    "    da = _ensure_layer_multiindex_strict(da, layer_dim=layer_dim, level_order=layer_level_order)\n",
    "\n",
    "    # 2) unstack：layer -> 多维 dims (am/lm/lu/source/...)\n",
    "    da_u = da.unstack(layer_dim)\n",
    "\n",
    "    # 3) 在真正 dims 上求和\n",
    "    present = [d for d in dims_to_sum if d in da_u.dims]\n",
    "    if present:\n",
    "        da_u = da_u.sum(dim=present, keep_attrs=keep_attrs, skipna=skipna)\n",
    "\n",
    "    # 4) stack 回 layer：把除 cell 以外的 dims 全部 stack\n",
    "    stack_levels = [d for d in da_u.dims if d != \"cell\"]\n",
    "    if layer_level_order is not None:\n",
    "        layer_level_order = list(layer_level_order)\n",
    "        stack_levels = [d for d in layer_level_order if d in stack_levels] + \\\n",
    "                       [d for d in stack_levels if d not in layer_level_order]\n",
    "\n",
    "    if stack_levels:\n",
    "        da_out = da_u.stack({layer_dim: stack_levels})\n",
    "        # 让 MultiIndex 的 level coords 作为 (layer,) coords 存在（xarray 会自动创建）\n",
    "        return da_out\n",
    "    else:\n",
    "        # 全 sum 掉了，只剩 cell\n",
    "        return da_u\n",
    "\n"
   ],
   "id": "dd87f3a730652cd2",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T06:45:21.397424800Z",
     "start_time": "2026-02-18T06:45:20.946207500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# ====== 1. 配置你要看的文件 ======\n",
    "file_path = load_path\n",
    "engine = \"h5netcdf\"\n",
    "chunks = \"auto\"\n",
    "\n",
    "dims_to_sum = (\n",
    "    'lm', 'source', 'Type', 'GHG_source',\n",
    "    'Cost type', 'From water-supply', 'To water-supply'\n",
    ")\n",
    "\n",
    "layer_level_order = None\n",
    "# 例如：\n",
    "# layer_level_order = ['am','lm','lu','source','Type']\n",
    "\n",
    "# ====== 2. 打开文件 ======\n",
    "ds = cfxr.decode_compress_to_multi_index(xr.open_dataset(load_path), 'layer')\n",
    "ds = ds.fillna(0)\n",
    "\n",
    "print(\"\\n=== ORIGINAL DATASET ===\")\n",
    "print(ds)\n",
    "\n",
    "# ====== 3. 对每个变量执行你的新逻辑 ======\n",
    "out_vars = {}\n",
    "\n",
    "for v in ds.data_vars:\n",
    "    print(f\"\\n--- Processing variable: {v} ---\")\n",
    "    da = ds[v]\n",
    "\n",
    "    print(\"Before processing:\")\n",
    "    print(\"  dims:\", da.dims)\n",
    "    print(\"  coords:\", list(da.coords))\n",
    "    if \"layer\" in da.dims:\n",
    "        print(\"  layer index type:\", type(da.indexes.get(\"layer\")))\n",
    "\n",
    "    # (1) 过滤 ALL（包括 layer-level coords）\n",
    "    da = filter_all_from_dims(\n",
    "        da,\n",
    "        layer_dim=\"layer\",\n",
    "        strict_layer_multiindex=True,\n",
    "        layer_level_order=layer_level_order,\n",
    "    )\n",
    "\n",
    "    print(\"\\nAfter filter_all_from_dims:\")\n",
    "    print(\"  dims:\", da.dims)\n",
    "    if \"layer\" in da.dims:\n",
    "        print(\"  layer index type:\", type(da.indexes[\"layer\"]))\n",
    "        if hasattr(da.indexes[\"layer\"], \"names\"):\n",
    "            print(\"  layer levels:\", da.indexes[\"layer\"].names)\n",
    "\n",
    "    # (2) 可逆求和\n",
    "    da = reduce_layered_da(\n",
    "        da,\n",
    "        dims_to_sum=dims_to_sum,\n",
    "        layer_dim=\"layer\",\n",
    "        keep_attrs=True,\n",
    "        skipna=True,\n",
    "        layer_level_order=layer_level_order,\n",
    "    )\n",
    "\n",
    "    print(\"\\nAfter reduce_layered_da:\")\n",
    "    print(\"  dims:\", da.dims)\n",
    "    if \"layer\" in da.dims:\n",
    "        print(\"  layer index type:\", type(da.indexes[\"layer\"]))\n",
    "        print(\"  layer levels:\", da.indexes[\"layer\"].names)\n",
    "        print(\"  number of layers:\", da.sizes[\"layer\"])\n",
    "\n",
    "        # 展示前几行 MultiIndex\n",
    "        print(\"\\n  layer MultiIndex preview:\")\n",
    "        print(da.indexes[\"layer\"].to_frame().head())\n",
    "\n",
    "    out_vars[v] = da\n",
    "\n",
    "# ====== 4. 汇总为 Dataset（不保存） ======\n",
    "out_ds = xr.Dataset(out_vars, attrs=ds.attrs)\n",
    "\n",
    "print(\"\\n================ FINAL RESULT ================\")\n",
    "print(out_ds)\n",
    "\n",
    "# 如果你只关心 data 这个变量\n",
    "if \"data\" in out_ds:\n",
    "    da_final = out_ds[\"data\"]\n",
    "    print(\"\\n=== FINAL DataArray SUMMARY ===\")\n",
    "    print(\"dims:\", da_final.dims)\n",
    "    print(\"sizes:\", da_final.sizes)\n",
    "    print(\"coords:\")\n",
    "    for c in da_final.coords:\n",
    "        print(f\"  {c}: dims={da_final.coords[c].dims}, dtype={da_final.coords[c].dtype}\")\n",
    "\n",
    "    if \"layer\" in da_final.dims:\n",
    "        print(\"\\nLayer MultiIndex detail:\")\n",
    "        print(\"  type:\", type(da_final.indexes[\"layer\"]))\n",
    "        print(\"  level names:\", da_final.indexes[\"layer\"].names)\n",
    "        print(da_final.indexes[\"layer\"].to_frame().head())"
   ],
   "id": "b3df13a6dc24226e",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"No variable named 'layer'. Variables on the dataset include ['From-land-use', 'To-land-use', 'Cost-type', 'cell', 'data']\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32mF:\\Users\\s222552331\\Work\\Apps\\miniforge3\\envs\\xpluto\\Lib\\site-packages\\xarray\\core\\dataset.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   1474\u001B[0m             \u001B[0mvariable\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_variables\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1475\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1476\u001B[1;33m             \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvariable\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_get_virtual_variable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_variables\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msizes\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1477\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'layer'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32mF:\\Users\\s222552331\\Work\\Apps\\miniforge3\\envs\\xpluto\\Lib\\site-packages\\xarray\\core\\dataset.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   1573\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_construct_dataarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1574\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1575\u001B[1;33m                 raise KeyError(\n\u001B[0m\u001B[0;32m   1576\u001B[0m                     \u001B[1;33mf\"\u001B[0m\u001B[1;33mNo variable named \u001B[0m\u001B[1;33m{\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m!\u001B[0m\u001B[0mr\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m. Variables on the dataset include \u001B[0m\u001B[1;33m{\u001B[0m\u001B[0mshorten_list_repr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvariables\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeys\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmax_items\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mF:\\Users\\s222552331\\Work\\Apps\\miniforge3\\envs\\xpluto\\Lib\\site-packages\\xarray\\core\\dataset.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   1474\u001B[0m             \u001B[0mvariable\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_variables\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1475\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1476\u001B[1;33m             \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvariable\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_get_virtual_variable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_variables\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msizes\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1477\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mF:\\Users\\s222552331\\Work\\Apps\\miniforge3\\envs\\xpluto\\Lib\\site-packages\\xarray\\core\\dataset.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(variables, key, dim_sizes)\u001B[0m\n\u001B[0;32m    207\u001B[0m     \u001B[0msplit_key\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mkey\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\".\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    208\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msplit_key\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[1;36m2\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 209\u001B[1;33m         \u001B[1;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    210\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'layer'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32mC:\\Users\\local_s222552331\\Temp\\2\\ipykernel_76492\\144491024.py\u001B[0m in \u001B[0;36m?\u001B[1;34m()\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[1;31m# 例如：\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[1;31m# layer_level_order = ['am','lm','lu','source','Type']\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[1;31m# ====== 2. 打开文件 ======\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 19\u001B[1;33m \u001B[0mds\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcfxr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdecode_compress_to_multi_index\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mxr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mopen_dataset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mload_path\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'layer'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     20\u001B[0m \u001B[0mds\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mds\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfillna\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"\\n=== ORIGINAL DATASET ===\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mF:\\Users\\s222552331\\Work\\Apps\\miniforge3\\envs\\xpluto\\Lib\\site-packages\\cf_xarray\\coding.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(encoded, idxnames)\u001B[0m\n\u001B[0;32m     95\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0midxnames\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     96\u001B[0m         \u001B[0midxnames\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0midxnames\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     97\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     98\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0midxname\u001B[0m \u001B[1;32min\u001B[0m \u001B[0midxnames\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 99\u001B[1;33m         \u001B[1;32mif\u001B[0m \u001B[1;34m\"compress\"\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mencoded\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0midxname\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mattrs\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    100\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Attribute 'compress' not found in provided Dataset.\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    101\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    102\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mencoded\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mxr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataset\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mF:\\Users\\s222552331\\Work\\Apps\\miniforge3\\envs\\xpluto\\Lib\\site-packages\\xarray\\core\\dataset.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   1571\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mutils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhashable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1572\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1573\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_construct_dataarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1574\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1575\u001B[1;33m                 raise KeyError(\n\u001B[0m\u001B[0;32m   1576\u001B[0m                     \u001B[1;33mf\"\u001B[0m\u001B[1;33mNo variable named \u001B[0m\u001B[1;33m{\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m!\u001B[0m\u001B[0mr\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m. Variables on the dataset include \u001B[0m\u001B[1;33m{\u001B[0m\u001B[0mshorten_list_repr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvariables\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeys\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmax_items\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1577\u001B[0m                 \u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1578\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: \"No variable named 'layer'. Variables on the dataset include ['From-land-use', 'To-land-use', 'Cost-type', 'cell', 'data']\""
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "604957f5bc920387",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xpluto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
