{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T01:54:03.949154900Z",
     "start_time": "2026-02-25T01:54:03.820404700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import xarray as xr\n",
    "import cf_xarray as cfxr\n",
    "import pandas as pd\n",
    "\n",
    "def load_from_nc(load_path: str, var_name: str = 'data') -> xr.DataArray:\n",
    "    \"\"\"\n",
    "    从 NetCDF 文件恢复 DataArray,自动处理 multi-index\n",
    "    \"\"\"\n",
    "    ds = xr.open_dataset(load_path)\n",
    "\n",
    "    # 尝试解码 multi-index\n",
    "    try:\n",
    "        has_compress = any(\n",
    "            'compress' in ds[var].attrs\n",
    "            for var in ds.coords\n",
    "            if var in ds.variables\n",
    "        )\n",
    "        if has_compress:\n",
    "            ds = cfxr.decode_compress_to_multi_index(ds, 'layer')\n",
    "    except (ValueError, KeyError):\n",
    "        pass\n",
    "\n",
    "    # 提取 DataArray\n",
    "    if var_name in ds.data_vars:\n",
    "        da = ds[var_name]\n",
    "    else:\n",
    "        var_name = list(ds.data_vars)[0]\n",
    "        da = ds[var_name]\n",
    "\n",
    "    return da"
   ],
   "id": "c326b5913ee0e13d",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-25T01:54:05.226017200Z",
     "start_time": "2026-02-25T01:54:03.952974900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_path = r\"F:\\Users\\s222552331\\Work\\LUTO2_XH\\luto-2.0\\output\\20260223_Paper2_Results_test\\carbon_price\\0_base_data\\Run_25_GHG_off_BIO_off_CUT_10\\2050\\xr_biodiversity_GBF2_priority_ag_2050.nc\"\n",
    "xr_arr = xr.open_dataset(load_path)\n",
    "print(xr_arr)"
   ],
   "id": "c50805998fd8a6bd",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "did not find a match in any of xarray's currently installed IO backends ['netcdf4', 'h5netcdf', 'scipy', 'rasterio']. Consider explicitly selecting one of the installed engines via the ``engine`` parameter, or installing additional IO dependencies, see:\nhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html\nhttps://docs.xarray.dev/en/stable/user-guide/io.html",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m load_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mF:\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mUsers\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124ms222552331\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mWork\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mLUTO2_XH\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mluto-2.0\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124moutput\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m20260223_Paper2_Results_test\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mcarbon_price\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m0_base_data\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mRun_25_GHG_off_BIO_off_CUT_10\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m2050\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mxr_biodiversity_GBF2_priority_ag_2050.nc\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m----> 2\u001B[0m xr_arr \u001B[38;5;241m=\u001B[39m \u001B[43mxr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mload_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(xr_arr)\n",
      "File \u001B[1;32mF:\\Users\\s222552331\\Work\\Apps\\miniforge3\\envs\\xpluto\\Lib\\site-packages\\xarray\\backends\\api.py:552\u001B[0m, in \u001B[0;36mopen_dataset\u001B[1;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001B[0m\n\u001B[0;32m    549\u001B[0m     kwargs\u001B[38;5;241m.\u001B[39mupdate(backend_kwargs)\n\u001B[0;32m    551\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m engine \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 552\u001B[0m     engine \u001B[38;5;241m=\u001B[39m \u001B[43mplugins\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mguess_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename_or_obj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    554\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m from_array_kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    555\u001B[0m     from_array_kwargs \u001B[38;5;241m=\u001B[39m {}\n",
      "File \u001B[1;32mF:\\Users\\s222552331\\Work\\Apps\\miniforge3\\envs\\xpluto\\Lib\\site-packages\\xarray\\backends\\plugins.py:197\u001B[0m, in \u001B[0;36mguess_engine\u001B[1;34m(store_spec)\u001B[0m\n\u001B[0;32m    189\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    190\u001B[0m     error_msg \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    191\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfound the following matches with the input file in xarray\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms IO \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    192\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbackends: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcompatible_engines\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. But their dependencies may not be installed, see:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    193\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://docs.xarray.dev/en/stable/user-guide/io.html \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    194\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    195\u001B[0m     )\n\u001B[1;32m--> 197\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(error_msg)\n",
      "\u001B[1;31mValueError\u001B[0m: did not find a match in any of xarray's currently installed IO backends ['netcdf4', 'h5netcdf', 'scipy', 'rasterio']. Consider explicitly selecting one of the installed engines via the ``engine`` parameter, or installing additional IO dependencies, see:\nhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html\nhttps://docs.xarray.dev/en/stable/user-guide/io.html"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "xr_arr.sum()",
   "id": "5322e654dbfaf8a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "bd0b91c51f3e9047",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "xr_arr.coords['From-land-use'].values",
   "id": "d1fa64245023fc2b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from typing import Union, Iterable, Optional\n",
    "\n",
    "\n",
    "def _ensure_layer_multiindex_strict(\n",
    "    da: xr.DataArray,\n",
    "    layer_dim: str = \"layer\",\n",
    "    level_order: Optional[Iterable[str]] = None,\n",
    ") -> xr.DataArray:\n",
    "    \"\"\"\n",
    "    严格确保 da 的 layer 是 MultiIndex。\n",
    "    规则：\n",
    "    - 如果 layer 已经是 MultiIndex：直接返回\n",
    "    - 否则要求存在 coords(dims=(layer,)) 的 level 变量（如 am/lm/lu/source...）\n",
    "      用 set_index(layer=[...]) 构造 MultiIndex\n",
    "    - 如果没有 level 变量：直接报错（因为无法还原）\n",
    "    \"\"\"\n",
    "    if layer_dim not in da.dims:\n",
    "        return da\n",
    "\n",
    "    idx = da.indexes.get(layer_dim, None)\n",
    "    if isinstance(idx, pd.MultiIndex):\n",
    "        return da\n",
    "\n",
    "    layer_level_vars = [\n",
    "        c for c in da.coords\n",
    "        if c != layer_dim and da.coords[c].dims == (layer_dim,)\n",
    "    ]\n",
    "    if not layer_level_vars:\n",
    "        raise ValueError(\n",
    "            f\"'{layer_dim}' is not a MultiIndex and no layer-level coords exist to rebuild it. \"\n",
    "            f\"Available coords with dims=('layer',): {layer_level_vars}\"\n",
    "        )\n",
    "\n",
    "    if level_order is not None:\n",
    "        level_order = list(level_order)\n",
    "        layer_level_vars = [c for c in level_order if c in layer_level_vars] + \\\n",
    "                           [c for c in layer_level_vars if c not in level_order]\n",
    "\n",
    "    return da.set_index({layer_dim: layer_level_vars})\n",
    "\n",
    "\n",
    "def filter_all_from_dims(\n",
    "    obj: Union[xr.Dataset, xr.DataArray],\n",
    "    layer_dim: str = \"layer\",\n",
    "    strict_layer_multiindex: bool = True,\n",
    "    layer_level_order: Optional[Iterable[str]] = None,\n",
    ") -> Union[xr.Dataset, xr.DataArray]:\n",
    "    \"\"\"\n",
    "    同时过滤：\n",
    "    1) 正常 dims 中坐标值为 'ALL' 的部分\n",
    "    2) 如果存在 (cell, layer) 且 'ALL' 出现在 layer-level coords（dims=('layer',)），也过滤掉这些 layer\n",
    "\n",
    "    不使用 try；如果 strict 且 layer 无法成为 MultiIndex，则直接报错。\n",
    "    \"\"\"\n",
    "\n",
    "    def _filter_da(da: xr.DataArray) -> xr.DataArray:\n",
    "        out = da\n",
    "\n",
    "        # ---------- A) 过滤真正 dims 中的 ALL ----------\n",
    "        for dim in list(out.dims):\n",
    "            if dim in out.coords and out[dim].dtype.kind in (\"U\", \"S\", \"O\"):\n",
    "                vals = out[dim].values\n",
    "                if np.isin(vals, [\"ALL\"]).any():\n",
    "                    out = out.sel({dim: out[dim] != \"ALL\"})\n",
    "\n",
    "        # ---------- B) 过滤 layer-level coords 中的 ALL ----------\n",
    "        if layer_dim in out.dims:\n",
    "            # 仅当存在 layer-level coords 才做\n",
    "            layer_level_vars = [\n",
    "                c for c in out.coords\n",
    "                if c != layer_dim and out.coords[c].dims == (layer_dim,)\n",
    "            ]\n",
    "            if layer_level_vars:\n",
    "                if strict_layer_multiindex:\n",
    "                    out = _ensure_layer_multiindex_strict(\n",
    "                        out, layer_dim=layer_dim, level_order=layer_level_order\n",
    "                    )\n",
    "\n",
    "                # 现在 layer 必须是 MultiIndex（strict 情况下）\n",
    "                if strict_layer_multiindex:\n",
    "                    idx = out.indexes[layer_dim]\n",
    "                    if not isinstance(idx, pd.MultiIndex):\n",
    "                        raise ValueError(f\"Expected '{layer_dim}' to be MultiIndex after ensure, got {type(idx)}\")\n",
    "\n",
    "                    # 过滤：任意 level == 'ALL' 的 layer 都删掉\n",
    "                    keep = np.ones(len(idx), dtype=bool)\n",
    "                    for lvl in idx.names:\n",
    "                        # idx.get_level_values 返回 Index，可直接比较\n",
    "                        keep &= (idx.get_level_values(lvl) != \"ALL\")\n",
    "\n",
    "                    out = out.isel({layer_dim: keep})\n",
    "\n",
    "        return out\n",
    "\n",
    "    # Dataset：对每个变量应用（coords 保持）\n",
    "    if isinstance(obj, xr.Dataset):\n",
    "        new_vars = {}\n",
    "        for v in obj.data_vars:\n",
    "            new_vars[v] = _filter_da(obj[v])\n",
    "        # 注意：不同变量过滤后 layer 可能不同长度；通常你是逐文件逐变量处理，这样是 OK 的\n",
    "        return xr.Dataset(new_vars, attrs=obj.attrs)\n",
    "\n",
    "    # DataArray\n",
    "    return _filter_da(obj)\n",
    "\n",
    "from typing import Sequence\n",
    "\n",
    "\n",
    "def reduce_layered_da(\n",
    "    da: xr.DataArray,\n",
    "    dims_to_sum: Sequence[str],\n",
    "    layer_dim: str = \"layer\",\n",
    "    keep_attrs: bool = True,\n",
    "    skipna: bool = True,\n",
    "    layer_level_order: Optional[Iterable[str]] = None,\n",
    ") -> xr.DataArray:\n",
    "    \"\"\"\n",
    "    输入：da dims 通常为 ('cell','layer')，且 layer 是 MultiIndex（或可由 layer-level coords 严格重建）\n",
    "    输出：仍为 ('cell','layer')，并保持 layer 为 MultiIndex（多级索引坐标可恢复、可 sel）\n",
    "\n",
    "    不使用 try；无法 unstack 就直接报错。\n",
    "    \"\"\"\n",
    "    if not np.issubdtype(da.dtype, np.number):\n",
    "        return da\n",
    "\n",
    "    if layer_dim not in da.dims:\n",
    "        # 没有 layer，就按普通 dims_to_sum 求和\n",
    "        present = [d for d in dims_to_sum if d in da.dims]\n",
    "        return da.sum(dim=present, keep_attrs=keep_attrs, skipna=skipna) if present else da\n",
    "\n",
    "    # 1) 严格确保 layer 是 MultiIndex\n",
    "    da = _ensure_layer_multiindex_strict(da, layer_dim=layer_dim, level_order=layer_level_order)\n",
    "\n",
    "    # 2) unstack：layer -> 多维 dims (am/lm/lu/source/...)\n",
    "    da_u = da.unstack(layer_dim)\n",
    "\n",
    "    # 3) 在真正 dims 上求和\n",
    "    present = [d for d in dims_to_sum if d in da_u.dims]\n",
    "    if present:\n",
    "        da_u = da_u.sum(dim=present, keep_attrs=keep_attrs, skipna=skipna)\n",
    "\n",
    "    # 4) stack 回 layer：把除 cell 以外的 dims 全部 stack\n",
    "    stack_levels = [d for d in da_u.dims if d != \"cell\"]\n",
    "    if layer_level_order is not None:\n",
    "        layer_level_order = list(layer_level_order)\n",
    "        stack_levels = [d for d in layer_level_order if d in stack_levels] + \\\n",
    "                       [d for d in stack_levels if d not in layer_level_order]\n",
    "\n",
    "    if stack_levels:\n",
    "        da_out = da_u.stack({layer_dim: stack_levels})\n",
    "        # 让 MultiIndex 的 level coords 作为 (layer,) coords 存在（xarray 会自动创建）\n",
    "        return da_out\n",
    "    else:\n",
    "        # 全 sum 掉了，只剩 cell\n",
    "        return da_u\n",
    "\n"
   ],
   "id": "dd87f3a730652cd2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# ====== 1. 配置你要看的文件 ======\n",
    "file_path = load_path\n",
    "engine = \"h5netcdf\"\n",
    "chunks = \"auto\"\n",
    "\n",
    "dims_to_sum = (\n",
    "    'lm', 'source', 'Type', 'GHG_source',\n",
    "    'Cost type', 'From water-supply', 'To water-supply'\n",
    ")\n",
    "\n",
    "layer_level_order = None\n",
    "# 例如：\n",
    "# layer_level_order = ['am','lm','lu','source','Type']\n",
    "\n",
    "# ====== 2. 打开文件 ======\n",
    "ds = cfxr.decode_compress_to_multi_index(xr.open_dataset(load_path), 'layer')\n",
    "ds = ds.fillna(0)\n",
    "\n",
    "print(\"\\n=== ORIGINAL DATASET ===\")\n",
    "print(ds)\n",
    "\n",
    "# ====== 3. 对每个变量执行你的新逻辑 ======\n",
    "out_vars = {}\n",
    "\n",
    "for v in ds.data_vars:\n",
    "    print(f\"\\n--- Processing variable: {v} ---\")\n",
    "    da = ds[v]\n",
    "\n",
    "    print(\"Before processing:\")\n",
    "    print(\"  dims:\", da.dims)\n",
    "    print(\"  coords:\", list(da.coords))\n",
    "    if \"layer\" in da.dims:\n",
    "        print(\"  layer index type:\", type(da.indexes.get(\"layer\")))\n",
    "\n",
    "    # (1) 过滤 ALL（包括 layer-level coords）\n",
    "    da = filter_all_from_dims(\n",
    "        da,\n",
    "        layer_dim=\"layer\",\n",
    "        strict_layer_multiindex=True,\n",
    "        layer_level_order=layer_level_order,\n",
    "    )\n",
    "\n",
    "    print(\"\\nAfter filter_all_from_dims:\")\n",
    "    print(\"  dims:\", da.dims)\n",
    "    if \"layer\" in da.dims:\n",
    "        print(\"  layer index type:\", type(da.indexes[\"layer\"]))\n",
    "        if hasattr(da.indexes[\"layer\"], \"names\"):\n",
    "            print(\"  layer levels:\", da.indexes[\"layer\"].names)\n",
    "\n",
    "    # (2) 可逆求和\n",
    "    da = reduce_layered_da(\n",
    "        da,\n",
    "        dims_to_sum=dims_to_sum,\n",
    "        layer_dim=\"layer\",\n",
    "        keep_attrs=True,\n",
    "        skipna=True,\n",
    "        layer_level_order=layer_level_order,\n",
    "    )\n",
    "\n",
    "    print(\"\\nAfter reduce_layered_da:\")\n",
    "    print(\"  dims:\", da.dims)\n",
    "    if \"layer\" in da.dims:\n",
    "        print(\"  layer index type:\", type(da.indexes[\"layer\"]))\n",
    "        print(\"  layer levels:\", da.indexes[\"layer\"].names)\n",
    "        print(\"  number of layers:\", da.sizes[\"layer\"])\n",
    "\n",
    "        # 展示前几行 MultiIndex\n",
    "        print(\"\\n  layer MultiIndex preview:\")\n",
    "        print(da.indexes[\"layer\"].to_frame().head())\n",
    "\n",
    "    out_vars[v] = da\n",
    "\n",
    "# ====== 4. 汇总为 Dataset（不保存） ======\n",
    "out_ds = xr.Dataset(out_vars, attrs=ds.attrs)\n",
    "\n",
    "print(\"\\n================ FINAL RESULT ================\")\n",
    "print(out_ds)\n",
    "\n",
    "# 如果你只关心 data 这个变量\n",
    "if \"data\" in out_ds:\n",
    "    da_final = out_ds[\"data\"]\n",
    "    print(\"\\n=== FINAL DataArray SUMMARY ===\")\n",
    "    print(\"dims:\", da_final.dims)\n",
    "    print(\"sizes:\", da_final.sizes)\n",
    "    print(\"coords:\")\n",
    "    for c in da_final.coords:\n",
    "        print(f\"  {c}: dims={da_final.coords[c].dims}, dtype={da_final.coords[c].dtype}\")\n",
    "\n",
    "    if \"layer\" in da_final.dims:\n",
    "        print(\"\\nLayer MultiIndex detail:\")\n",
    "        print(\"  type:\", type(da_final.indexes[\"layer\"]))\n",
    "        print(\"  level names:\", da_final.indexes[\"layer\"].names)\n",
    "        print(da_final.indexes[\"layer\"].to_frame().head())"
   ],
   "id": "b3df13a6dc24226e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "604957f5bc920387",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xpluto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
